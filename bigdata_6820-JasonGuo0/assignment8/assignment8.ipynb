{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assignment8.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"5a0b-JeEKoiV","colab_type":"text"},"cell_type":"markdown","source":["# Assignment 8: Exploration of our neural network in MNIST\n","In this assignment, I would like you to add some features to our neural network , and then use this to optimize its performance.\n","\n","Tasks:\n","1.  During training, as one cycles over the epochs, it is helpful to keep track of the test set performance.   At the end of each epoch,  calculate the training and test set accuracy.   Plot these to see how the performance changes vs epoch.   You could try to come up with a way to automatically stop the training.\n","2.  Add the confusion matrix calculation to the summary performance information that is calculated when training is done.\n","3.  Optimize this network for the number of hidden nodes.   Do this the correct way!\n","\n","Extra:\n","1.  Did you notice that there is structure in the cost function plot?   What is the source of this structure?   Can you remove it?\n","2.  This is more involved: add another hidden layer to the network.   You will have to modify the forward pass as well as the backpropagation methods.\n"]},{"metadata":{"id":"HyV5V8ZscWIN","colab_type":"text"},"cell_type":"markdown","source":["##Basic mathematical functions"]},{"metadata":{"id":"d78i4wiJKnqi","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","def sigmoid(z):\n","  sm = 1.0 / (1.0 + np.exp(z))\n","  return sm\n","\n","def sigmoid_deriv(z):\n","  sm = sigmoid(z)*(1-sigmoid(z))\n","  return sm\n","\n","def tanh(z):\n","  return np.tanh(z)\n","\n","\n","def tanh_deriv(z):\n","  return 1 - np.square(np.tanh(z))\n","\n","#The output v has the same shape as the input v\n","def softmaxNew(v):\n","  # v is of shape (m, k)\n","  logC = -np.max(v)\n","  #For every element in the v matrix, it is shifted, \n","  # to keep the element from getting too big that it freaks out the exponential\n","  #np.sum(np.exp(v + loC), axis=1)[:, np.newaxis] is of shape m\n","  #np.exp(v + logC)/np.sum(np.exp(v + logC), axis = 1)[:,np.newaxis] \n","  return np.exp(v + logC)/np.sum(np.exp(v + logC), axis = 1)[:,np.newaxis] # Shape is (m,k)\n","\n","def autovivify(levels=1, final=dict):\n","    return (defaultdict(final) if levels < 2 else\n","            defaultdict(lambda: autovivify(levels-1, final)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uB4A_tCNfdmj","colab_type":"text"},"cell_type":"markdown","source":["##Get the google drive ready."]},{"metadata":{"id":"uYLmm_bLfibe","colab_type":"code","outputId":"1624a45c-5275-414f-fb70-5ca33e9ab910","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1551233230515,"user_tz":300,"elapsed":3831,"user":{"displayName":"Jason Guo","photoUrl":"","userId":"14099781163872529237"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","import sys\n","#!{sys.executable} -m pip install -U -q PyDrive\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"hJF6ceZndrrN","colab_type":"text"},"cell_type":"markdown","source":["##Import the MNIST data and onehot encode the labels.\n","Make train and test sets."]},{"metadata":{"id":"0yj_qsUpdeRv","colab_type":"code","outputId":"ac1ff28e-354d-4dbd-d3b0-9def36a07c48","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1551233234671,"user_tz":300,"elapsed":7967,"user":{"displayName":"Jason Guo","photoUrl":"","userId":"14099781163872529237"}}},"cell_type":"code","source":["#Import the data\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Form our test and train data\n","from sklearn.model_selection import train_test_split\n","\n","#short = \"\"\n","short = \"short_\"\n","dfCombined = pd.DataFrame()\n","#\n","# Read in digits\n","for digit in range(10):\n","    fname = 'https://raw.githubusercontent.com/big-data-analytics-physics/data/master/ch3/digit_' + short + str(digit) + '.csv'\n","    df = pd.read_csv(fname,header=None)\n","    df['digit'] = digit\n","    dfCombined = pd.concat([dfCombined, df])\n","\n","train_digits,test_digits = train_test_split(dfCombined, test_size=0.3, random_state=42)\n","yTrain_digit = train_digits['digit'].values\n","XTrain = train_digits.as_matrix(columns=train_digits.columns[:784])\n","\n","yTest_digit = test_digits['digit'].values\n","XTest = test_digits.as_matrix(columns=test_digits.columns[:784])\n","\n","#onehot encode the train labels\n","yTrain_oneHot = np.zeros((len(yTrain_digit), 10))\n","for i in range(len(yTrain_digit)):\n","    yTrain_oneHot[i][yTrain_digit[i]] = 1\n","\n","#onehot encode the test labels    \n","yTest_oneHot = np.zeros((len(yTest_digit), 10))\n","for i in range(len(yTest_digit)):\n","    yTest_oneHot[i][yTest_digit[i]] = 1\n","    \n","\n","#Normalize the grayscale figure\n","XTrain = XTrain / 255.0\n","XTest = XTest / 255.0\n","#\n","print(\"XTrain\",XTrain.shape)\n","print(\"XTest\",XTest.shape)\n","\n","print(\"yTrain_oneHot\", yTrain_oneHot.shape, yTrain_oneHot[20])\n","print(\"yTest_oneHot\", yTest_oneHot.shape, yTest_oneHot[20])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["XTrain (7000, 784)\n","XTest (3000, 784)\n","yTrain_oneHot (7000, 10) [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","yTest_oneHot (3000, 10) [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"],"name":"stdout"}]},{"metadata":{"id":"rUTRfEBycedB","colab_type":"text"},"cell_type":"markdown","source":["#Define the Neural Network class to facilitate future reuse.\n"]},{"metadata":{"id":"ndt2PkgPdBm_","colab_type":"text"},"cell_type":"markdown","source":["##Define the class\n","A neural network of any depth can be defined using a list of the numbers of hidden layer nodes. "]},{"metadata":{"id":"w0sxlCdecnaY","colab_type":"code","colab":{}},"cell_type":"code","source":["import time\n","\n","#Generate the same initial guesses so that we can reliably compare the results between models.\n","\n","#To allow the reuse of fitted models, we should import weight and layers hidden layers\n","class neuralNetwork:\n","    #We can skip passing the sample data and w for now.\n","    def __init__(self, X=None, w=None, Lambda=0.0):\n","        self.X = X\n","        self.w = w\n","        self.Lambda = Lambda\n","        \n","        self.a = [] #a[i] is the matrix immediately before being linearly mapped to a neural layer[i+1]\n","        self.z = [] #z[i] is the neural layer\n","        self.probs = None\n","        \n","        if self.X == None:\n","            print(\"No sample data passed, please use load() or initialize() to build your network\")\n","            \n","        if self.w == None:\n","            print(\"No weights layers passed, please use load() or initialize() to build your network\")\n","    \n","    def clearMemory(self):\n","        self.X = None\n","        \n","        self.w = []\n","        self.z = []\n","        self.a = []\n","        \n","        self.Lambda = 0.0\n","        \n","        self.probs = None\n","        \n","    #If no sample data and w was passed, we can initialize the neural network now.\n","    #Load just needs to care about the original sample and the weights..\n","    def load(self, X, filename, link, num_of_weights_layers):\n","        self.clearMemory()\n","        \n","        self.X = X\n","        self.w = []\n","        \n","#        if loadFromGoogleDrive == False:\n","#            file = open(filename, 'w')\n","#            #Write the Lambda then the weights\n","#            self.Lambda = float(file.readlines())\n","#            print(\"The Lambda is:\", self.Lambda)\n","#            \n","#            for shape in shapes:\n","#                w = np.zeros(shape)\n","#                for i in range(shape[0]):\n","#                    w[i] = np.fromstring(file.readlines(), dtype=float, sep=',').copy()\n","#                print(\"Loading weights layer: \", w.shape)\n","#                self.w.append(w)\n","#                \n","#            file.close()\n","#                \n","#        else:\n","        id = link.split('=')[1]\n","        print(\"The file to read has name\", filename)\n","        print(\"The file to read has id: \", id)\n","        downloaded = drive.CreateFile({'id': id})\n","        downloaded.GetContentFile(filename)\n","        file = open(filename, 'r')\n","        info = file.readlines()\n","        \n","        \n","        self.Lambda = float(info[0])\n","        print(\"The Lambda is:\", self.Lambda)\n","        print(info)\n","        \n","        shapes = []\n","        for i in range(1, num_of_weights_layers + 1):\n","            array = np.fromstring(info[i], dtype=float, sep=',')\n","            shape = (int(array[0]), int(array[1]))\n","            shapes.append(shape)\n","            \n","        print(\"The shape of the weights layers are: \", shapes)\n","        #We have generated a list of shapes which allows us to read in the data in the correct form.\n","        \n","        load_start = num_of_weights_layers + 1\n","        for shape in shapes:\n","            w = np.zeros(shape)\n","            for i in range(load_start, load_start + shape[0]):\n","                w[i-load_start] = np.fromstring(info[i], dtype=float, sep=',').copy()\n","            print(\"Loading weights layer: \", w.shape)\n","            self.w.append(w)\n","            load_start += shape[0] #Move the load position to get ready for the next layers reading.\n","        #The spacing line created in the writing process is ignore by the file.readlines()\n","        \n","        self.z = [i for i in range(0, len(self.w)+1)]\n","        self.z[0] = self.X\n","        \n","        self.forward_pass(self.X)\n","        \n","        \n","    def export(self):\n","        time_mark  = str(time.gmtime().tm_year) + '_' + str(time.gmtime().tm_mon) + '_' + str(time.gmtime().tm_mday) + '_' + str(time.gmtime().tm_hour) + '_' + str(time.gmtime().tm_min)\n","        model_shapes = \"\"\n","        for w in self.w:\n","            model_shapes += '_' + str(w.shape[0]) + 'x' + str(w.shape[1])\n","            \n","        filename = time_mark + model_shapes\n","        \n","        print(\"The filename will be: \", filename)\n","        \n","        with open(\"/content/gdrive/My Drive/NeuralNetwork/\" + filename + \".text\", 'w') as f:\n","            f.write(str(self.Lambda) + \"\\n\")\n","            print(\"Lambda exported: \", self.Lambda)\n","            \n","            for i in self.w:\n","                f.write(str(i.shape[0]) + ',' + str(i.shape[1]) + '\\n')   \n","            \n","            for i in range(len(self.w)):\n","                for j in range(len(self.w[i])):\n","                    self.w[i][j].tofile(f, sep=',')\n","                    f.write('\\n')\n","                f.write('\\n') #Leave a spacing line between different w layers\n","            \n","    \n","    def initialize(self, X, hidden_nodes, Lambda = 0.0):\n","        self.clearMemory()\n","        \n","        self.X = X\n","        #Start generating weights layers\n","        print(\"All memory of current progress has been cleared\\nRandomly generating new network layers using hidden_nodes\")\n","        print(\"The numbers of hidden nodes are: \", hidden_nodes)\n","        np.random.seed(42)\n","        self.w.append(np.random.uniform(-1, 1, size=(hidden_nodes[0], self.X.shape[1] + 1)))\n","        print(\"The #0 weights layer is RNGed, shape: \", type(self.w), self.w[0].shape)\n","\n","        for i in range(1, len(hidden_nodes)):\n","            np.random.seed(42)\n","            self.w.append(np.random.uniform(-1, 1, size=(hidden_nodes[i], self.w[i-1].shape[0] + 1)))\n","            print(\"The #\", i, \" weights layer is RNGed, shape: \", self.w[i].shape)\n","        \n","        \n","        #Now we have X and w , we can invoke forward_pass() to flesh out the network\n","        self.a, self.z, self.probs = self.forward_pass(self.X)\n","        \n","        print(\"The original sample:\\n\", type(self.X), self.X.shape)\n","        for i in range(len(self.z)):\n","            print(\"The generated neural layers: z[\", i, \"] is \", type(self.z[i]), self.z[i].shape)\n","        for i in range(len(self.a)):\n","            print(\"The a list: a[\", i, \"] is\", type(self.a[i]))\n","        print(\"The output probabilities are:\\n\", type(self.probs), self.probs.shape)\n","                \n","    #We don't change the weights matrices, but we generate new a and z matrices all the time.\n","    #Take in the X, w and flesh out all the other data.\n","    def forward_pass(self, X):\n","        a = None\n","        a = [i for i in range(len(self.w))]\n","        #self.we should have self.w and X at this point, noself.w let's calculate a, z, probs.\n","        z = [i for i in range(0, len(self.w)+1)]\n","        z[0] = X.copy() #z[0] is a copy of the original data.\n","        \n","        for i in range(0, len(self.w)):\n","            ones = np.ones((len(X), 1))\n","            if i == 0:\n","                a[i] = np.append(ones, z[i], axis = 1)\n","            else:\n","                #The remaining layers require nonlinearization\n","                a[i] = np.append(ones, tanh(z[i]), axis =1)\n","                \n","            z[i+1] = np.dot(a[i], self.w[i].T)\n","        #The probs is from the last z layer, self.we self.want to store this information as it self.will be useful for both gradient calc and cost calc\n","        probs = softmaxNew(z[len(z) - 1])\n","        return a, z, probs\n","    \n","    #calc_cost() uses the network's own probability matrix and \n","    def calc_cost(self, yp_oneHot):\n","        sample_size = yp_oneHot.shape[0]\n","        regularization = 0.0\n","        if self.Lambda != 0:\n","            for i in range(len(self.w)):\n","                regularization += np.sum(np.square(self.w[i][:, 1:]))\n","        \n","        cost = (-1.0 / sample_size) * np.sum(yp_oneHot * np.log(self.probs)) + (self.Lambda/2.0) * regularization\n","        return cost\n","\n","    #Ideally, back_propagate should only use the weights layer and the input sample subsets to generate the gradients of the weights layers.\n","    def back_propagate(self, X, yp_oneHot):\n","        #Jz[i] = pJ_pzi\n","        #a[i] and z[i] always need to be generated.\n","        a, z, probs = self.forward_pass(X)\n","        \n","        Jz = [i for i in range(len(z))] #There are same number of Jz as self.z\n","        #self.z is 1 element long than self.a and self.w\n","        #Here, we are just initializing the back_propagate info, the num of layers are fixed,\n","        #but the dimension at each layer is flexible depending on X\n","        Ja = [i for i in range(len(a))]\n","        Ja_z = [i for i in range(len(a))]\n","        Jw = [i for i in range(len(self.w))]\n","        Dz = [i for i in range(len(z))]\n","        \n","        #Back propagate\n","        #Jz[len(z) - 1] = 1.0/ len(X) * (probs - yp_oneHot). Technically, this is the correct expression, but we need a bigger graident.\n","        Jz[len(z) - 1] = probs - yp_oneHot #The immediate layer to the cost function.\n","        \n","        i = len(z) - 2\n","        while(i >=0 ):\n","            Jw[i] = Jz[i+1].T.dot(a[i])\n","            Jw[i][:, 1:] += self.w[i][:, 1:] * self.Lambda\n","            Ja[i] = Jz[i+1].dot(self.w[i])\n","            #Delete the column due to appending ones, and filter out params passed by last z layer\n","            Ja_z[i] = np.delete(Ja[i], 0, 1)\n","            Jz[i] = Ja_z[i] * tanh_deriv(z[i])\n","            \n","            i -= 1\n","            \n","        grad_w = Jw\n","        \n","        return grad_w\n","    \n","    def fit(self, yTrain_oneHot, learningRate=0.001, epochs=100, numBatches=20, realtime_eval=False, delta=0.0005, XTest=None, yTest_oneHot=None):\n","        decay_rate = 0.01\n","        learning_rate = learningRate\n","        costs = []\n","        results = []\n","        try:\n","            for i in range(epochs):\n","                learning_rate = learning_rate / (1 + decay_rate * i)\n","                #for every epoch, we generate a random sequence so that we won't deal with the same splitting every epoch.\n","                #np.random.permutation(array) returns an array shuffled along the first axis.\n","                #np.array_split(array, numBatches) splits the array into numBatches small batches, while the order is maintained.\n","                mini = np.array_split(np.random.permutation(np.arange(self.X.shape[0])), numBatches)\n","                print(\"epoch\", i)\n","                \n","                for index in mini:\n","                    grad_w  = self.back_propagate(self.X[index], yTrain_oneHot[index])\n","\n","                    for j in range(len(self.w)):\n","                        self.w[j] -= learning_rate * grad_w[j]\n","                    self.a, self.z, self.probs = self.forward_pass(self.X)\n","\n","\n","                    cost = self.calc_cost(yTrain_oneHot)\n","                    costs.append(cost)\n","                    \n","                print(\"The cost at the end of this epoch is \", cost)\n","                \n","                if realtime_eval == True:\n","                    print(\"Now let's test the model after this epoch:\")\n","                    result = self.performance(yTest_oneHot, self.predict(XTest))\n","                    results.append(result)\n","                    print(\"Confusion array \", result[\"confusion\"])\n","                    print(\"Accuracy Macro\", result[\"accMacro\"], \"Precision Macro\", result[\"precMacro\"])\n","                    \n","                    if i > 1:\n","                        accMacroChange = np.abs(results[len(results)-1][\"accMacro\"] - results[len(results)-2][\"accMacro\"])\n","                        precMacroChange = np.abs(results[len(results)-1][\"precMacro\"] - results[len(results)-2][\"precMacro\"])\n","                        costChange = np.abs(costs[len(costs)-1] - costs[len(costs)-2])\n","                        print(\"Change of the performance:\", accMacroChange, precMacroChange, \"\\nChange of cost: \", costChange)\n","                        if accMacroChange < delta and precMacroChange < delta and costChange < delta:\n","                            print(\"The fitting stopped improving and has been terminated, while the progress has been saved.\")\n","                            break\n","                        \n","                    \n","        except KeyboardInterrupt:\n","            print(\"The fitting was forced to stop early by KeyboardInterrupt, but all progress is saved.\")\n","            \n","        if realtime_eval == False:\n","            return costs\n","        else:\n","            return costs, results\n","    \n","    #Feed data, be it the original or test sample. We create temporary containers to store them.\n","    #We don't want the test sample to mess with fitting. And we won't change the weights, since those are the soul of a neural network.\n","    def predict(self, X):\n","        a, z, probs = self.forward_pass(X)\n","        predictions = np.zeros((probs.shape))\n","        \n","        for i in range(len(probs)):\n","            predictions[i][np.argmax(probs[i])] = 1\n","        \n","        return predictions\n","        \n","    \n","    def performance(self, yTest_oneHot, predictions):        \n","        #Our counter array. We don't need autovivify actually. For now we just need to analyze numerical data, and efficiency.\n","        confusion = np.zeros((yTest_oneHot.shape[1], yTest_oneHot.shape[1]))\n","        \n","        for i in range(len(predictions)):\n","            true = np.argmax(yTest_oneHot[i]) #The true class of the digit\n","            pred = np.argmax(predictions[i]) #The predicted class.\n","            #totalTrue[true] += 1 #Counts how many times true shows up\n","            #totalPred[pred] += 1 #Counts how many times pred is predicted\n","            confusion[true][pred] += 1\n","        \n","        accMacro = 0.0\n","        precMacro = 0.0\n","        \n","        for pred in range(len(confusion)): #We now will iterate over all the 10 predicted classes.\n","            #For example, we predict 4 at this iteration.\n","            accMacro += confusion[pred][pred] / np.sum(confusion, axis=1)[pred] #The probability of accurately catching a label with 4. \n","            #Precision is how confident you are sure of your predictions.\n","            precMacro += confusion[pred][pred] / np.sum(confusion, axis=0)[pred]\n","            \n","            \n","            #Recall is how sensitive your estimator is to the digit you should catch.\n","        \n","        accMacro /= predictions.shape[1]#accMacro averaged over the number of classes.\n","        precMacro /= predictions.shape[1]\n","\n","        return {\"confusion\":confusion,\"accMacro\":accMacro, \"precMacro\":precMacro}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"df8jgkijctaN","colab_type":"text"},"cell_type":"markdown","source":["##Test the initialization of the class"]},{"metadata":{"id":"-dvP_OgIc0km","colab_type":"code","outputId":"aa4164a8-c8f9-41c0-f64f-9ab4221ea797","colab":{"base_uri":"https://localhost:8080/","height":524},"executionInfo":{"status":"ok","timestamp":1551233236557,"user_tz":300,"elapsed":9821,"user":{"displayName":"Jason Guo","photoUrl":"","userId":"14099781163872529237"}}},"cell_type":"code","source":["#Initiralize the network.\n","#initialize(self, X, hidden_nodes, Lambda = 0.0)\n","#load(self, X, filename, link, num_of_weights_layers)\n","NN = neuralNetwork()\n","X = np.random.randint(5, size=(4,6))\n","NN.initialize(XTrain, np.array([10, 10]), Lambda = 0.0)\n","\n","print(\"Test the normalization of the a matrices:\\n\", np.sum(NN.probs, axis=1))\n","\n","NN.export()\n","\n","NN_Load = neuralNetwork()\n","\n","NN_Load.load(X, \"2019_2_25_3_3_10x7_10x11.text\", \"https://drive.google.com/open?id=1-Djbu5Prdn6Xt6Sp6A4UbQ_-DU4oyPap\", 2)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [10 10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (10, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 11)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","Test the normalization of the a matrices:\n"," [1. 1. 1. ... 1. 1. 1.]\n","The filename will be:  2019_2_27_2_7_10x785_10x11\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","The file to read has name 2019_2_25_3_3_10x7_10x11.text\n","The file to read has id:  1-Djbu5Prdn6Xt6Sp6A4UbQ_-DU4oyPap\n","The Lambda is: 0.0\n","['0.0\\n', '10,7\\n', '10,11\\n', '-0.33849391803246376,-0.07673264980639627,0.6919685952219168,0.7333204618540756,0.7545619830038708,-0.5553483240354609,0.992134582582558\\n', '-0.6478845425228748,0.47549243556903176,0.0034609919139332312,-0.1356409957764957,-0.6735242419530458,-0.5286099096641839,-0.9620890256803485\\n', '0.6546792647504072,-0.907609967059344,0.7183377754647107,0.6824746457281221,-0.048263568166249105,0.640168993795315,0.31417381236023845\\n', '-0.22493917047111145,0.14706219195087566,0.5133150945958971,0.847583815616439,0.5802077729677357,-0.4635573993297959,-0.3330019529161181\\n', '0.884247604963915,-0.3746015431216334,-0.6511317434093975,0.013432703670311463,-0.4099433559577066,-0.5372232744431911,0.04744070909738052\\n', '-0.7237611527470307,0.4965356343260061,0.1897301739048618,0.25203878211965725,-0.6810477550536469,-0.37924790193171853,-0.4535746178884421\\n', '0.029673915978855936,0.8606338000893976,-0.3938987902894835,-0.6872900945941605,-0.4980619120995846,0.24552345370375872,-0.37122571856395803\\n', '0.028724276541050475,0.6601136800264646,-0.747193486310264,-0.5215693456678978,0.5441700900986894,-0.2633689229478928,-0.8481648877437971\\n', '-0.6577907181941334,-0.2612099703066122,0.035944304232765845,0.14369714765648722,-0.1329963100855085,0.5188654675585045,0.9777593256289274\\n', '0.4373519827615371,-0.17220609132383036,0.9841875539687761,-0.4706270376222512,-0.44301535433658734,-0.28968946332089063,-0.44219613830131443\\n', '\\n', '-0.39197335232698705,-0.26462723802700405,0.7307118090962366,0.7553591151332208,-0.02732696239091692,-0.4751427970725137,-0.6094227814005853,0.7579317393391698,-0.62909217537262,-0.7260365324507867,-0.7104649955036137\\n', '-0.9787098786185817,-0.7606630532566054,-0.4633317361253506,-0.49012282117253836,-0.16834744737760188,-0.8119691088727969,0.9210642784902301,-0.675761797910442,-0.09988174035089914,-0.27311413348363267,0.596977822014372\\n', '-0.09643222113192729,-0.9873006522650625,-0.46153328757714895,-0.8279024763957452,0.9351322932381148,0.004642025875250866,-0.011947242433179017,-0.5928496764151354,0.5896981801275349,0.17872770382589254,-0.9163933715315373\\n', '0.04209068146819961,-0.9816722988433733,-0.8630772120140098,0.2848534970063976,0.05637814784391648,0.3721304929702405,0.5453529041942451,-0.3847979625931772,-0.35681162349056583,-0.8288855017339698,0.561099568585163\\n', '-0.6661424035016668,-0.18447295834164334,-0.13225985648218064,-0.4590940253969278,0.04366813538972214,0.8227295409786635,-0.24076348715441176,-0.602410758989335,-0.7140166621677335,0.6866292053431502,0.10356120966289706\\n', '-0.6533905202788157,0.3861569625306569,-0.13209832412936184,-0.05352948286193171,-0.05596424168348357,-0.08827968443912448,-0.13108984387479894,0.665395582261308,0.5397845762712581,-0.1943440133380303,0.3907009209400123\\n', '0.1775635205715771,0.6174698580864058,-0.8647586061651396,0.0036450905427749536,0.9732657099955033,-0.44072354458339946,0.9853749189872107,0.7183859217361306,-0.7143518156826911,0.37232380768638373,0.9288317171837996\\n', '0.6438945361488733,0.1830900659627699,0.9027529798029572,-0.21128030040200163,0.5687580255451488,0.9079239535428838,-0.02321399374394817,-0.9919885211485184,-0.15626139837192943,0.1338891711843746,0.3857907978113648\\n', '0.43002014586120874,0.9904059281601862,-0.030661767674771134,-0.3728420289543166,-0.9641990856893117,0.35387188903537603,-0.2269130965913233,0.9250243339295736,0.35762024519960645,-0.9182156128532379,-0.3245085798212475\\n', '-0.4974580052637865,0.06498732972131172,-0.23677557974607,-0.1247775577457304,0.9105182986691573,-0.9511415555525322,-0.8388643774485316,-0.8773195237274509,0.7901650101091846,-0.062228775354507215,-0.15463834937277965\\n', '\\n']\n","The shape of the weights layers are:  [(10, 7), (10, 11)]\n","Loading weights layer:  (10, 7)\n","Loading weights layer:  (10, 11)\n"],"name":"stdout"}]},{"metadata":{"id":"aCIQy69Lc54W","colab_type":"text"},"cell_type":"markdown","source":["#Apply the network model on the MNIST data"]},{"metadata":{"id":"BV3S_SF-dkid","colab_type":"text"},"cell_type":"markdown","source":["##Run the fit and view the cost list."]},{"metadata":{"id":"CrllUjGQdfyp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":7829},"outputId":"6f0820b7-fb23-413c-c591-516c7f0b49dd","executionInfo":{"status":"ok","timestamp":1551233297828,"user_tz":300,"elapsed":71074,"user":{"displayName":"Jason Guo","photoUrl":"","userId":"14099781163872529237"}}},"cell_type":"code","source":["#fit(self, yTrain_oneHot, learningRate=0.001, epochs=100, numBatches=20, realtime_eval=False, delta=0.0005, XTest=None, yTest_oneHot=None):\n","print(\"XTrain shape\", XTrain.shape)\n","print(\"yTrain_oneHot shape\", yTrain_oneHot.shape)\n","\n","print(\"XTest shape\", XTest.shape)\n","print(\"yTest_oneHot\", yTest_oneHot.shape)\n","costs, results = NN.fit(yTrain_oneHot, learningRate=0.01, epochs=100, numBatches=20, realtime_eval=True, delta= 0.0001, XTest=XTest, yTest_oneHot=yTest_oneHot)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["XTrain shape (7000, 784)\n","yTrain_oneHot shape (7000, 10)\n","XTest shape (3000, 784)\n","yTest_oneHot (3000, 10)\n","epoch 0\n","The cost at the end of this epoch is  1.0565896173428826\n","Now let's test the model after this epoch:\n","Confusion array  [[284.   1.   5.   3.   2.   5.   1.   2.  15.   0.]\n"," [  0. 282.   4.   4.   0.   1.   1.   0.  14.   2.]\n"," [  7.   7. 128.  18.  10.   0.  15.   7.  93.   3.]\n"," [ 14.   9.   4. 210.   4.  16.   0.   4.  37.   5.]\n"," [  2.   2.   9.   1. 149.   0.   6.   2.  35. 114.]\n"," [ 17.   9.   2.  65.   3.  74.   5.   4. 108.   3.]\n"," [ 24.   5.  13.   0.  43.   4. 154.   5.  43.   1.]\n"," [  9.   8.   1.   2.   9.   2.   0. 186.  22.  53.]\n"," [  2.  12.   6.  20.   3.   4.   3.   0. 268.   6.]\n"," [  2.   2.   2.   3.  21.   3.   0.  18.  49. 165.]]\n","Accuracy Macro 0.6281162906663903 Precision Macro 0.6801642408270148\n","epoch 1\n","The cost at the end of this epoch is  0.8633540502533508\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   6.   2.   1.   0.   2.   1.   4.   0.]\n"," [  1. 268.  28.   1.   0.   0.   1.   0.   5.   4.]\n"," [  9.   0. 229.   5.   0.   0.  16.   9.  18.   2.]\n"," [ 18.   6.  45. 184.   1.   7.   2.   6.  22.  12.]\n"," [  0.   1.   9.   0. 120.   0.  23.   3.   0. 164.]\n"," [ 53.   3.  16.  35.   2.  66.  17.   7.  81.  10.]\n"," [ 13.   2.  16.   0.  10.   0. 239.   1.  10.   1.]\n"," [  3.   2.   8.   1.   3.   0.   1. 229.   5.  40.]\n"," [  8.   7.  44.   8.   1.   2.   8.   0. 225.  21.]\n"," [  1.   1.   2.   0.   9.   0.   3.  24.   3. 222.]]\n","Accuracy Macro 0.695972124610756 Precision Macro 0.7362046267108334\n","epoch 2\n","The cost at the end of this epoch is  0.6117041840684718\n","Now let's test the model after this epoch:\n","Confusion array  [[293.   0.   1.   4.   0.   8.   5.   0.   7.   0.]\n"," [  0. 286.   5.   1.   2.   2.   0.   0.  10.   2.]\n"," [  6.   3. 220.  14.   3.   3.  11.   5.  20.   3.]\n"," [  7.   5.  22. 224.   2.  18.   1.   3.  17.   4.]\n"," [  0.   0.   4.   1. 271.   1.   9.   2.   3.  29.]\n"," [  9.   2.   4.  28.   3. 176.  13.   1.  51.   3.]\n"," [  6.   4.   6.   0.   9.   6. 254.   0.   7.   0.]\n"," [  2.   6.   7.   4.  11.   0.   0. 227.   8.  27.]\n"," [  3.  12.  11.  17.   3.  12.   5.   0. 258.   3.]\n"," [  1.   1.   0.   1.  62.   1.   0.  12.   6. 181.]]\n","Accuracy Macro 0.7933464882569365 Precision Macro 0.8001232419743726\n","Change of the performance: 0.09737436364618057 0.06391861526353915 \n","Change of cost:  0.017252546211554587\n","epoch 3\n","The cost at the end of this epoch is  0.5703130521588791\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   0.  10.   2.   0.   4.   0.]\n"," [  0. 289.   6.   6.   0.   3.   0.   1.   3.   0.]\n"," [  6.   6. 218.  25.   1.   5.  10.   2.  13.   2.]\n"," [  7.   4.  16. 243.   1.  23.   0.   3.   4.   2.]\n"," [  2.   0.   2.   2. 268.   4.   7.   2.  11.  22.]\n"," [  9.   0.   5.  35.   0. 223.   4.   0.  13.   1.]\n"," [  7.   2.   7.   0.  13.  14. 241.   0.   8.   0.]\n"," [  5.   4.   5.  19.   2.   2.   0. 240.   6.   9.]\n"," [  4.  10.  16.  26.   0.  40.   4.   2. 221.   1.]\n"," [  3.   0.   0.  11.  43.   6.   0.  22.  10. 170.]]\n","Accuracy Macro 0.8014821893711324 Precision Macro 0.8091173022052776\n","Change of the performance: 0.008135701114195815 0.008994060230904988 \n","Change of cost:  0.026263079969067404\n","epoch 4\n","The cost at the end of this epoch is  0.517439945899178\n","Now let's test the model after this epoch:\n","Confusion array  [[287.   0.   5.   5.   0.   7.   3.   0.  11.   0.]\n"," [  0. 294.   5.   2.   1.   1.   0.   0.   3.   2.]\n"," [  4.   4. 244.  10.   0.   3.  10.   2.  10.   1.]\n"," [  5.   7.  31. 237.   0.  11.   0.   3.   2.   7.]\n"," [  0.   0.   6.   0. 277.   0.   8.   2.   1.  26.]\n"," [  7.   1.   7.  50.   1. 170.  11.   0.  42.   1.]\n"," [  7.   3.  16.   0.   5.   6. 246.   0.   9.   0.]\n"," [  4.   4.   8.   7.   2.   0.   0. 235.   4.  28.]\n"," [  2.  17.  20.  23.   4.   7.   5.   1. 242.   3.]\n"," [  1.   1.   2.   4.  17.   1.   0.   3.   0. 236.]]\n","Accuracy Macro 0.8223033406366989 Precision Macro 0.8279360778053828\n","Change of the performance: 0.020821151265566495 0.018818775600105253 \n","Change of cost:  0.006993403243510943\n","epoch 5\n","The cost at the end of this epoch is  0.4389689552224452\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   3.   0.  11.   4.   0.   0.   0.]\n"," [  0. 291.   3.   4.   1.   4.   0.   2.   2.   1.]\n"," [  6.   2. 231.  17.   0.   6.  11.   4.  10.   1.]\n"," [  5.   5.  20. 230.   0.  29.   0.   5.   4.   5.]\n"," [  0.   1.   2.   0. 283.   2.   9.   5.   1.  17.]\n"," [  6.   0.   5.  10.   1. 248.   6.   0.  13.   1.]\n"," [  9.   3.   4.   0.   4.   6. 263.   0.   3.   0.]\n"," [  3.   2.   4.   7.   2.   0.   0. 265.   3.   6.]\n"," [  3.  10.   8.  12.   4.  39.   6.   3. 237.   2.]\n"," [  2.   0.   0.   0.  23.   2.   0.  47.   1. 190.]]\n","Accuracy Macro 0.8442445213488581 Precision Macro 0.8470124436051956\n","Change of the performance: 0.021941180712159225 0.019076365799812756 \n","Change of cost:  0.00013956033327522377\n","epoch 6\n","The cost at the end of this epoch is  0.41612352154605353\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   0.   9.   2.   0.   5.   0.]\n"," [  0. 293.   4.   2.   0.   3.   0.   0.   5.   1.]\n"," [  5.   4. 233.  17.   0.   3.  11.   2.  12.   1.]\n"," [  4.   5.  17. 239.   0.  28.   0.   3.   4.   3.]\n"," [  1.   1.   4.   0. 271.   1.   8.   2.   5.  27.]\n"," [  6.   0.   3.  13.   1. 240.   8.   0.  18.   1.]\n"," [ 10.   2.   5.   0.   2.   7. 261.   0.   5.   0.]\n"," [  3.   5.   5.   8.   4.   0.   0. 247.   4.  16.]\n"," [  3.   9.   7.  12.   0.  30.   5.   1. 254.   3.]\n"," [  1.   1.   1.   1.  10.   3.   0.  10.   3. 235.]]\n","Accuracy Macro 0.8571142579611214 Precision Macro 0.8581938198204504\n","Change of the performance: 0.012869736612263316 0.011181376215254835 \n","Change of cost:  0.016460030905669776\n","epoch 7\n","The cost at the end of this epoch is  0.3821674562542427\n","Now let's test the model after this epoch:\n","Confusion array  [[305.   0.   0.   2.   0.   5.   5.   0.   1.   0.]\n"," [  0. 287.   3.   1.   0.   5.   0.   2.   8.   2.]\n"," [  5.   3. 231.   8.   1.   5.  15.   4.  15.   1.]\n"," [  8.   4.  22. 219.   0.  34.   0.   6.   6.   4.]\n"," [  0.   0.   1.   0. 294.   1.   9.   2.   3.  10.]\n"," [ 10.   0.   2.   7.   2. 244.  10.   0.  14.   1.]\n"," [  8.   3.   3.   0.   4.   4. 268.   0.   2.   0.]\n"," [  3.   4.   4.   2.   2.   2.   0. 265.   3.   7.]\n"," [  5.   7.   6.   7.   2.  20.   6.   1. 267.   3.]\n"," [  1.   0.   1.   0.  20.   3.   0.  24.   2. 214.]]\n","Accuracy Macro 0.8632886309218231 Precision Macro 0.8656321022557684\n","Change of the performance: 0.006174372960701668 0.007438282435317967 \n","Change of cost:  0.013948981353609946\n","epoch 8\n","The cost at the end of this epoch is  0.3884969521267852\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   2.   6.   0.   3.   3.   0.   1.   0.]\n"," [  0. 293.   5.   4.   0.   2.   0.   2.   1.   1.]\n"," [  5.   3. 241.  12.   0.   2.  11.   4.   9.   1.]\n"," [  5.   4.  24. 246.   1.  16.   0.   5.   2.   0.]\n"," [  0.   1.   3.   0. 298.   1.   6.   1.   3.   7.]\n"," [ 10.   1.   6.  32.   1. 220.   8.   0.  11.   1.]\n"," [  9.   2.   9.   0.   5.   4. 258.   0.   5.   0.]\n"," [  3.   4.   7.   6.   2.   1.   0. 262.   2.   5.]\n"," [  6.  11.  17.  15.   4.  19.   6.   1. 243.   2.]\n"," [  1.   1.   0.   5.  20.   2.   0.  26.   1. 209.]]\n","Accuracy Macro 0.8562187486398724 Precision Macro 0.8591697010469618\n","Change of the performance: 0.007069882281950712 0.00646240120880659 \n","Change of cost:  0.025638295229940544\n","epoch 9\n","The cost at the end of this epoch is  0.3606243318887917\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   2.   0.   6.   3.   0.   3.   1.]\n"," [  0. 287.   4.   1.   1.   1.   1.   1.  10.   2.]\n"," [  5.   3. 227.   9.   3.   3.  11.   5.  21.   1.]\n"," [  6.   6.  20. 224.   1.  31.   0.   4.   5.   6.]\n"," [  1.   0.   1.   0. 304.   1.   5.   1.   3.   4.]\n"," [  9.   0.   2.   8.   2. 236.  11.   1.  21.   0.]\n"," [  6.   3.   3.   0.   8.   5. 261.   0.   6.   0.]\n"," [  3.   4.   4.   3.   4.   1.   0. 260.   3.  10.]\n"," [  4.   8.   7.   4.   5.  13.   5.   1. 273.   4.]\n"," [  1.   0.   0.   0.  23.   2.   0.  15.   1. 223.]]\n","Accuracy Macro 0.864425844768021 Precision Macro 0.8673148228098482\n","Change of the performance: 0.008207096128148628 0.008145121762886398 \n","Change of cost:  0.013210094516698967\n","epoch 10\n","The cost at the end of this epoch is  0.32535902670293854\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   0.   7.   2.   0.   4.   1.]\n"," [  0. 288.   3.   2.   1.   3.   1.   2.   7.   1.]\n"," [  5.   1. 234.  10.   1.   3.  11.   5.  17.   1.]\n"," [  3.   4.  23. 227.   0.  33.   0.   4.   4.   5.]\n"," [  1.   0.   2.   0. 299.   2.   5.   1.   3.   7.]\n"," [  5.   0.   3.  11.   2. 247.   7.   0.  14.   1.]\n"," [  7.   3.   3.   0.   7.   6. 261.   0.   5.   0.]\n"," [  3.   3.   8.   2.   2.   0.   0. 262.   1.  11.]\n"," [  3.   6.   7.   8.   4.  20.   4.   1. 267.   4.]\n"," [  1.   0.   0.   0.  15.   2.   0.  18.   1. 228.]]\n","Accuracy Macro 0.8701782539878413 Precision Macro 0.8712026555329576\n","Change of the performance: 0.0057524092198203425 0.003887832723109441 \n","Change of cost:  0.0022654505500642186\n","epoch 11\n","The cost at the end of this epoch is  0.3303198717683028\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   2.   0.   9.   2.   0.   3.   1.]\n"," [  0. 286.   3.   2.   1.   2.   1.   2.   9.   2.]\n"," [  5.   1. 238.   8.   1.   4.   9.   6.  14.   2.]\n"," [  3.   4.  22. 223.   0.  36.   0.   6.   6.   3.]\n"," [  1.   0.   1.   0. 285.   1.   6.   3.   1.  22.]\n"," [  4.   0.   3.   7.   3. 256.   6.   0.  10.   1.]\n"," [ 12.   2.   2.   0.   5.   5. 257.   0.   9.   0.]\n"," [  3.   2.   6.   3.   2.   0.   0. 266.   0.  10.]\n"," [  3.   4.   7.   9.   2.  21.   3.   1. 269.   5.]\n"," [  1.   0.   1.   0.   7.   2.   0.  23.   1. 230.]]\n","Accuracy Macro 0.8700125748305945 Precision Macro 0.8712761258064357\n","Change of the performance: 0.00016567915724685633 7.347027347803792e-05 \n","Change of cost:  0.008904611500175796\n","epoch 12\n","The cost at the end of this epoch is  0.3138195286661643\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   2.   3.   0.   3.   3.   1.   3.   0.]\n"," [  0. 292.   4.   1.   1.   2.   0.   1.   6.   1.]\n"," [  5.   2. 242.   8.   1.   3.  10.   6.  10.   1.]\n"," [  4.   4.  22. 235.   1.  24.   0.   6.   4.   3.]\n"," [  1.   0.   2.   0. 302.   2.   5.   1.   2.   5.]\n"," [  5.   0.   3.  14.   3. 243.   6.   0.  14.   2.]\n"," [  8.   3.   5.   0.   5.   7. 259.   0.   5.   0.]\n"," [  3.   3.   5.   2.   2.   0.   0. 267.   0.  10.]\n"," [  5.   8.   8.   6.   5.  13.   4.   2. 269.   4.]\n"," [  1.   0.   0.   0.  15.   2.   0.  18.   1. 228.]]\n","Accuracy Macro 0.8790412641832015 Precision Macro 0.8794991807779701\n","Change of the performance: 0.009028689352607033 0.008223054971534416 \n","Change of cost:  0.006499529741602228\n","epoch 13\n","The cost at the end of this epoch is  0.3072077434346368\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   0.   4.   3.   0.   4.   1.]\n"," [  0. 291.   4.   1.   1.   2.   1.   1.   6.   1.]\n"," [  5.   2. 240.   8.   1.   4.  10.   6.  11.   1.]\n"," [  3.   4.  23. 228.   1.  32.   0.   5.   4.   3.]\n"," [  1.   0.   1.   0. 302.   2.   6.   1.   3.   4.]\n"," [  4.   0.   2.  11.   2. 249.   6.   0.  15.   1.]\n"," [  8.   3.   3.   0.   6.   7. 260.   0.   5.   0.]\n"," [  3.   3.   6.   2.   4.   1.   0. 262.   1.  10.]\n"," [  3.   8.   8.   6.   3.  18.   3.   2. 270.   3.]\n"," [  1.   0.   0.   0.  18.   2.   0.  15.   1. 228.]]\n","Accuracy Macro 0.8767196578698311 Precision Macro 0.8782263204232714\n","Change of the performance: 0.002321606313370417 0.0012728603546986461 \n","Change of cost:  0.001983410083303272\n","epoch 14\n","The cost at the end of this epoch is  0.30113550787283905\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   0.   8.   2.   1.   3.   0.]\n"," [  0. 290.   4.   2.   1.   2.   0.   1.   7.   1.]\n"," [  5.   3. 238.   9.   1.   4.  10.   6.  11.   1.]\n"," [  3.   4.  22. 233.   1.  29.   0.   5.   3.   3.]\n"," [  1.   0.   2.   0. 299.   2.   6.   1.   4.   5.]\n"," [  4.   0.   2.  13.   2. 250.   6.   0.  12.   1.]\n"," [ 10.   3.   5.   0.   4.   7. 257.   0.   6.   0.]\n"," [  3.   3.   6.   2.   2.   1.   0. 267.   1.   7.]\n"," [  3.   7.   8.  10.   2.  23.   3.   2. 263.   3.]\n"," [  1.   0.   0.   0.  12.   3.   0.  21.   1. 227.]]\n","Accuracy Macro 0.8736472482573225 Precision Macro 0.875136424086395\n","Change of the performance: 0.003072409612508542 0.0030898963368763965 \n","Change of cost:  0.0019769938225536743\n","epoch 15\n","The cost at the end of this epoch is  0.2925693448190508\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   0.   5.   3.   1.   4.   0.]\n"," [  0. 289.   4.   2.   1.   2.   1.   1.   7.   1.]\n"," [  5.   1. 239.  10.   1.   4.  10.   5.  12.   1.]\n"," [  3.   4.  22. 230.   1.  31.   0.   5.   4.   3.]\n"," [  1.   0.   2.   0. 303.   2.   4.   1.   2.   5.]\n"," [  4.   0.   2.  13.   2. 247.   6.   0.  15.   1.]\n"," [  8.   3.   4.   0.   4.   7. 260.   0.   6.   0.]\n"," [  3.   3.   6.   2.   3.   1.   0. 265.   0.   9.]\n"," [  3.   7.   8.   9.   3.  16.   3.   2. 269.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  14.   1. 235.]]\n","Accuracy Macro 0.8784228643249575 Precision Macro 0.8790616856663815\n","Change of the performance: 0.004775616067634991 0.0039252615799865165 \n","Change of cost:  0.0012755189869512185\n","epoch 16\n","The cost at the end of this epoch is  0.2888345369595934\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   2.   3.   0.   3.   3.   1.   4.   0.]\n"," [  0. 291.   4.   1.   1.   2.   0.   1.   7.   1.]\n"," [  5.   1. 241.   8.   1.   3.  10.   6.  12.   1.]\n"," [  3.   4.  23. 233.   1.  28.   0.   5.   3.   3.]\n"," [  1.   0.   2.   0. 302.   2.   5.   1.   2.   5.]\n"," [  5.   0.   3.  13.   3. 243.   7.   0.  15.   1.]\n"," [  8.   3.   4.   0.   4.   7. 261.   0.   5.   0.]\n"," [  3.   3.   6.   2.   3.   1.   0. 265.   0.   9.]\n"," [  4.   7.   8.   8.   4.  15.   3.   2. 269.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  14.   1. 235.]]\n","Accuracy Macro 0.8800363446548607 Precision Macro 0.8804486192002532\n","Change of the performance: 0.0016134803299031608 0.0013869335338716482 \n","Change of cost:  0.0019060457936012076\n","epoch 17\n","The cost at the end of this epoch is  0.2878195438586688\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   2.   3.   0.   2.   3.   1.   4.   0.]\n"," [  0. 291.   4.   1.   1.   1.   1.   1.   7.   1.]\n"," [  5.   1. 244.   8.   1.   3.  10.   4.  11.   1.]\n"," [  3.   4.  24. 230.   0.  30.   0.   5.   3.   4.]\n"," [  1.   0.   2.   0. 292.   1.   6.   3.   3.  12.]\n"," [  5.   0.   3.  12.   3. 246.   7.   0.  13.   1.]\n"," [  8.   3.   4.   0.   4.   7. 261.   0.   5.   0.]\n"," [  3.   3.   7.   2.   3.   0.   0. 263.   0.  11.]\n"," [  5.   7.   8.   9.   3.  13.   5.   2. 268.   4.]\n"," [  1.   0.   0.   0.  10.   2.   0.  15.   1. 236.]]\n","Accuracy Macro 0.8776956454874603 Precision Macro 0.8773553230837668\n","Change of the performance: 0.0023406991674004285 0.0030932961164863437 \n","Change of cost:  0.0017661543061762153\n","epoch 18\n","The cost at the end of this epoch is  0.2838515121282382\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   0.   3.   3.   1.   4.   0.]\n"," [  0. 292.   4.   1.   0.   2.   0.   1.   8.   0.]\n"," [  5.   2. 240.   8.   1.   3.  10.   7.  11.   1.]\n"," [  3.   4.  23. 231.   1.  29.   0.   6.   4.   2.]\n"," [  1.   0.   2.   0. 300.   2.   5.   1.   4.   5.]\n"," [  5.   0.   3.  12.   2. 247.   7.   0.  13.   1.]\n"," [  8.   3.   4.   0.   4.   7. 260.   0.   6.   0.]\n"," [  3.   3.   5.   2.   3.   1.   0. 266.   1.   8.]\n"," [  5.   8.   8.   7.   2.  16.   3.   2. 269.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  17.   1. 232.]]\n","Accuracy Macro 0.8792904320326477 Precision Macro 0.8801913847250853\n","Change of the performance: 0.00159478654518741 0.0028360616413184436 \n","Change of cost:  2.4263070146191e-05\n","epoch 19\n","The cost at the end of this epoch is  0.2805987425365218\n","Now let's test the model after this epoch:\n","Confusion array  [[305.   0.   0.   3.   0.   2.   3.   1.   4.   0.]\n"," [  0. 291.   4.   1.   1.   1.   1.   1.   7.   1.]\n"," [  5.   1. 240.   8.   1.   5.  10.   5.  12.   1.]\n"," [  3.   4.  21. 238.   1.  25.   0.   5.   3.   3.]\n"," [  1.   0.   2.   0. 300.   2.   6.   0.   2.   7.]\n"," [  5.   0.   2.  14.   3. 244.   7.   0.  14.   1.]\n"," [  8.   3.   4.   0.   4.   7. 261.   0.   5.   0.]\n"," [  3.   3.   6.   2.   3.   0.   0. 265.   0.  10.]\n"," [  5.   6.   7.   9.   3.  13.   4.   2. 271.   4.]\n"," [  1.   0.   0.   0.  11.   2.   0.  15.   1. 235.]]\n","Accuracy Macro 0.8826197952123795 Precision Macro 0.8826893602660908\n","Change of the performance: 0.00332936317973187 0.002497975541005504 \n","Change of cost:  0.0003831450521614155\n","epoch 20\n","The cost at the end of this epoch is  0.27896636849376955\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   0.   3.   3.   1.   4.   0.]\n"," [  0. 291.   4.   1.   1.   1.   1.   1.   7.   1.]\n"," [  5.   1. 239.  10.   1.   4.  10.   6.  11.   1.]\n"," [  3.   4.  20. 236.   1.  28.   0.   5.   3.   3.]\n"," [  1.   0.   2.   0. 301.   2.   6.   0.   2.   6.]\n"," [  5.   0.   2.  13.   3. 245.   7.   0.  13.   2.]\n"," [  8.   3.   4.   0.   4.   7. 260.   0.   6.   0.]\n"," [  3.   3.   6.   2.   3.   1.   0. 265.   0.   9.]\n"," [  5.   6.   7.   8.   4.  15.   3.   2. 270.   4.]\n"," [  1.   0.   0.   0.  11.   2.   0.  15.   1. 235.]]\n","Accuracy Macro 0.8809897960234201 Precision Macro 0.8812379308139484\n","Change of the performance: 0.0016299991889594523 0.0014514294521423832 \n","Change of cost:  0.0005142233496947535\n","epoch 21\n","The cost at the end of this epoch is  0.27858985548917325\n","Now let's test the model after this epoch:\n","Confusion array  [[305.   0.   0.   3.   0.   2.   3.   1.   4.   0.]\n"," [  0. 290.   4.   1.   1.   2.   1.   1.   7.   1.]\n"," [  5.   1. 240.   8.   1.   4.  10.   6.  12.   1.]\n"," [  3.   4.  23. 228.   1.  33.   0.   5.   3.   3.]\n"," [  1.   0.   2.   0. 301.   2.   6.   1.   2.   5.]\n"," [  6.   0.   3.  10.   3. 248.   7.   0.  12.   1.]\n"," [  8.   3.   4.   0.   4.   7. 262.   0.   4.   0.]\n"," [  3.   3.   6.   2.   3.   1.   0. 266.   0.   8.]\n"," [  5.   6.   7.   8.   4.  13.   4.   2. 271.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  15.   1. 234.]]\n","Accuracy Macro 0.8809941732158117 Precision Macro 0.8816894571909302\n","Change of the performance: 4.3771923916580135e-06 0.000451526376981759 \n","Change of cost:  0.0005102241756798631\n","epoch 22\n","The cost at the end of this epoch is  0.27633903122022985\n","Now let's test the model after this epoch:\n","Confusion array  [[305.   0.   0.   3.   0.   2.   3.   1.   4.   0.]\n"," [  0. 291.   4.   1.   0.   1.   1.   1.   8.   1.]\n"," [  5.   1. 240.   8.   1.   4.  10.   6.  12.   1.]\n"," [  3.   4.  22. 232.   1.  30.   0.   5.   3.   3.]\n"," [  1.   0.   2.   0. 301.   2.   6.   1.   2.   5.]\n"," [  4.   0.   2.  12.   3. 247.   7.   0.  14.   1.]\n"," [  8.   3.   4.   0.   4.   7. 262.   0.   4.   0.]\n"," [  3.   3.   6.   2.   3.   1.   0. 265.   0.   9.]\n"," [  5.   6.   7.   8.   3.  14.   4.   2. 271.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  15.   1. 234.]]\n","Accuracy Macro 0.8819516872140568 Precision Macro 0.882410220854162\n","Change of the performance: 0.0009575139982450631 0.000720763663231816 \n","Change of cost:  6.003257642855919e-05\n","epoch 23\n","The cost at the end of this epoch is  0.2754285211014113\n","Now let's test the model after this epoch:\n","Confusion array  [[305.   0.   0.   3.   0.   2.   3.   1.   4.   0.]\n"," [  0. 290.   4.   1.   1.   2.   0.   1.   8.   1.]\n"," [  5.   1. 240.   8.   1.   4.  10.   6.  12.   1.]\n"," [  3.   4.  22. 233.   1.  29.   0.   5.   3.   3.]\n"," [  1.   0.   2.   0. 301.   2.   6.   1.   2.   5.]\n"," [  5.   0.   2.  13.   3. 246.   7.   0.  13.   1.]\n"," [  8.   3.   4.   0.   4.   7. 261.   0.   5.   0.]\n"," [  4.   3.   6.   2.   3.   1.   0. 265.   0.   8.]\n"," [  5.   6.   7.   8.   4.  13.   4.   2. 271.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  15.   1. 234.]]\n","Accuracy Macro 0.8812697515530503 Precision Macro 0.8818345451152183\n","Change of the performance: 0.0006819356610064942 0.0005756757389436817 \n","Change of cost:  8.982524719092222e-05\n","epoch 24\n","The cost at the end of this epoch is  0.2747537802160082\n","Now let's test the model after this epoch:\n","Confusion array  [[305.   0.   0.   3.   0.   2.   3.   1.   4.   0.]\n"," [  0. 291.   4.   1.   1.   2.   0.   1.   7.   1.]\n"," [  5.   1. 240.   8.   1.   4.  10.   6.  12.   1.]\n"," [  3.   4.  22. 233.   1.  28.   0.   6.   3.   3.]\n"," [  1.   0.   2.   0. 302.   2.   6.   0.   2.   5.]\n"," [  4.   0.   2.  14.   3. 245.   7.   0.  14.   1.]\n"," [  8.   3.   4.   0.   4.   7. 262.   0.   4.   0.]\n"," [  3.   3.   6.   2.   3.   1.   0. 264.   0.  10.]\n"," [  5.   6.   7.   8.   4.  13.   4.   2. 271.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  15.   1. 234.]]\n","Accuracy Macro 0.8815620992915187 Precision Macro 0.8818552884780917\n","Change of the performance: 0.00029234773846842366 2.074336287338774e-05 \n","Change of cost:  1.2839185531965391e-06\n","epoch 25\n","The cost at the end of this epoch is  0.2740165970486267\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   3.   0.   2.   3.   1.   4.   0.]\n"," [  0. 292.   4.   1.   1.   1.   0.   1.   7.   1.]\n"," [  5.   1. 240.   9.   1.   3.  10.   6.  12.   1.]\n"," [  3.   4.  22. 236.   1.  25.   0.   6.   3.   3.]\n"," [  1.   0.   2.   0. 301.   2.   6.   1.   2.   5.]\n"," [  5.   0.   2.  14.   3. 245.   7.   0.  13.   1.]\n"," [  8.   3.   4.   0.   4.   7. 262.   0.   4.   0.]\n"," [  3.   3.   6.   2.   3.   1.   0. 266.   0.   8.]\n"," [  5.   7.   7.   8.   3.  15.   4.   2. 269.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  15.   1. 234.]]\n","Accuracy Macro 0.8823175557735219 Precision Macro 0.8825026657528576\n","Change of the performance: 0.0007554564820031473 0.0006473772747659368 \n","Change of cost:  7.963491165474679e-05\n","epoch 26\n","The cost at the end of this epoch is  0.2736009751384438\n","Now let's test the model after this epoch:\n","Confusion array  [[305.   0.   0.   3.   0.   2.   3.   1.   4.   0.]\n"," [  0. 291.   4.   1.   1.   2.   0.   1.   7.   1.]\n"," [  5.   1. 240.   8.   1.   4.  10.   6.  12.   1.]\n"," [  3.   4.  22. 235.   1.  26.   0.   6.   3.   3.]\n"," [  1.   0.   2.   0. 301.   2.   6.   1.   2.   5.]\n"," [  4.   0.   2.  13.   3. 246.   7.   0.  14.   1.]\n"," [  8.   3.   4.   0.   4.   7. 262.   0.   4.   0.]\n"," [  3.   3.   6.   2.   3.   1.   0. 266.   0.   8.]\n"," [  5.   6.   7.   8.   3.  15.   4.   2. 270.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  15.   1. 234.]]\n","Accuracy Macro 0.8826307824158668 Precision Macro 0.8830175384770651\n","Change of the performance: 0.0003132266423448993 0.0005148727242074713 \n","Change of cost:  1.0676846551038732e-05\n","epoch 27\n","The cost at the end of this epoch is  0.27323868998301415\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   0.   3.   3.   1.   4.   0.]\n"," [  0. 291.   4.   1.   1.   2.   0.   1.   7.   1.]\n"," [  5.   1. 240.   9.   1.   3.  10.   6.  12.   1.]\n"," [  3.   4.  22. 236.   1.  25.   0.   6.   3.   3.]\n"," [  1.   0.   2.   0. 302.   2.   6.   0.   2.   5.]\n"," [  4.   0.   2.  14.   3. 245.   7.   0.  14.   1.]\n"," [  8.   3.   4.   0.   4.   7. 262.   0.   4.   0.]\n"," [  3.   3.   6.   2.   3.   1.   0. 264.   0.  10.]\n"," [  5.   7.   7.   8.   3.  15.   4.   2. 269.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  15.   1. 234.]]\n","Accuracy Macro 0.8813059835331923 Precision Macro 0.8814806138673351\n","Change of the performance: 0.0013247988826744495 0.0015369246097299838 \n","Change of cost:  2.848620951423353e-05\n","epoch 28\n","The cost at the end of this epoch is  0.2729858760313185\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   0.   3.   3.   1.   4.   0.]\n"," [  0. 291.   4.   1.   1.   2.   0.   1.   7.   1.]\n"," [  5.   1. 240.   9.   1.   3.  10.   6.  12.   1.]\n"," [  3.   4.  22. 236.   1.  25.   0.   6.   3.   3.]\n"," [  1.   0.   2.   0. 302.   2.   6.   0.   2.   5.]\n"," [  4.   0.   2.  14.   3. 245.   7.   0.  14.   1.]\n"," [  8.   3.   4.   0.   4.   7. 262.   0.   4.   0.]\n"," [  3.   3.   6.   2.   3.   1.   0. 264.   0.  10.]\n"," [  5.   7.   7.   8.   3.  15.   4.   2. 269.   4.]\n"," [  1.   0.   0.   0.  12.   2.   0.  15.   1. 234.]]\n","Accuracy Macro 0.8813059835331923 Precision Macro 0.8814806138673351\n","Change of the performance: 0.0 0.0 \n","Change of cost:  2.107632757042399e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n"],"name":"stdout"}]},{"metadata":{"id":"QBqZCoBVJC8T","colab_type":"text"},"cell_type":"markdown","source":["##Looks like we got some decent fitting, precision and recall not very great though.\n","**The costs don't show the pattern Prof. Hughes showed us, since the batches have been shuffled during each epoch.**"]},{"metadata":{"id":"KMx8XpKc2dQn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":347},"outputId":"07bfde49-b87a-4c2e-fe5a-4f5e21acb3e1","executionInfo":{"status":"ok","timestamp":1551233297991,"user_tz":300,"elapsed":71217,"user":{"displayName":"Jason Guo","photoUrl":"","userId":"14099781163872529237"}}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.plot(costs)\n","plt.show()"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDEAgAwCQAQhkAAAywP8H6A5k79ea8KMAAAAASUVORK5CYII=\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"p7qXjaiUJZW_","colab_type":"text"},"cell_type":"markdown","source":["#Look for the correct number of nodes and then try three layers."]},{"metadata":{"id":"2JytXExglmyQ","colab_type":"text"},"cell_type":"markdown","source":["**Try to compare the performance at the auto stop points and also the performances at certain iteration times. The intial guesses are generated using the same seeds.**"]},{"metadata":{"id":"wTSYp6xYJg7f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":131124},"outputId":"df5fbea7-a312-4ef5-d524-29e68018e07b","executionInfo":{"status":"ok","timestamp":1551234327054,"user_tz":300,"elapsed":1100261,"user":{"displayName":"Jason Guo","photoUrl":"","userId":"14099781163872529237"}}},"cell_type":"code","source":["#Write a for loop that creates singler layer neural networks with different nodes.\n","nodes = np.arange(100, 1200, 50)\n","print(nodes)\n","#create neural network list and result list\n","NN_list = [i for i in nodes]\n","Result_list = []\n","for i in nodes:\n","    nn = neuralNetwork()\n","    nn.initialize(XTrain, np.array([i, 10]), Lambda=0.0)\n","    costs, results = NN.fit(yTrain_oneHot, learningRate=0.01, epochs=100, numBatches=20, realtime_eval=True, delta= 0.0001, XTest=XTest, yTest_oneHot=yTest_oneHot)\n","    \n","    NN_list.append({\"nodes\": i, \"network\": nn})\n","    Result_list.append({\"nodes\": i, \"costs\": costs, \"results\": results})\n","    nn.export()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[ 100  150  200  250  300  350  400  450  500  550  600  650  700  750\n","  800  850  900  950 1000 1050 1100 1150]\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [100  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (100, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 101)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 100)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.30209428465909277\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   3.   4.   0.   1.   3.   2.   3.   0.]\n"," [  0. 291.   4.   3.   1.   2.   0.   1.   6.   0.]\n"," [  5.   2. 249.   6.   2.   2.   6.   6.   9.   1.]\n"," [  4.   4.  25. 246.   0.  16.   0.   5.   2.   1.]\n"," [  1.   0.   4.   0. 282.   1.   7.   4.   2.  19.]\n"," [ 10.   0.   4.  20.   3. 229.   9.   0.  14.   1.]\n"," [ 10.   3.   4.   0.   3.   5. 262.   0.   5.   0.]\n"," [  4.   3.   7.   3.   2.   0.   1. 266.   0.   6.]\n"," [  7.   8.  11.  12.   1.  13.   5.   2. 260.   5.]\n"," [  1.   0.   1.   0.   7.   2.   0.  17.   1. 236.]]\n","Accuracy Macro 0.8743114774882839 Precision Macro 0.8740641752012636\n","epoch 1\n","The cost at the end of this epoch is  0.2831023111224495\n","Now let's test the model after this epoch:\n","Confusion array  [[306.   0.   0.   3.   0.   2.   4.   1.   2.   0.]\n"," [  0. 290.   3.   1.   1.   1.   1.   3.   7.   1.]\n"," [  5.   1. 235.  10.   3.   2.   9.   8.  14.   1.]\n"," [  3.   3.  19. 246.   1.  18.   0.   7.   4.   2.]\n"," [  0.   0.   1.   0. 303.   2.   7.   1.   2.   4.]\n"," [  7.   0.   2.  23.   3. 233.   7.   0.  13.   2.]\n"," [  6.   2.   2.   0.   5.   4. 269.   0.   4.   0.]\n"," [  3.   2.   5.   3.   3.   0.   0. 271.   0.   5.]\n"," [  5.   7.   8.  10.   2.  11.   5.   2. 271.   3.]\n"," [  1.   0.   0.   1.  19.   2.   0.  17.   1. 224.]]\n","Accuracy Macro 0.8813017119152438 Precision Macro 0.8825554556315346\n","epoch 2\n","The cost at the end of this epoch is  0.2995067091399426\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   0.   7.   3.   1.   4.   0.]\n"," [  0. 281.   5.   0.   0.   2.   1.   1.  17.   1.]\n"," [  5.   2. 228.   6.   1.   4.  10.  10.  21.   1.]\n"," [  3.   5.  21. 219.   1.  37.   0.   6.   9.   2.]\n"," [  1.   0.   0.   0. 302.   2.   4.   1.   4.   6.]\n"," [  5.   0.   2.   8.   1. 254.   6.   1.  13.   0.]\n"," [ 10.   2.   1.   0.   5.   7. 259.   0.   8.   0.]\n"," [  2.   2.   4.   1.   3.   1.   0. 274.   2.   3.]\n"," [  4.   3.   7.   5.   0.  17.   2.   1. 281.   4.]\n"," [  1.   0.   0.   0.  10.   3.   0.  19.   1. 231.]]\n","Accuracy Macro 0.875410943119092 Precision Macro 0.8803445855391658\n","Change of the performance: 0.005890768796151802 0.002210870092368755 \n","Change of cost:  0.017628296643243835\n","epoch 3\n","The cost at the end of this epoch is  0.28053386990035367\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   0.   3.   0.   3.   3.   0.   4.   1.]\n"," [  0. 287.   4.   0.   1.   3.   0.   0.  10.   3.]\n"," [  5.   4. 232.   8.   1.   2.   8.   4.  22.   2.]\n"," [  3.   4.  16. 240.   0.  20.   0.   4.   8.   8.]\n"," [  1.   0.   0.   0. 297.   2.   5.   0.   2.  13.]\n"," [  4.   0.   1.  14.   3. 240.   7.   1.  19.   1.]\n"," [  8.   4.   1.   0.   5.   6. 262.   0.   6.   0.]\n"," [  2.   4.   5.   2.   5.   0.   0. 250.   1.  23.]\n"," [  1.   5.   6.   6.   3.  14.   3.   1. 278.   7.]\n"," [  1.   0.   0.   0.   8.   2.   0.   3.   1. 250.]]\n","Accuracy Macro 0.8795984570265741 Precision Macro 0.8815849037427654\n","Change of the performance: 0.0041875139074821766 0.0012403182035995997 \n","Change of cost:  0.017892673505665813\n","epoch 4\n","The cost at the end of this epoch is  0.27800184698658587\n","Now let's test the model after this epoch:\n","Confusion array  [[305.   0.   0.   3.   0.   4.   3.   2.   1.   0.]\n"," [  0. 292.   3.   3.   1.   4.   0.   1.   3.   1.]\n"," [  5.   4. 240.   8.   1.   5.   7.   8.  10.   0.]\n"," [  2.   5.  18. 244.   0.  20.   0.   7.   4.   3.]\n"," [  1.   0.   2.   0. 297.   2.   8.   2.   3.   5.]\n"," [  5.   1.   1.  16.   3. 252.   8.   0.   3.   1.]\n"," [ 12.   3.   3.   0.   4.   8. 261.   0.   1.   0.]\n"," [  2.   4.   6.   2.   1.   0.   1. 270.   0.   6.]\n"," [  5.   9.   7.  13.   0.  33.   6.   3. 237.  11.]\n"," [  2.   0.   0.   0.  12.   3.   0.  21.   1. 226.]]\n","Accuracy Macro 0.8745680644380471 Precision Macro 0.8753790341264329\n","Change of the performance: 0.0050303925885269996 0.0062058696163325155 \n","Change of cost:  0.008916296592147599\n","epoch 5\n","The cost at the end of this epoch is  0.2476622989038927\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   0.   3.   4.   1.   3.   0.]\n"," [  0. 290.   4.   2.   1.   3.   0.   1.   6.   1.]\n"," [  5.   4. 238.   7.   1.   3.   8.   6.  15.   1.]\n"," [  2.   3.  19. 234.   0.  30.   0.   7.   4.   4.]\n"," [  1.   0.   2.   0. 302.   2.   6.   0.   2.   5.]\n"," [  4.   0.   1.  12.   3. 251.   7.   1.  11.   0.]\n"," [  5.   2.   3.   0.   4.   6. 267.   0.   5.   0.]\n"," [  1.   5.   6.   3.   2.   0.   1. 261.   1.  12.]\n"," [  4.   9.   8.   4.   3.  20.   6.   2. 261.   7.]\n"," [  1.   0.   0.   0.  10.   3.   0.  11.   1. 239.]]\n","Accuracy Macro 0.8817983514319234 Precision Macro 0.8817380375283284\n","Change of the performance: 0.007230286993876289 0.0063590034018954356 \n","Change of cost:  0.005176054774886779\n","epoch 6\n","The cost at the end of this epoch is  0.24504580871878406\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   1.   0.   7.   3.   1.   5.   0.]\n"," [  0. 290.   5.   1.   0.   2.   0.   1.   8.   1.]\n"," [  5.   4. 244.   4.   1.   3.   7.   5.  14.   1.]\n"," [  2.   4.  21. 245.   1.  19.   0.   6.   4.   1.]\n"," [  1.   1.   3.   0. 294.   2.   7.   0.   3.   9.]\n"," [  4.   0.   3.  15.   1. 240.   6.   0.  21.   0.]\n"," [  9.   2.   4.   0.   1.   7. 260.   0.   9.   0.]\n"," [  2.   7.   8.   2.   2.   0.   1. 262.   1.   7.]\n"," [  2.   7.   7.   6.   0.  17.   5.   1. 276.   3.]\n"," [  1.   0.   0.   0.   8.   2.   0.  12.   2. 240.]]\n","Accuracy Macro 0.8829132763177123 Precision Macro 0.8843636824799276\n","Change of the performance: 0.0011149248857889038 0.0026256449515992264 \n","Change of cost:  0.0065844812867063285\n","epoch 7\n","The cost at the end of this epoch is  0.23074539003037206\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   1.   0.   4.   3.   2.   5.   0.]\n"," [  0. 288.   6.   1.   1.   3.   0.   1.   7.   1.]\n"," [  5.   1. 240.   7.   2.   3.   9.   8.  11.   2.]\n"," [  2.   3.  19. 249.   0.  17.   0.   7.   4.   2.]\n"," [  1.   0.   2.   0. 291.   2.   4.   2.   4.  14.]\n"," [  5.   0.   2.  16.   3. 247.   6.   0.  10.   1.]\n"," [ 11.   2.   3.   0.   5.   8. 254.   0.   9.   0.]\n"," [  2.   3.   5.   4.   3.   0.   0. 267.   0.   8.]\n"," [  3.   5.   7.   8.   2.  19.   2.   2. 270.   6.]\n"," [  1.   0.   0.   0.   8.   3.   0.  14.   1. 238.]]\n","Accuracy Macro 0.8813513581273238 Precision Macro 0.8814775897988927\n","Change of the performance: 0.0015619181903885337 0.002886092681034902 \n","Change of cost:  0.0038992844353317457\n","epoch 8\n","The cost at the end of this epoch is  0.2269528164868505\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   1.   1.   5.   2.   2.   4.   0.]\n"," [  0. 291.   4.   2.   1.   2.   0.   1.   6.   1.]\n"," [  5.   4. 239.   8.   1.   2.   7.   6.  14.   2.]\n"," [  2.   3.  18. 244.   0.  20.   0.   7.   5.   4.]\n"," [  1.   0.   1.   0. 301.   2.   5.   0.   3.   7.]\n"," [  5.   2.   1.  16.   3. 247.   4.   1.  11.   0.]\n"," [ 12.   4.   3.   0.   5.   8. 253.   0.   7.   0.]\n"," [  1.   5.   4.   2.   3.   0.   0. 270.   0.   7.]\n"," [  3.   8.   7.   8.   2.  20.   2.   2. 266.   6.]\n"," [  1.   0.   0.   0.   9.   3.   0.  12.   1. 239.]]\n","Accuracy Macro 0.8832807189588067 Precision Macro 0.883633334558197\n","Change of the performance: 0.0019293608314828736 0.0021557447593043566 \n","Change of cost:  0.0025323337893288222\n","epoch 9\n","The cost at the end of this epoch is  0.222020724686874\n","Now let's test the model after this epoch:\n","Confusion array  [[306.   0.   2.   1.   0.   2.   3.   0.   4.   0.]\n"," [  0. 285.   6.   2.   1.   3.   0.   1.   9.   1.]\n"," [  5.   1. 240.   8.   2.   2.   9.   5.  14.   2.]\n"," [  2.   3.  20. 240.   0.  24.   0.   7.   6.   1.]\n"," [  1.   0.   0.   0. 299.   2.   6.   1.   3.   8.]\n"," [  6.   0.   1.  15.   1. 252.   6.   0.   9.   0.]\n"," [ 10.   2.   2.   0.   5.   8. 255.   0.  10.   0.]\n"," [  2.   3.   8.   4.   3.   0.   0. 267.   0.   5.]\n"," [  5.   3.   5.   6.   1.  18.   2.   2. 278.   4.]\n"," [  1.   0.   0.   0.   9.   3.   0.  14.   1. 237.]]\n","Accuracy Macro 0.8856377431639821 Precision Macro 0.8870972177567472\n","Change of the performance: 0.002357024205175473 0.0034638831985501772 \n","Change of cost:  0.00799208812424379\n","epoch 10\n","The cost at the end of this epoch is  0.22483594539725404\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   2.   0.   3.   3.   1.   5.   1.]\n"," [  0. 290.   3.   3.   0.   3.   0.   1.   7.   1.]\n"," [  5.   4. 231.   9.   2.   6.   8.   7.  15.   1.]\n"," [  2.   4.  13. 246.   1.  25.   0.   7.   5.   0.]\n"," [  1.   0.   1.   0. 304.   1.   5.   2.   3.   3.]\n"," [  5.   1.   1.  11.   1. 261.   3.   0.   7.   0.]\n"," [  9.   3.   3.   0.   5.  10. 255.   0.   7.   0.]\n"," [  2.   6.   6.   3.   3.   0.   0. 265.   0.   7.]\n"," [  3.   8.   4.   8.   1.  30.   3.   3. 261.   3.]\n"," [  1.   0.   0.   0.  15.   3.   0.  13.   1. 232.]]\n","Accuracy Macro 0.8817057669078764 Precision Macro 0.8843938410742\n","Change of the performance: 0.003931976256105751 0.002703376682547165 \n","Change of cost:  0.010045248889854252\n","epoch 11\n","The cost at the end of this epoch is  0.20943733008477194\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   2.   0.   2.   3.   2.   5.   0.]\n"," [  0. 288.   5.   2.   1.   2.   0.   1.   8.   1.]\n"," [  5.   4. 234.   7.   2.   2.   9.   6.  17.   2.]\n"," [  2.   4.  18. 248.   1.  18.   0.   7.   4.   1.]\n"," [  1.   0.   0.   0. 304.   1.   4.   1.   3.   6.]\n"," [  5.   1.   1.  19.   3. 244.   6.   0.  10.   1.]\n"," [  9.   3.   2.   0.   5.   7. 256.   0.  10.   0.]\n"," [  1.   4.   5.   4.   3.   0.   0. 268.   0.   7.]\n"," [  5.   5.   6.   8.   2.  12.   2.   2. 276.   6.]\n"," [  1.   0.   0.   0.  11.   2.   0.  12.   1. 238.]]\n","Accuracy Macro 0.8854741889618054 Precision Macro 0.886254896622243\n","Change of the performance: 0.0037684220539290214 0.0018610555480429447 \n","Change of cost:  0.00249308526293765\n","epoch 12\n","The cost at the end of this epoch is  0.20741257092932663\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   2.   1.   0.   2.   3.   2.   4.   0.]\n"," [  0. 291.   4.   1.   1.   2.   0.   0.   7.   2.]\n"," [  5.   4. 240.   6.   2.   2.   7.   6.  14.   2.]\n"," [  2.   5.  19. 245.   0.  16.   0.   8.   4.   4.]\n"," [  1.   0.   1.   0. 299.   1.   6.   1.   3.   8.]\n"," [  5.   1.   1.  19.   3. 245.   6.   1.   9.   0.]\n"," [ 11.   4.   3.   0.   5.   7. 256.   0.   6.   0.]\n"," [  1.   5.   4.   2.   3.   0.   0. 268.   0.   9.]\n"," [  6.   9.   7.   8.   2.  12.   2.   2. 268.   8.]\n"," [  1.   0.   0.   0.   9.   2.   0.   8.   1. 244.]]\n","Accuracy Macro 0.8864332573952026 Precision Macro 0.8859123645754012\n","Change of the performance: 0.0009590684333972144 0.0003425320468417592 \n","Change of cost:  0.0018884345134029257\n","epoch 13\n","The cost at the end of this epoch is  0.20231947400082584\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   2.   1.   0.   2.   3.   2.   4.   0.]\n"," [  0. 289.   5.   2.   1.   3.   0.   0.   6.   2.]\n"," [  5.   4. 239.   6.   2.   2.   7.   6.  15.   2.]\n"," [  2.   4.  19. 248.   1.  19.   0.   6.   4.   0.]\n"," [  1.   0.   1.   0. 302.   1.   6.   1.   3.   5.]\n"," [  5.   1.   1.  15.   2. 252.   5.   0.   9.   0.]\n"," [  9.   2.   3.   0.   5.  10. 255.   0.   8.   0.]\n"," [  2.   5.   6.   3.   3.   0.   0. 263.   0.  10.]\n"," [  5.   5.   7.   6.   1.  14.   2.   2. 276.   6.]\n"," [  1.   0.   0.   0.  13.   2.   0.   8.   1. 240.]]\n","Accuracy Macro 0.8886829839566361 Precision Macro 0.889365075008534\n","Change of the performance: 0.0022497265614335182 0.0034527104331327774 \n","Change of cost:  0.002407254246639151\n","epoch 14\n","The cost at the end of this epoch is  0.20133136461607823\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   2.   1.   0.   2.   3.   2.   4.   0.]\n"," [  0. 290.   4.   2.   1.   3.   0.   0.   6.   2.]\n"," [  5.   3. 243.   7.   2.   2.   7.   8.   9.   2.]\n"," [  2.   4.  18. 252.   1.  14.   0.   7.   4.   1.]\n"," [  1.   0.   1.   0. 300.   1.   6.   1.   3.   7.]\n"," [  5.   1.   2.  19.   2. 250.   4.   0.   6.   1.]\n"," [ 10.   3.   3.   0.   5.  10. 255.   0.   6.   0.]\n"," [  1.   4.   5.   4.   3.   0.   0. 266.   0.   9.]\n"," [  4.   9.   8.  10.   2.  17.   2.   3. 261.   8.]\n"," [  1.   0.   0.   0.   9.   2.   0.  11.   1. 241.]]\n","Accuracy Macro 0.8871771511321981 Precision Macro 0.8866503096791705\n","Change of the performance: 0.001505832824438058 0.0027147653293635443 \n","Change of cost:  0.001439031351614356\n","epoch 15\n","The cost at the end of this epoch is  0.19742185018276182\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   2.   0.   2.   3.   2.   5.   0.]\n"," [  0. 289.   5.   2.   1.   2.   0.   0.   7.   2.]\n"," [  5.   4. 238.   6.   2.   2.   8.   6.  15.   2.]\n"," [  2.   4.  19. 250.   1.  16.   0.   7.   4.   0.]\n"," [  1.   0.   1.   0. 302.   1.   6.   1.   3.   5.]\n"," [  6.   2.   1.  18.   2. 244.   4.   0.  12.   1.]\n"," [ 10.   3.   3.   0.   5.   8. 256.   0.   7.   0.]\n"," [  1.   5.   5.   3.   3.   0.   0. 267.   0.   8.]\n"," [  5.   7.   7.   8.   2.  12.   2.   2. 272.   7.]\n"," [  1.   0.   0.   0.  12.   2.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8860231440178771 Precision Macro 0.8864368198353695\n","Change of the performance: 0.0011540071143210096 0.00021348984380098468 \n","Change of cost:  2.5505876396492155e-06\n","epoch 16\n","The cost at the end of this epoch is  0.1979709035675099\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   2.   0.   2.   3.   2.   5.   0.]\n"," [  0. 288.   5.   2.   1.   3.   0.   0.   7.   2.]\n"," [  5.   4. 236.   6.   2.   2.   8.   6.  17.   2.]\n"," [  2.   4.  18. 247.   0.  19.   0.   6.   5.   2.]\n"," [  1.   0.   0.   0. 296.   1.   6.   1.   4.  11.]\n"," [  6.   2.   1.  16.   1. 248.   3.   0.  12.   1.]\n"," [ 13.   3.   3.   0.   5.   7. 252.   0.   9.   0.]\n"," [  1.   5.   5.   3.   3.   0.   0. 267.   0.   8.]\n"," [  5.   5.   5.   8.   2.  13.   2.   2. 275.   7.]\n"," [  1.   0.   0.   0.   9.   2.   0.  12.   2. 239.]]\n","Accuracy Macro 0.883074298495911 Precision Macro 0.8837967416136265\n","Change of the performance: 0.002948845521966059 0.0026400782217429475 \n","Change of cost:  0.0009322966391399623\n","epoch 17\n","The cost at the end of this epoch is  0.1961661004172401\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   2.   0.   2.   3.   2.   4.   0.]\n"," [  0. 289.   5.   2.   1.   3.   0.   0.   6.   2.]\n"," [  5.   4. 240.   6.   2.   2.   7.   7.  13.   2.]\n"," [  2.   4.  18. 253.   0.  15.   0.   6.   4.   1.]\n"," [  1.   0.   1.   0. 297.   1.   6.   1.   4.   9.]\n"," [  6.   2.   2.  17.   1. 251.   3.   0.   8.   0.]\n"," [ 11.   3.   3.   0.   5.   9. 252.   0.   9.   0.]\n"," [  2.   4.   5.   4.   3.   0.   0. 266.   0.   8.]\n"," [  5.   5.   6.   8.   1.  15.   2.   2. 273.   7.]\n"," [  1.   0.   0.   0.   9.   2.   0.  12.   1. 240.]]\n","Accuracy Macro 0.8878471176832272 Precision Macro 0.8881314601008425\n","Change of the performance: 0.004772819187316202 0.004334718487216005 \n","Change of cost:  0.0008952435210051457\n","epoch 18\n","The cost at the end of this epoch is  0.1931886177852973\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   2.   0.   2.   3.   2.   4.   0.]\n"," [  0. 290.   4.   2.   1.   2.   0.   0.   7.   2.]\n"," [  5.   4. 239.   6.   2.   2.   7.   6.  15.   2.]\n"," [  2.   4.  19. 250.   1.  17.   0.   6.   4.   0.]\n"," [  1.   0.   1.   0. 302.   1.   6.   1.   3.   5.]\n"," [  5.   2.   2.  16.   1. 249.   4.   0.  10.   1.]\n"," [ 10.   3.   3.   0.   5.  10. 255.   0.   6.   0.]\n"," [  1.   6.   5.   2.   3.   0.   0. 266.   0.   9.]\n"," [  5.  10.   6.   9.   1.  15.   2.   2. 267.   7.]\n"," [  1.   0.   0.   0.  12.   2.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8865055035212215 Precision Macro 0.8867699780471169\n","Change of the performance: 0.0013416141620057331 0.00136148205372566 \n","Change of cost:  0.00022521319714569055\n","epoch 19\n","The cost at the end of this epoch is  0.1918687294725544\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   2.   0.   2.   3.   2.   4.   0.]\n"," [  0. 289.   5.   2.   1.   3.   0.   0.   6.   2.]\n"," [  5.   4. 239.   6.   2.   2.   7.   6.  15.   2.]\n"," [  2.   4.  19. 249.   1.  17.   0.   6.   4.   1.]\n"," [  1.   0.   1.   0. 299.   1.   6.   1.   4.   7.]\n"," [  5.   2.   2.  17.   2. 249.   4.   0.   8.   1.]\n"," [ 10.   3.   3.   0.   5.   9. 255.   0.   7.   0.]\n"," [  2.   5.   6.   3.   3.   0.   0. 263.   0.  10.]\n"," [  5.   9.   8.   8.   2.  14.   2.   2. 267.   7.]\n"," [  1.   0.   0.   0.   9.   2.   0.   8.   1. 244.]]\n","Accuracy Macro 0.8857726903858023 Precision Macro 0.8855999908626574\n","Change of the performance: 0.0007328131354191747 0.0011699871844594867 \n","Change of cost:  0.0002532561024959634\n","epoch 20\n","The cost at the end of this epoch is  0.19155804958264852\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   2.   0.   2.   3.   2.   5.   0.]\n"," [  0. 289.   5.   2.   1.   3.   0.   0.   6.   2.]\n"," [  5.   4. 237.   6.   2.   2.   8.   6.  16.   2.]\n"," [  2.   4.  19. 249.   1.  18.   0.   6.   4.   0.]\n"," [  1.   0.   1.   0. 299.   1.   6.   1.   4.   7.]\n"," [  5.   2.   1.  17.   1. 251.   4.   0.   8.   1.]\n"," [ 10.   3.   3.   0.   5.  10. 254.   0.   7.   0.]\n"," [  2.   5.   6.   3.   3.   0.   0. 263.   0.  10.]\n"," [  4.   7.   5.   9.   1.  15.   2.   2. 272.   7.]\n"," [  1.   0.   0.   0.   9.   2.   0.   8.   1. 244.]]\n","Accuracy Macro 0.8866541798280851 Precision Macro 0.8867662828168624\n","Change of the performance: 0.0008814894422828345 0.0011662919542050343 \n","Change of cost:  7.650316354382292e-05\n","epoch 21\n","The cost at the end of this epoch is  0.19101587254300065\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   2.   0.   2.   3.   2.   5.   0.]\n"," [  0. 289.   5.   2.   1.   3.   0.   0.   6.   2.]\n"," [  5.   4. 238.   6.   2.   2.   8.   6.  15.   2.]\n"," [  2.   4.  19. 249.   1.  18.   0.   6.   4.   0.]\n"," [  1.   0.   1.   0. 300.   1.   6.   1.   3.   7.]\n"," [  5.   2.   2.  15.   1. 254.   4.   0.   7.   0.]\n"," [ 10.   3.   3.   0.   5.  10. 253.   0.   8.   0.]\n"," [  2.   6.   6.   2.   3.   0.   0. 264.   0.   9.]\n"," [  5.   7.   6.   8.   1.  15.   2.   2. 271.   7.]\n"," [  1.   0.   0.   0.  11.   2.   0.  11.   1. 239.]]\n","Accuracy Macro 0.8861529503807892 Precision Macro 0.8864967581455192\n","Change of the performance: 0.0005012294472959145 0.0002695246713432242 \n","Change of cost:  0.0003612401973886181\n","epoch 22\n","The cost at the end of this epoch is  0.190342097012195\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   2.   0.   2.   3.   2.   4.   0.]\n"," [  0. 289.   5.   2.   1.   3.   0.   0.   6.   2.]\n"," [  5.   4. 239.   6.   2.   2.   7.   6.  15.   2.]\n"," [  2.   4.  18. 251.   1.  16.   0.   6.   4.   1.]\n"," [  1.   0.   1.   0. 300.   1.   5.   1.   4.   7.]\n"," [  5.   2.   2.  17.   1. 251.   4.   0.   7.   1.]\n"," [ 10.   3.   4.   0.   5.  10. 253.   0.   7.   0.]\n"," [  1.   5.   5.   3.   3.   0.   0. 266.   0.   9.]\n"," [  5.   7.   7.   8.   2.  13.   2.   2. 271.   7.]\n"," [  1.   0.   0.   0.   9.   2.   0.   9.   1. 243.]]\n","Accuracy Macro 0.8886345867289098 Precision Macro 0.8886412941987955\n","Change of the performance: 0.002481636348120597 0.002144536053276247 \n","Change of cost:  0.00010470250258642899\n","epoch 23\n","The cost at the end of this epoch is  0.18987033454031058\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   2.   0.   2.   3.   2.   4.   0.]\n"," [  0. 289.   5.   2.   1.   2.   0.   0.   7.   2.]\n"," [  5.   4. 239.   6.   2.   2.   7.   6.  15.   2.]\n"," [  2.   4.  19. 250.   1.  16.   0.   6.   4.   1.]\n"," [  1.   0.   1.   0. 299.   1.   6.   1.   4.   7.]\n"," [  5.   2.   2.  16.   1. 250.   4.   0.   9.   1.]\n"," [ 10.   3.   3.   0.   5.   9. 255.   0.   7.   0.]\n"," [  1.   5.   5.   3.   4.   0.   0. 264.   0.  10.]\n"," [  5.   7.   8.   8.   2.  14.   2.   2. 269.   7.]\n"," [  1.   0.   0.   0.   9.   2.   0.   7.   1. 245.]]\n","Accuracy Macro 0.8877846591699173 Precision Macro 0.8876708969468122\n","Change of the performance: 0.0008499275589924915 0.0009703972519832238 \n","Change of cost:  0.00012792825540333674\n","epoch 24\n","The cost at the end of this epoch is  0.18955605178755638\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   2.   0.   2.   3.   2.   4.   0.]\n"," [  0. 289.   5.   2.   1.   2.   0.   0.   7.   2.]\n"," [  5.   4. 239.   6.   2.   2.   7.   6.  15.   2.]\n"," [  2.   4.  19. 250.   1.  16.   0.   6.   4.   1.]\n"," [  1.   0.   1.   0. 299.   1.   6.   1.   4.   7.]\n"," [  5.   2.   2.  16.   1. 251.   4.   0.   8.   1.]\n"," [ 10.   3.   3.   0.   5.  10. 254.   0.   7.   0.]\n"," [  1.   5.   5.   3.   3.   0.   0. 265.   0.  10.]\n"," [  5.   8.   8.   8.   2.  13.   2.   2. 269.   7.]\n"," [  1.   0.   0.   0.   9.   2.   0.   8.   1. 244.]]\n","Accuracy Macro 0.8877521282655583 Precision Macro 0.8876258638633596\n","Change of the performance: 3.2530904359062696e-05 4.5033083452605815e-05 \n","Change of cost:  7.1905737279776e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_9_100x785_10x101\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [150  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (150, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 151)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 150)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.271366014982534\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   1.   4.   0.   5.   6.   2.   4.   0.]\n"," [  0. 290.   3.   5.   1.   1.   0.   1.   6.   1.]\n"," [  4.   2. 247.  10.   2.   1.   6.   5.  10.   1.]\n"," [  1.   3.  18. 264.   1.   8.   0.   6.   2.   0.]\n"," [  0.   0.   1.   0. 303.   1.   8.   5.   2.   0.]\n"," [  5.   1.   1.  32.   2. 234.   4.   0.  11.   0.]\n"," [  6.   3.   4.   0.   2.   7. 265.   0.   5.   0.]\n"," [  2.   3.   7.   4.   2.   0.   0. 271.   0.   3.]\n"," [  4.   8.  15.  20.   2.  15.   6.   3. 249.   2.]\n"," [  1.   0.   0.   6.  26.   0.   0.  18.   1. 213.]]\n","Accuracy Macro 0.8762982162727575 Precision Macro 0.8805598177181432\n","epoch 1\n","The cost at the end of this epoch is  0.23981343509046976\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   4.   1.   5.   4.   2.   2.   0.]\n"," [  0. 295.   3.   1.   0.   2.   0.   2.   4.   1.]\n"," [  4.   6. 243.  10.   1.   2.   6.   9.   6.   1.]\n"," [  2.   7.  19. 256.   1.  11.   0.   6.   1.   0.]\n"," [  0.   1.   1.   0. 308.   1.   3.   3.   3.   0.]\n"," [  5.   2.   1.  20.   2. 250.   3.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.  11. 256.   0.   6.   0.]\n"," [  1.   6.   4.   1.   2.   0.   0. 274.   0.   4.]\n"," [  5.  11.  13.  12.   1.  23.   2.   3. 251.   3.]\n"," [  1.   0.   0.   1.  25.   2.   0.  11.   1. 224.]]\n","Accuracy Macro 0.8849434758216688 Precision Macro 0.887436553844591\n","epoch 2\n","The cost at the end of this epoch is  0.2281433797904108\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   2.   1.   1.   5.   2.   1.   4.   0.]\n"," [  0. 290.   6.   0.   1.   2.   0.   0.   7.   2.]\n"," [  5.   3. 247.   5.   1.   1.   7.   5.  12.   2.]\n"," [  2.   7.  20. 251.   0.  12.   0.   6.   4.   1.]\n"," [  3.   1.   1.   0. 275.   1.   5.   1.   4.  29.]\n"," [  4.   3.   2.  19.   2. 240.   3.   0.  17.   0.]\n"," [ 12.   3.   4.   0.   2.   5. 254.   0.   9.   3.]\n"," [  1.   7.   5.   1.   5.   0.   0. 260.   0.  13.]\n"," [  5.   8.   9.   5.   2.  15.   2.   2. 271.   5.]\n"," [  1.   0.   0.   0.   7.   2.   0.   6.   2. 247.]]\n","Accuracy Macro 0.8792996107606179 Precision Macro 0.8798517378159287\n","Change of the performance: 0.005643865061050857 0.0075848160286622335 \n","Change of cost:  0.029029452391456184\n","epoch 3\n","The cost at the end of this epoch is  0.22439800410128727\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   3.   1.   5.   3.   0.   4.   0.]\n"," [  0. 282.   3.   1.   0.   5.   0.   0.  15.   2.]\n"," [  5.   3. 217.  10.   2.   2.  13.   7.  25.   4.]\n"," [  2.   3.  10. 249.   0.  21.   0.   5.   9.   4.]\n"," [  1.   1.   0.   0. 297.   2.   5.   0.   5.   9.]\n"," [  4.   1.   1.  14.   0. 254.   3.   0.  13.   0.]\n"," [ 11.   2.   0.   0.   4.   8. 260.   0.   7.   0.]\n"," [  3.   6.   4.   3.   4.   0.   0. 261.   1.  10.]\n"," [  3.   2.   3.   7.   1.  24.   2.   1. 276.   5.]\n"," [  1.   0.   0.   0.   8.   2.   0.   8.   2. 244.]]\n","Accuracy Macro 0.8801364563756623 Precision Macro 0.8837715214651662\n","Change of the performance: 0.0008368456150443793 0.003919783649237507 \n","Change of cost:  0.012648978780099657\n","epoch 4\n","The cost at the end of this epoch is  0.20009284858529558\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   5.   3.   1.   3.   0.]\n"," [  0. 291.   2.   3.   0.   2.   0.   2.   7.   1.]\n"," [  5.   2. 238.  11.   2.   3.   7.   8.  11.   1.]\n"," [  2.   3.  16. 260.   0.  12.   0.   5.   4.   1.]\n"," [  1.   1.   1.   0. 299.   2.   5.   2.   5.   4.]\n"," [  5.   2.   1.  23.   0. 249.   4.   0.   6.   0.]\n"," [  9.   3.   2.   0.   3.  10. 261.   0.   4.   0.]\n"," [  2.   6.   4.   2.   3.   0.   0. 270.   0.   5.]\n"," [  3.   7.   8.  15.   1.  19.   2.   2. 262.   5.]\n"," [  1.   0.   0.   2.  12.   2.   0.  15.   2. 231.]]\n","Accuracy Macro 0.8867649701634379 Precision Macro 0.888015969109184\n","Change of the performance: 0.006628513787775625 0.004244447644017768 \n","Change of cost:  0.016054955948571092\n","epoch 5\n","The cost at the end of this epoch is  0.2007997726332748\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   1.   3.   0.   4.   4.   2.   6.   1.]\n"," [  0. 286.   5.   5.   0.   2.   0.   0.   8.   2.]\n"," [  4.   3. 246.   7.   2.   3.   7.   5.  10.   1.]\n"," [  2.   5.  19. 255.   1.  12.   0.   5.   4.   0.]\n"," [  0.   1.   1.   0. 306.   1.   3.   2.   4.   2.]\n"," [  4.   2.   2.  19.   0. 240.   4.   0.  19.   0.]\n"," [  7.   3.   6.   0.   4.   4. 258.   0.  10.   0.]\n"," [  3.   4.   5.   5.   4.   0.   0. 262.   0.   9.]\n"," [  3.   5.  10.   8.   1.  13.   2.   3. 274.   5.]\n"," [  1.   0.   0.   1.  15.   2.   0.  10.   2. 234.]]\n","Accuracy Macro 0.8851640522779858 Precision Macro 0.8868242067773927\n","Change of the performance: 0.0016009178854521355 0.0011917623317913018 \n","Change of cost:  0.008715529178587228\n","epoch 6\n","The cost at the end of this epoch is  0.1891633621627824\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   0.   6.   0.]\n"," [  0. 285.   2.   4.   0.   3.   0.   0.  12.   2.]\n"," [  5.   3. 232.  10.   2.   2.   7.   7.  18.   2.]\n"," [  2.   5.  15. 250.   0.  18.   0.   5.   6.   2.]\n"," [  1.   1.   0.   0. 301.   1.   3.   1.   4.   8.]\n"," [  5.   2.   1.  16.   0. 247.   2.   0.  17.   0.]\n"," [ 10.   2.   2.   0.   5.   7. 257.   0.   9.   0.]\n"," [  2.   7.   5.   1.   4.   0.   0. 262.   0.  11.]\n"," [  4.   4.   4.   7.   0.  14.   2.   1. 283.   5.]\n"," [  1.   0.   0.   0.  10.   2.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8855140770226815 Precision Macro 0.8879752140539459\n","Change of the performance: 0.00035002474469569833 0.001151007276553151 \n","Change of cost:  0.007889830289404598\n","epoch 7\n","The cost at the end of this epoch is  0.1847268639377375\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   0.   4.   3.   0.   5.   0.]\n"," [  0. 281.   6.   2.   0.   3.   1.   0.  13.   2.]\n"," [  5.   1. 241.   6.   2.   2.   7.   5.  17.   2.]\n"," [  2.   4.  17. 246.   0.  19.   0.   6.   7.   2.]\n"," [  2.   1.   1.   0. 299.   0.   4.   1.   4.   8.]\n"," [  6.   2.   1.  14.   1. 246.   4.   0.  16.   0.]\n"," [ 10.   1.   2.   0.   5.   8. 258.   0.   8.   0.]\n"," [  3.   6.   5.   2.   4.   0.   0. 260.   0.  12.]\n"," [  4.   2.   7.   7.   1.  12.   2.   1. 281.   7.]\n"," [  1.   0.   0.   0.  10.   2.   0.  11.   2. 239.]]\n","Accuracy Macro 0.8836504148482032 Precision Macro 0.885525534668789\n","Change of the performance: 0.0018636621744783088 0.0024496793851568333 \n","Change of cost:  0.0017563958256243128\n","epoch 8\n","The cost at the end of this epoch is  0.17222513561333586\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   2.   1.   5.   2.   1.   4.   0.]\n"," [  0. 290.   5.   1.   1.   3.   0.   0.   6.   2.]\n"," [  4.   1. 241.   9.   2.   2.   7.   8.  12.   2.]\n"," [  2.   4.  18. 254.   0.  12.   0.   6.   5.   2.]\n"," [  2.   1.   1.   0. 301.   0.   3.   1.   4.   7.]\n"," [  5.   2.   1.  16.   1. 249.   5.   0.  11.   0.]\n"," [ 10.   3.   3.   0.   5.  10. 254.   0.   7.   0.]\n"," [  2.   6.   4.   1.   4.   0.   0. 266.   0.   9.]\n"," [  4.   4.  10.   6.   2.  10.   2.   2. 277.   7.]\n"," [  1.   0.   0.   0.   9.   2.   0.   9.   2. 242.]]\n","Accuracy Macro 0.8914546786326172 Precision Macro 0.8918494841058164\n","Change of the performance: 0.007804263784414012 0.00632394943702741 \n","Change of cost:  0.0076707594657879075\n","epoch 9\n","The cost at the end of this epoch is  0.17514069019650996\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   0.   4.   4.   0.   3.   0.]\n"," [  0. 290.   3.   4.   1.   3.   0.   0.   5.   2.]\n"," [  4.   2. 242.   9.   2.   3.   7.   4.  13.   2.]\n"," [  2.   5.  16. 255.   0.  15.   1.   5.   3.   1.]\n"," [  2.   0.   1.   0. 297.   0.  10.   1.   4.   5.]\n"," [  6.   3.   1.  13.   1. 257.   3.   0.   6.   0.]\n"," [  9.   3.   1.   0.   3.  11. 261.   0.   4.   0.]\n"," [  2.   6.   6.   2.   5.   0.   0. 260.   0.  11.]\n"," [  4.   8.   7.   7.   2.  23.   3.   2. 262.   6.]\n"," [  1.   0.   0.   0.  11.   2.   0.  11.   2. 238.]]\n","Accuracy Macro 0.8881584221181308 Precision Macro 0.8883588500233456\n","Change of the performance: 0.0032962565144863953 0.003490634082470856 \n","Change of cost:  0.00017776171329414447\n","epoch 10\n","The cost at the end of this epoch is  0.16697587510531148\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   0.   4.   3.   1.   3.   0.]\n"," [  0. 289.   4.   4.   0.   2.   0.   0.   7.   2.]\n"," [  4.   2. 244.   9.   1.   2.   7.   4.  13.   2.]\n"," [  2.   4.  18. 256.   0.  12.   0.   5.   5.   1.]\n"," [  2.   0.   2.   0. 295.   0.   7.   1.   4.   9.]\n"," [  6.   3.   2.  16.   0. 249.   3.   0.   9.   2.]\n"," [ 11.   3.   3.   0.   3.   8. 259.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 265.   0.   9.]\n"," [  5.   8.   9.   6.   2.  13.   2.   2. 268.   9.]\n"," [  1.   0.   0.   0.   8.   2.   0.   9.   2. 243.]]\n","Accuracy Macro 0.890240645116501 Precision Macro 0.8899927567746608\n","Change of the performance: 0.0020822229983702423 0.0016339067513152505 \n","Change of cost:  0.0007174456759287129\n","epoch 11\n","The cost at the end of this epoch is  0.16948413064226192\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   2.   1.   5.   2.   1.   4.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   6.   2.]\n"," [  5.   2. 243.   9.   1.   2.   7.   6.  11.   2.]\n"," [  2.  10.  17. 250.   0.  13.   0.   5.   4.   2.]\n"," [  2.   1.   1.   0. 303.   0.   3.   1.   5.   4.]\n"," [  5.   3.   2.  17.   0. 251.   3.   0.   9.   0.]\n"," [ 10.   3.   4.   0.   4.   8. 257.   0.   6.   0.]\n"," [  2.   7.   4.   1.   4.   0.   0. 263.   1.  10.]\n"," [  4.   9.   8.   7.   0.  18.   2.   2. 266.   8.]\n"," [  1.   0.   0.   1.  11.   2.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8883287527672925 Precision Macro 0.888654134729794\n","Change of the performance: 0.0019118923492085216 0.0013386220448667885 \n","Change of cost:  0.004506162850078044\n","epoch 12\n","The cost at the end of this epoch is  0.16005523061973348\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   0.   4.   3.   1.   5.   0.]\n"," [  0. 290.   4.   3.   0.   2.   0.   0.   7.   2.]\n"," [  4.   1. 242.  10.   1.   3.   7.   5.  13.   2.]\n"," [  2.   4.  16. 254.   0.  15.   0.   5.   4.   3.]\n"," [  2.   0.   0.   0. 301.   0.   5.   1.   4.   7.]\n"," [  6.   3.   1.  15.   0. 255.   3.   0.   7.   0.]\n"," [ 10.   3.   2.   0.   4.   8. 259.   0.   6.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 264.   0.  10.]\n"," [  4.   7.   6.   7.   1.  15.   2.   2. 271.   9.]\n"," [  1.   0.   0.   0.   9.   2.   0.   8.   2. 243.]]\n","Accuracy Macro 0.8931093048622639 Precision Macro 0.8931748245349125\n","Change of the performance: 0.004780552094971413 0.0045206898051184385 \n","Change of cost:  0.0006897918546091841\n","epoch 13\n","The cost at the end of this epoch is  0.1595652111297473\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   0.   4.   3.   1.   4.   0.]\n"," [  0. 291.   4.   3.   0.   2.   0.   0.   6.   2.]\n"," [  4.   2. 242.  10.   2.   3.   7.   5.  11.   2.]\n"," [  2.   5.  16. 253.   0.  16.   0.   5.   4.   2.]\n"," [  2.   0.   0.   0. 301.   1.   6.   1.   4.   5.]\n"," [  6.   3.   1.  14.   1. 256.   3.   0.   6.   0.]\n"," [ 10.   3.   3.   0.   4.   9. 258.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 265.   0.   9.]\n"," [  5.   8.   7.   7.   2.  16.   2.   2. 266.   9.]\n"," [  1.   0.   0.   0.  10.   2.   0.  10.   2. 240.]]\n","Accuracy Macro 0.8910879548304095 Precision Macro 0.8911235092039387\n","Change of the performance: 0.002021350031854441 0.002051315330973802 \n","Change of cost:  0.00016572149552340765\n","epoch 14\n","The cost at the end of this epoch is  0.15741850420862594\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   2.   1.   5.   2.   1.   5.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   0.   7.   2.]\n"," [  4.   1. 243.   9.   2.   3.   7.   5.  12.   2.]\n"," [  2.   5.  19. 246.   0.  18.   0.   5.   6.   2.]\n"," [  2.   0.   0.   0. 302.   0.   5.   1.   4.   6.]\n"," [  6.   3.   1.  14.   0. 256.   4.   0.   6.   0.]\n"," [ 10.   3.   3.   0.   4.   9. 258.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 264.   0.  10.]\n"," [  4.   8.   8.   6.   1.  17.   2.   2. 267.   9.]\n"," [  1.   0.   0.   0.   9.   2.   0.   8.   2. 243.]]\n","Accuracy Macro 0.8898965569896312 Precision Macro 0.8899640264851051\n","Change of the performance: 0.0011913978407782633 0.0011594827188335932 \n","Change of cost:  4.721593158599213e-05\n","epoch 15\n","The cost at the end of this epoch is  0.15650479774230605\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   2.   1.   4.   0.]\n"," [  0. 289.   4.   4.   0.   2.   0.   0.   7.   2.]\n"," [  4.   2. 242.   9.   2.   3.   7.   5.  12.   2.]\n"," [  2.   3.  17. 255.   0.  13.   0.   5.   6.   2.]\n"," [  2.   0.   0.   0. 303.   0.   5.   1.   4.   5.]\n"," [  6.   3.   1.  16.   0. 253.   4.   0.   7.   0.]\n"," [ 10.   3.   3.   0.   4.   8. 258.   0.   6.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 265.   0.   9.]\n"," [  5.   6.   8.   6.   2.  14.   2.   2. 270.   9.]\n"," [  1.   0.   0.   0.  11.   2.   0.  10.   2. 239.]]\n","Accuracy Macro 0.8915463968397074 Precision Macro 0.8917785732543827\n","Change of the performance: 0.0016498398500761624 0.001814546769277614 \n","Change of cost:  9.671150350026858e-06\n","epoch 16\n","The cost at the end of this epoch is  0.1557923669176381\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 291.   4.   3.   0.   2.   0.   0.   6.   2.]\n"," [  4.   2. 241.   9.   2.   3.   7.   6.  12.   2.]\n"," [  2.   3.  18. 255.   0.  14.   0.   5.   5.   1.]\n"," [  2.   1.   1.   0. 302.   0.   4.   1.   4.   5.]\n"," [  6.   3.   1.  16.   0. 254.   4.   0.   6.   0.]\n"," [ 11.   3.   3.   0.   4.   9. 257.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 265.   0.   9.]\n"," [  5.   9.   9.   8.   1.  13.   2.   2. 265.  10.]\n"," [  1.   0.   0.   0.   9.   2.   0.   9.   2. 242.]]\n","Accuracy Macro 0.8908127872859678 Precision Macro 0.8907168777857019\n","Change of the performance: 0.0007336095537395781 0.0010616954686808455 \n","Change of cost:  0.0003420513767659894\n","epoch 17\n","The cost at the end of this epoch is  0.15464121422634935\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 289.   4.   3.   0.   3.   0.   0.   7.   2.]\n"," [  4.   1. 242.   9.   2.   3.   7.   6.  12.   2.]\n"," [  2.   3.  17. 252.   0.  16.   0.   5.   6.   2.]\n"," [  2.   0.   0.   0. 303.   0.   4.   1.   4.   6.]\n"," [  6.   3.   1.  14.   0. 256.   4.   0.   6.   0.]\n"," [ 11.   3.   3.   0.   4.  10. 256.   0.   5.   0.]\n"," [  2.   6.   4.   1.   4.   0.   0. 266.   0.   9.]\n"," [  5.   6.   8.   6.   2.  14.   2.   2. 269.  10.]\n"," [  1.   0.   0.   0.  10.   2.   0.  10.   2. 240.]]\n","Accuracy Macro 0.8910025659414547 Precision Macro 0.8912233570027974\n","Change of the performance: 0.0001897786554868608 0.0005064792170955679 \n","Change of cost:  0.00019331906200834026\n","epoch 18\n","The cost at the end of this epoch is  0.1540636410144265\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 291.   4.   4.   0.   1.   0.   0.   6.   2.]\n"," [  4.   2. 243.   9.   2.   3.   7.   5.  11.   2.]\n"," [  2.   4.  18. 250.   0.  17.   0.   5.   5.   2.]\n"," [  2.   0.   0.   0. 302.   1.   5.   1.   4.   5.]\n"," [  5.   3.   1.  15.   0. 255.   4.   0.   7.   0.]\n"," [ 10.   3.   4.   0.   4.   9. 258.   0.   4.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 264.   0.  10.]\n"," [  4.   9.  10.   6.   2.  14.   2.   2. 266.   9.]\n"," [  1.   0.   0.   0.  10.   2.   0.   9.   2. 241.]]\n","Accuracy Macro 0.89013317778486 Precision Macro 0.8899989073413181\n","Change of the performance: 0.0008693881565946526 0.0012244496614792766 \n","Change of cost:  0.0002582692290799826\n","epoch 19\n","The cost at the end of this epoch is  0.15321231680123334\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 290.   5.   2.   0.   2.   0.   0.   7.   2.]\n"," [  4.   3. 242.   9.   2.   3.   7.   5.  11.   2.]\n"," [  2.   4.  17. 252.   0.  17.   0.   5.   5.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   1.   4.   6.]\n"," [  5.   3.   1.  14.   0. 254.   4.   0.   8.   1.]\n"," [ 11.   3.   3.   0.   4.   9. 257.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 264.   0.  10.]\n"," [  5.   7.   9.   6.   2.  14.   2.   2. 267.  10.]\n"," [  1.   0.   0.   0.  10.   2.   0.  11.   2. 239.]]\n","Accuracy Macro 0.8889879778991083 Precision Macro 0.8890329039886081\n","Change of the performance: 0.0011451998857516799 0.0009660033527100209 \n","Change of cost:  3.502581718173303e-05\n","epoch 20\n","The cost at the end of this epoch is  0.1527376955729851\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 289.   4.   4.   0.   2.   0.   0.   7.   2.]\n"," [  4.   2. 243.   9.   2.   3.   7.   5.  11.   2.]\n"," [  2.   4.  17. 251.   0.  16.   0.   5.   6.   2.]\n"," [  2.   0.   0.   0. 303.   0.   4.   1.   4.   6.]\n"," [  6.   3.   1.  14.   0. 256.   4.   0.   6.   0.]\n"," [ 11.   3.   2.   0.   4.   9. 258.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 265.   0.   9.]\n"," [  5.   6.   8.   6.   2.  14.   2.   2. 269.  10.]\n"," [  1.   0.   0.   0.  10.   2.   0.  10.   2. 240.]]\n","Accuracy Macro 0.8913622209138014 Precision Macro 0.8914878771626675\n","Change of the performance: 0.0023742430146930227 0.002454973174059405 \n","Change of cost:  1.1980825968094244e-05\n","epoch 21\n","The cost at the end of this epoch is  0.1523608808764027\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   0.   7.   2.]\n"," [  4.   1. 243.   9.   2.   3.   7.   6.  11.   2.]\n"," [  2.   4.  17. 251.   0.  16.   0.   5.   6.   2.]\n"," [  2.   0.   0.   0. 303.   0.   4.   1.   4.   6.]\n"," [  5.   3.   1.  14.   0. 256.   4.   0.   7.   0.]\n"," [ 11.   3.   2.   0.   4.   9. 258.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 265.   0.   9.]\n"," [  5.   6.   8.   6.   2.  14.   2.   2. 269.  10.]\n"," [  1.   0.   0.   0.  10.   2.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8920642547290427 Precision Macro 0.8921825346924275\n","Change of the performance: 0.0007020338152413652 0.0006946575297599455 \n","Change of cost:  9.67884287382259e-05\n","epoch 22\n","The cost at the end of this epoch is  0.15203260649691724\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 290.   4.   4.   0.   1.   0.   0.   7.   2.]\n"," [  4.   2. 242.   9.   2.   3.   7.   5.  12.   2.]\n"," [  2.   4.  17. 252.   0.  16.   0.   5.   5.   2.]\n"," [  2.   1.   0.   0. 303.   0.   3.   1.   4.   6.]\n"," [  5.   3.   1.  14.   0. 255.   4.   0.   7.   1.]\n"," [ 11.   3.   3.   0.   4.   9. 257.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 265.   0.   9.]\n"," [  5.   6.   9.   7.   1.  13.   2.   2. 269.  10.]\n"," [  1.   0.   0.   0.   9.   2.   0.   9.   2. 242.]]\n","Accuracy Macro 0.8917371306610553 Precision Macro 0.8917659359047233\n","Change of the performance: 0.00032712406798740545 0.0004165987877041699 \n","Change of cost:  6.320522866137823e-05\n","epoch 23\n","The cost at the end of this epoch is  0.15181988128258897\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   0.   7.   2.]\n"," [  4.   2. 243.   9.   2.   3.   7.   5.  11.   2.]\n"," [  2.   4.  17. 250.   0.  17.   0.   5.   6.   2.]\n"," [  2.   0.   0.   0. 302.   0.   5.   1.   4.   6.]\n"," [  5.   3.   1.  14.   0. 255.   4.   0.   7.   1.]\n"," [ 11.   3.   3.   0.   4.   9. 257.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 264.   0.  10.]\n"," [  4.   6.   8.   6.   2.  13.   2.   2. 271.  10.]\n"," [  1.   0.   0.   0.  10.   2.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8910092465833033 Precision Macro 0.8911073807738958\n","Change of the performance: 0.000727884077752039 0.0006585551308274651 \n","Change of cost:  4.371315940887577e-05\n","epoch 24\n","The cost at the end of this epoch is  0.15155999689468205\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 291.   4.   3.   0.   1.   0.   0.   7.   2.]\n"," [  4.   3. 242.   9.   2.   3.   7.   5.  11.   2.]\n"," [  2.   4.  17. 251.   0.  17.   0.   5.   5.   2.]\n"," [  2.   0.   0.   0. 302.   0.   5.   1.   4.   6.]\n"," [  5.   3.   1.  14.   0. 255.   4.   0.   7.   1.]\n"," [ 11.   3.   3.   0.   4.   9. 257.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 264.   0.  10.]\n"," [  5.   6.   9.   7.   1.  13.   2.   2. 269.  10.]\n"," [  1.   0.   0.   0.  10.   2.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8906994487384395 Precision Macro 0.8906615368775104\n","Change of the performance: 0.00030979784486373507 0.0004458438963854672 \n","Change of cost:  0.00017659337181843981\n","epoch 25\n","The cost at the end of this epoch is  0.15140159291136107\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 291.   4.   3.   0.   1.   0.   0.   7.   2.]\n"," [  4.   2. 243.   9.   2.   3.   7.   5.  11.   2.]\n"," [  2.   4.  17. 251.   0.  17.   0.   5.   5.   2.]\n"," [  2.   0.   0.   0. 303.   0.   4.   1.   4.   6.]\n"," [  5.   3.   1.  14.   0. 255.   4.   0.   7.   1.]\n"," [ 11.   3.   3.   0.   4.   9. 257.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 264.   0.  10.]\n"," [  5.   6.   9.   7.   1.  13.   2.   2. 269.  10.]\n"," [  1.   0.   0.   0.  10.   2.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8913591709606619 Precision Macro 0.8913601493112452\n","Change of the performance: 0.0006597222222223253 0.0006986124337348132 \n","Change of cost:  1.5455239308737045e-05\n","epoch 26\n","The cost at the end of this epoch is  0.1512905640618812\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   2.   1.   5.   0.]\n"," [  0. 291.   4.   3.   0.   1.   0.   0.   7.   2.]\n"," [  4.   1. 243.   9.   2.   3.   7.   6.  11.   2.]\n"," [  2.   4.  17. 252.   0.  16.   0.   5.   5.   2.]\n"," [  2.   0.   0.   0. 303.   0.   4.   1.   4.   6.]\n"," [  5.   3.   1.  14.   0. 255.   4.   0.   7.   1.]\n"," [ 11.   3.   3.   0.   4.   9. 257.   0.   5.   0.]\n"," [  2.   6.   4.   2.   4.   0.   0. 264.   0.  10.]\n"," [  5.   6.   9.   7.   1.  14.   2.   2. 268.  10.]\n"," [  1.   0.   0.   0.  10.   2.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8913805619886535 Precision Macro 0.8913337938408439\n","Change of the performance: 2.139102799159076e-05 2.6355470401306924e-05 \n","Change of cost:  1.1569329595451094e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_10_150x785_10x151\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [200  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (200, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 201)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 200)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.20820649701585872\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   0.   8.   2.   1.   4.   1.]\n"," [  0. 285.   4.   3.   1.   2.   1.   5.   6.   1.]\n"," [  4.   3. 232.  11.   3.   4.   6.  10.  14.   1.]\n"," [  2.   5.  11. 261.   0.  13.   0.   7.   1.   3.]\n"," [  1.   0.   1.   0. 301.   3.   3.   2.   2.   7.]\n"," [  5.   3.   1.  20.   1. 249.   4.   0.   7.   0.]\n"," [ 11.   3.   2.   0.   5.  14. 252.   0.   5.   0.]\n"," [  2.   1.   4.   2.   3.   0.   0. 269.   0.  11.]\n"," [  4.   7.   5.  15.   5.  24.   2.   1. 242.  19.]\n"," [  1.   0.   0.   2.   9.   2.   0.  14.   0. 237.]]\n","Accuracy Macro 0.8757263409707198 Precision Macro 0.8762574113907936\n","epoch 1\n","The cost at the end of this epoch is  0.17441959492983522\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   0.   6.   3.   1.   4.   0.]\n"," [  0. 291.   2.   3.   0.   3.   0.   2.   6.   1.]\n"," [  5.   3. 235.  10.   2.   2.   7.   8.  14.   2.]\n"," [  2.   4.  15. 254.   1.  17.   0.   5.   5.   0.]\n"," [  1.   0.   1.   0. 305.   1.   4.   3.   3.   2.]\n"," [  5.   2.   2.  16.   0. 256.   1.   0.   8.   0.]\n"," [  7.   3.   3.   0.   6.  12. 255.   0.   6.   0.]\n"," [  3.   6.   4.   2.   4.   0.   0. 268.   0.   5.]\n"," [  3.   7.   8.   7.   2.  20.   2.   3. 268.   4.]\n"," [  1.   0.   0.   1.  16.   2.   0.  13.   2. 230.]]\n","Accuracy Macro 0.8861377350966959 Precision Macro 0.8883101284119231\n","epoch 2\n","The cost at the end of this epoch is  0.21903585142527454\n","Now let's test the model after this epoch:\n","Confusion array  [[306.   0.   1.   3.   1.   2.   2.   2.   1.   0.]\n"," [  0. 294.   2.   4.   0.   1.   0.   2.   4.   1.]\n"," [  6.   5. 237.   9.   1.   2.   7.  11.   8.   2.]\n"," [  1.   8.  16. 261.   0.   5.   1.   7.   2.   2.]\n"," [  2.   1.   1.   0. 300.   0.   3.   4.   4.   5.]\n"," [  5.   3.   1.  28.   1. 238.   7.   0.   7.   0.]\n"," [  9.   4.   4.   0.   5.   5. 258.   0.   7.   0.]\n"," [  2.   4.   4.   2.   2.   0.   0. 271.   0.   7.]\n"," [  6.  16.   9.  12.   2.  13.   2.   4. 251.   9.]\n"," [  1.   0.   0.   2.   9.   1.   0.  14.   1. 237.]]\n","Accuracy Macro 0.8839976882224431 Precision Macro 0.8847393355638445\n","Change of the performance: 0.0021400468742528433 0.0035707928480785966 \n","Change of cost:  0.00504390385445333\n","epoch 3\n","The cost at the end of this epoch is  0.1798690853331762\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   0.   4.   4.   0.   4.   0.]\n"," [  0. 284.   2.   4.   0.   4.   0.   2.  11.   1.]\n"," [  5.   1. 230.  12.   2.   6.   8.   7.  16.   1.]\n"," [  2.   1.  16. 248.   0.  22.   0.   5.   7.   2.]\n"," [  2.   0.   1.   0. 294.   0.   5.   4.   5.   9.]\n"," [  6.   2.   1.  17.   0. 251.   4.   0.   9.   0.]\n"," [ 10.   1.   2.   0.   4.   9. 262.   0.   4.   0.]\n"," [  3.   5.   5.   2.   2.   0.   0. 271.   0.   4.]\n"," [  4.   4.   7.  10.   1.  17.   2.   2. 274.   3.]\n"," [  1.   0.   0.   0.   8.   2.   0.  17.   3. 234.]]\n","Accuracy Macro 0.8827164003367989 Precision Macro 0.8845689095912193\n","Change of the performance: 0.001281287885644189 0.0001704259726252877 \n","Change of cost:  0.0073060658251879185\n","epoch 4\n","The cost at the end of this epoch is  0.1880913099235515\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   3.   3.   0.   5.   5.   0.   4.   0.]\n"," [  0. 285.   6.   1.   1.   3.   0.   0.  10.   2.]\n"," [  4.   1. 239.   6.   1.   3.   8.   5.  19.   2.]\n"," [  1.   3.  22. 246.   0.  16.   0.   6.   7.   2.]\n"," [  2.   0.   1.   0. 293.   0.   5.   2.   4.  13.]\n"," [  6.   3.   1.  18.   2. 241.   3.   0.  16.   0.]\n"," [ 10.   2.   3.   0.   4.   5. 258.   0.  10.   0.]\n"," [  3.   4.   6.   3.   6.   0.   0. 259.   0.  11.]\n"," [  3.   3.   8.   5.   4.  10.   2.   1. 280.   8.]\n"," [  1.   0.   0.   0.   7.   1.   0.   8.   2. 246.]]\n","Accuracy Macro 0.8813880738414342 Precision Macro 0.8826195060988734\n","Change of the performance: 0.001328326495364629 0.001949403492345847 \n","Change of cost:  0.021099779497571608\n","epoch 5\n","The cost at the end of this epoch is  0.15312395235944243\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   1.   4.   0.]\n"," [  0. 288.   4.   3.   1.   2.   0.   0.   8.   2.]\n"," [  4.   2. 237.   9.   2.   2.   7.   7.  16.   2.]\n"," [  2.   6.  16. 250.   0.  14.   1.   6.   5.   3.]\n"," [  2.   0.   0.   0. 300.   0.   7.   2.   4.   5.]\n"," [  6.   3.   1.  15.   1. 252.   3.   0.   9.   0.]\n"," [  8.   3.   2.   0.   5.   8. 261.   0.   5.   0.]\n"," [  2.   5.   5.   3.   4.   0.   0. 267.   0.   6.]\n"," [  5.   5.   8.   6.   3.  13.   2.   1. 275.   6.]\n"," [  1.   0.   0.   0.  12.   2.   0.  13.   2. 235.]]\n","Accuracy Macro 0.8879847570738099 Precision Macro 0.8886551365560635\n","Change of the performance: 0.006596683232375611 0.006035630457190133 \n","Change of cost:  0.02842496764300506\n","epoch 6\n","The cost at the end of this epoch is  0.14903224612822144\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   3.   1.   4.   0.]\n"," [  0. 292.   4.   3.   0.   1.   0.   0.   6.   2.]\n"," [  4.   2. 241.   8.   2.   2.   7.   9.  11.   2.]\n"," [  2.   4.  18. 249.   0.  17.   0.   6.   6.   1.]\n"," [  2.   0.   0.   0. 301.   0.   5.   2.   4.   6.]\n"," [  6.   3.   1.  16.   0. 252.   2.   0.  10.   0.]\n"," [  9.   3.   2.   0.   6.   9. 257.   0.   6.   0.]\n"," [  2.   6.   4.   2.   2.   0.   0. 267.   0.   9.]\n"," [  5.   5.   9.   7.   2.  15.   2.   2. 273.   4.]\n"," [  1.   0.   0.   0.  11.   2.   0.  12.   2. 237.]]\n","Accuracy Macro 0.8891079188661106 Precision Macro 0.889616212187839\n","Change of the performance: 0.0011231617923007642 0.0009610756317754987 \n","Change of cost:  0.0043432355587360305\n","epoch 7\n","The cost at the end of this epoch is  0.1614187419012648\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   6.   3.   0.   5.   0.]\n"," [  0. 287.   3.   2.   0.   5.   0.   0.   9.   2.]\n"," [  5.   1. 238.   9.   2.   4.   8.   4.  15.   2.]\n"," [  2.   3.  16. 247.   0.  21.   0.   5.   6.   3.]\n"," [  3.   0.   0.   0. 299.   0.   5.   1.   5.   7.]\n"," [  5.   3.   1.  16.   0. 251.   3.   0.  11.   0.]\n"," [  9.   3.   2.   0.   5.   9. 260.   0.   4.   0.]\n"," [  2.   8.   5.   2.   5.   0.   0. 255.   0.  15.]\n"," [  4.   4.   7.   6.   1.  17.   2.   1. 271.  11.]\n"," [  1.   0.   0.   0.   8.   2.   0.   5.   3. 246.]]\n","Accuracy Macro 0.8845097326669149 Precision Macro 0.8855177618155265\n","Change of the performance: 0.00459818619919572 0.00409845037231249 \n","Change of cost:  0.007339728868961087\n","epoch 8\n","The cost at the end of this epoch is  0.15058260082697092\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   4.   1.   3.   0.]\n"," [  0. 291.   5.   1.   0.   2.   0.   0.   7.   2.]\n"," [  5.   1. 246.   8.   2.   3.   7.   4.  10.   2.]\n"," [  2.   4.  19. 249.   0.  18.   0.   5.   5.   1.]\n"," [  2.   0.   0.   0. 303.   0.   5.   2.   3.   5.]\n"," [  5.   3.   1.  17.   1. 246.   4.   0.  13.   0.]\n"," [  8.   3.   2.   0.   5.   7. 262.   0.   5.   0.]\n"," [  2.   8.   5.   1.   5.   0.   0. 262.   0.   9.]\n"," [  4.   6.   9.   7.   2.  10.   2.   2. 276.   6.]\n"," [  1.   0.   0.   0.  13.   2.   0.   8.   2. 239.]]\n","Accuracy Macro 0.8907560320423631 Precision Macro 0.8911922283110953\n","Change of the performance: 0.006246299375448183 0.005674466495568797 \n","Change of cost:  0.0058387010808556294\n","epoch 9\n","The cost at the end of this epoch is  0.15413282864563124\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   2.   3.   1.   5.   5.   1.   5.   0.]\n"," [  0. 291.   4.   3.   0.   1.   1.   0.   6.   2.]\n"," [  5.   2. 244.   9.   2.   3.   7.   4.  10.   2.]\n"," [  2.   3.  17. 251.   1.  18.   0.   5.   6.   0.]\n"," [  1.   1.   0.   0. 303.   0.   5.   2.   4.   4.]\n"," [  6.   3.   1.  15.   0. 252.   3.   0.  10.   0.]\n"," [  7.   3.   2.   0.   5.   8. 263.   0.   4.   0.]\n"," [  2.   7.   5.   2.   6.   0.   0. 263.   1.   6.]\n"," [  4.   7.  10.   7.   1.  19.   2.   2. 268.   4.]\n"," [  1.   0.   0.   0.  15.   2.   0.  10.   4. 233.]]\n","Accuracy Macro 0.8874844022475245 Precision Macro 0.8885597233037374\n","Change of the performance: 0.0032716297948386375 0.0026325050073578993 \n","Change of cost:  0.007971647443644009\n","epoch 10\n","The cost at the end of this epoch is  0.14306729470598392\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   0.   4.   4.   0.   4.   0.]\n"," [  0. 292.   4.   3.   0.   1.   0.   0.   6.   2.]\n"," [  4.   2. 242.  10.   2.   4.   7.   5.  10.   2.]\n"," [  2.   4.  16. 248.   0.  19.   0.   6.   5.   3.]\n"," [  2.   0.   0.   0. 301.   0.   6.   2.   3.   6.]\n"," [  6.   3.   1.  17.   1. 250.   4.   0.   7.   1.]\n"," [  9.   3.   2.   0.   6.   9. 259.   0.   4.   0.]\n"," [  2.   6.   5.   2.   3.   0.   0. 265.   0.   9.]\n"," [  4.   5.   9.   7.   3.  15.   2.   1. 267.  11.]\n"," [  1.   0.   0.   0.   9.   2.   0.  10.   2. 241.]]\n","Accuracy Macro 0.8887219658406412 Precision Macro 0.8883244563346139\n","Change of the performance: 0.001237563593116775 0.00023526696912357092 \n","Change of cost:  0.00023604811257094127\n","epoch 11\n","The cost at the end of this epoch is  0.1421139572433196\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 292.   4.   3.   0.   2.   0.   0.   5.   2.]\n"," [  4.   2. 241.  10.   2.   4.   7.   6.  10.   2.]\n"," [  2.   6.  15. 250.   0.  19.   0.   5.   4.   2.]\n"," [  2.   0.   0.   0. 301.   0.   6.   2.   3.   6.]\n"," [  5.   3.   1.  17.   1. 251.   4.   0.   8.   0.]\n"," [ 10.   3.   2.   0.   5.   9. 259.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 263.   0.   9.]\n"," [  4.  10.   7.  10.   2.  21.   2.   2. 257.   9.]\n"," [  1.   0.   0.   0.  10.   2.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8859227513600956 Precision Macro 0.8858007401456037\n","Change of the performance: 0.002799214480545653 0.00252371618901015 \n","Change of cost:  0.0007755779641912541\n","epoch 12\n","The cost at the end of this epoch is  0.13999632692125938\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   6.   2.]\n"," [  4.   2. 241.  10.   2.   3.   7.   7.  10.   2.]\n"," [  2.   4.  18. 250.   0.  18.   0.   5.   5.   1.]\n"," [  2.   1.   0.   0. 303.   0.   4.   2.   3.   5.]\n"," [  6.   3.   1.  17.   1. 249.   5.   0.   8.   0.]\n"," [  9.   3.   2.   0.   6.   9. 258.   0.   5.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 264.   0.   8.]\n"," [  5.   7.   9.   8.   2.  15.   2.   2. 268.   6.]\n"," [  1.   0.   0.   0.  13.   2.   0.  11.   2. 236.]]\n","Accuracy Macro 0.8867374346456367 Precision Macro 0.887096444246043\n","Change of the performance: 0.000814683285541129 0.0012957041004392211 \n","Change of cost:  0.001127581194128452\n","epoch 13\n","The cost at the end of this epoch is  0.13918273872475276\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 291.   4.   3.   0.   1.   0.   0.   7.   2.]\n"," [  4.   2. 241.  10.   2.   3.   7.   7.  10.   2.]\n"," [  2.   5.  16. 253.   0.  14.   1.   5.   6.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  6.   3.   1.  17.   1. 248.   4.   0.   9.   1.]\n"," [ 11.   3.   2.   0.   6.   7. 258.   0.   5.   0.]\n"," [  2.   6.   5.   2.   5.   0.   0. 264.   0.   8.]\n"," [  4.   7.   9.   7.   3.  13.   2.   2. 270.   7.]\n"," [  1.   0.   0.   0.  10.   1.   0.  10.   2. 241.]]\n","Accuracy Macro 0.8892496071481031 Precision Macro 0.8892653227704995\n","Change of the performance: 0.002512172502466381 0.0021688785244565745 \n","Change of cost:  5.490842588282141e-05\n","epoch 14\n","The cost at the end of this epoch is  0.14084293841827075\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   3.   1.   4.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   5.   2.]\n"," [  4.   2. 243.  10.   2.   3.   7.   6.   9.   2.]\n"," [  2.   4.  17. 251.   0.  18.   0.   5.   5.   1.]\n"," [  2.   1.   1.   0. 302.   0.   4.   2.   3.   5.]\n"," [  6.   3.   2.  19.   1. 247.   4.   0.   8.   0.]\n"," [  9.   3.   3.   0.   6.  10. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   5.   0.   0. 264.   0.   7.]\n"," [  4.   9.  11.   8.   2.  19.   2.   2. 260.   7.]\n"," [  1.   0.   0.   1.  11.   2.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8850904407526423 Precision Macro 0.8852443908426479\n","Change of the performance: 0.004159166395460767 0.004020931927851579 \n","Change of cost:  0.0031512650941112608\n","epoch 15\n","The cost at the end of this epoch is  0.13714267902609742\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   1.   4.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   0.   7.   2.]\n"," [  5.   1. 241.  10.   2.   4.   7.   6.  10.   2.]\n"," [  2.   2.  17. 251.   0.  19.   0.   5.   6.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  6.   3.   1.  17.   1. 250.   4.   0.   8.   0.]\n"," [ 10.   3.   2.   0.   6.  10. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 263.   0.   9.]\n"," [  4.   6.   9.   7.   3.  17.   2.   2. 267.   7.]\n"," [  1.   0.   0.   0.  11.   2.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8869663050658996 Precision Macro 0.887295959494096\n","Change of the performance: 0.0018758643132572583 0.0020515686514480658 \n","Change of cost:  0.00018580790702305006\n","epoch 16\n","The cost at the end of this epoch is  0.13701218644544788\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   3.   1.   4.   0.]\n"," [  0. 291.   4.   3.   0.   1.   0.   0.   7.   2.]\n"," [  5.   2. 241.  10.   2.   3.   7.   6.  10.   2.]\n"," [  2.   4.  16. 255.   0.  15.   0.   5.   5.   1.]\n"," [  2.   1.   0.   0. 302.   0.   4.   2.   3.   6.]\n"," [  6.   3.   1.  18.   1. 248.   4.   0.   9.   0.]\n"," [ 10.   3.   2.   0.   6.  10. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 264.   0.   8.]\n"," [  4.   8.   9.   8.   2.  14.   2.   2. 269.   6.]\n"," [  1.   0.   0.   1.  10.   2.   0.  10.   3. 238.]]\n","Accuracy Macro 0.887812024545467 Precision Macro 0.8882076516598538\n","Change of the performance: 0.0008457194795674638 0.0009116921657578159 \n","Change of cost:  0.0009958889018887584\n","epoch 17\n","The cost at the end of this epoch is  0.13613743241562073\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   3.   1.   4.   0.]\n"," [  0. 290.   4.   3.   0.   2.   0.   0.   7.   2.]\n"," [  5.   2. 242.   9.   2.   3.   7.   6.  10.   2.]\n"," [  2.   5.  17. 253.   0.  15.   0.   5.   5.   1.]\n"," [  2.   1.   0.   0. 302.   0.   4.   2.   3.   6.]\n"," [  5.   3.   1.  18.   0. 248.   4.   0.  10.   1.]\n"," [ 11.   3.   2.   0.   6.   9. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 263.   0.   9.]\n"," [  3.   9.   9.   7.   2.  15.   2.   2. 269.   6.]\n"," [  1.   0.   0.   0.   9.   1.   0.  11.   3. 240.]]\n","Accuracy Macro 0.8875867566641208 Precision Macro 0.887731380512578\n","Change of the performance: 0.0002252678813462472 0.00047627114727577524 \n","Change of cost:  0.0008518227871326389\n","epoch 18\n","The cost at the end of this epoch is  0.1358546729419775\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   0.   4.   0.]\n"," [  0. 290.   4.   3.   0.   2.   0.   0.   7.   2.]\n"," [  5.   2. 240.   9.   2.   3.   7.   6.  12.   2.]\n"," [  2.   4.  17. 252.   0.  16.   0.   5.   6.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  5.   3.   1.  17.   1. 249.   4.   0.  10.   0.]\n"," [ 10.   2.   2.   0.   6.  10. 258.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 262.   0.  10.]\n"," [  3.   5.   8.   7.   3.  16.   2.   1. 272.   7.]\n"," [  1.   0.   0.   0.  12.   2.   0.  10.   3. 237.]]\n","Accuracy Macro 0.8873298880744208 Precision Macro 0.8878930502655663\n","Change of the performance: 0.0002568685896999767 0.00016166975298825825 \n","Change of cost:  0.00010042728805309542\n","epoch 19\n","The cost at the end of this epoch is  0.13510828339973338\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   0.   7.   2.]\n"," [  5.   2. 241.   9.   2.   3.   7.   6.  11.   2.]\n"," [  2.   4.  17. 249.   0.  19.   0.   5.   6.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  6.   3.   1.  17.   1. 249.   4.   0.   9.   0.]\n"," [ 10.   3.   2.   0.   6.  10. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 263.   0.   9.]\n"," [  4.   7.   9.   7.   3.  17.   2.   2. 266.   7.]\n"," [  1.   0.   0.   0.  11.   2.   0.   9.   3. 239.]]\n","Accuracy Macro 0.8855898764160223 Precision Macro 0.8859160769952842\n","Change of the performance: 0.0017400116583985437 0.001976973270282123 \n","Change of cost:  2.3778212333791515e-05\n","epoch 20\n","The cost at the end of this epoch is  0.1348692731406997\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   1.   4.   0.]\n"," [  0. 291.   4.   2.   0.   3.   0.   0.   6.   2.]\n"," [  5.   2. 240.  10.   2.   4.   7.   6.  10.   2.]\n"," [  2.   4.  16. 251.   0.  19.   0.   5.   5.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  6.   3.   1.  17.   0. 251.   4.   0.   8.   0.]\n"," [ 10.   3.   2.   0.   6.  10. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 263.   0.   9.]\n"," [  4.   9.   9.   7.   2.  17.   2.   2. 265.   7.]\n"," [  1.   0.   0.   0.   9.   1.   0.   9.   3. 242.]]\n","Accuracy Macro 0.8874260187850742 Precision Macro 0.887537884484976\n","Change of the performance: 0.0018361423690519407 0.0016218074896917622 \n","Change of cost:  2.713928175598901e-05\n","epoch 21\n","The cost at the end of this epoch is  0.13467832873984706\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   1.   4.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   0.   7.   2.]\n"," [  5.   2. 241.   9.   2.   3.   7.   6.  11.   2.]\n"," [  2.   5.  17. 250.   0.  17.   0.   5.   6.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  5.   3.   1.  17.   1. 249.   4.   0.  10.   0.]\n"," [ 10.   3.   2.   0.   6.   9. 258.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 262.   0.  10.]\n"," [  3.   6.   8.   7.   3.  15.   2.   2. 271.   7.]\n"," [  1.   0.   0.   0.  11.   2.   0.   9.   3. 239.]]\n","Accuracy Macro 0.887148653887061 Precision Macro 0.8874894188545888\n","Change of the performance: 0.0002773648980132215 4.846563038718443e-05 \n","Change of cost:  6.823950215598118e-05\n","epoch 22\n","The cost at the end of this epoch is  0.1344108397553542\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   0.   7.   2.]\n"," [  5.   2. 241.   9.   2.   3.   7.   6.  11.   2.]\n"," [  2.   4.  17. 253.   0.  16.   0.   5.   5.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  5.   3.   1.  17.   1. 249.   4.   0.  10.   0.]\n"," [ 10.   3.   2.   0.   6.  10. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 263.   0.   9.]\n"," [  4.   8.   9.   7.   3.  16.   2.   2. 266.   7.]\n"," [  1.   0.   0.   0.  10.   2.   0.  10.   3. 239.]]\n","Accuracy Macro 0.8865955430204187 Precision Macro 0.8867856164480669\n","Change of the performance: 0.0005531108666423368 0.0007038024065219028 \n","Change of cost:  2.9920810648259577e-05\n","epoch 23\n","The cost at the end of this epoch is  0.13425579590586026\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   0.   7.   2.]\n"," [  5.   2. 241.   9.   2.   4.   7.   6.  10.   2.]\n"," [  2.   4.  17. 252.   0.  17.   0.   5.   5.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  5.   3.   1.  17.   1. 249.   4.   0.  10.   0.]\n"," [ 10.   3.   2.   0.   6.  10. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 262.   0.  10.]\n"," [  4.   8.   9.   7.   3.  16.   2.   2. 266.   7.]\n"," [  1.   0.   0.   0.  11.   2.   0.   9.   3. 239.]]\n","Accuracy Macro 0.8859230442636935 Precision Macro 0.8861451876500672\n","Change of the performance: 0.0006724987567251484 0.000640428797999637 \n","Change of cost:  7.365138426085327e-06\n","epoch 24\n","The cost at the end of this epoch is  0.13414595935768406\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   0.   7.   2.]\n"," [  5.   2. 241.   9.   2.   4.   7.   6.  10.   2.]\n"," [  2.   4.  17. 252.   0.  17.   0.   5.   5.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  5.   3.   1.  17.   1. 250.   4.   0.   9.   0.]\n"," [ 10.   3.   2.   0.   6.  10. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 262.   0.  10.]\n"," [  4.   8.   9.   7.   3.  17.   2.   2. 265.   7.]\n"," [  1.   0.   0.   0.  11.   2.   0.   9.   3. 239.]]\n","Accuracy Macro 0.8859592298745917 Precision Macro 0.886169039319031\n","Change of the performance: 3.618561089824279e-05 2.3851668963792427e-05 \n","Change of cost:  1.4008520125591284e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_10_200x785_10x201\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [250  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (250, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 251)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 250)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.21959451730575885\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   3.   0.   5.   5.   0.   3.   0.]\n"," [  0. 272.   6.   1.   0.   4.   1.   1.  22.   1.]\n"," [  6.   0. 235.   6.   3.   6.  11.   5.  14.   2.]\n"," [  3.   1.  30. 232.   1.  22.   1.   6.   6.   1.]\n"," [  2.   0.   2.   0. 297.   0.   7.   1.   4.   7.]\n"," [  6.   1.   2.  12.   0. 255.   6.   0.   8.   0.]\n"," [  9.   1.   2.   0.   4.   8. 262.   0.   6.   0.]\n"," [  3.   3.  10.   1.   4.   0.   0. 263.   3.   5.]\n"," [  4.   2.   8.   5.   1.  14.   3.   1. 281.   5.]\n"," [  1.   0.   1.   1.   8.   1.   0.  15.   5. 233.]]\n","Accuracy Macro 0.8766360991530255 Precision Macro 0.8797970332553764\n","epoch 1\n","The cost at the end of this epoch is  0.30219529576312726\n","Now let's test the model after this epoch:\n","Confusion array  [[292.   0.   6.   3.   0.   7.   4.   2.   4.   0.]\n"," [  0. 279.   6.  13.   0.   5.   0.   0.   3.   2.]\n"," [  3.   2. 251.  15.   2.   2.   8.   0.   3.   2.]\n"," [  0.   0.  15. 271.   1.  13.   0.   3.   0.   0.]\n"," [  1.   1.   5.   1. 294.   4.   4.   3.   5.   2.]\n"," [  0.   1.   0.  23.   0. 258.   2.   0.   6.   0.]\n"," [  6.   2.   7.   0.   1.  15. 258.   0.   3.   0.]\n"," [  2.   6.  12.  12.   6.   1.   0. 238.   1.  14.]\n"," [  1.   6.  13.  33.   0.  45.   3.   1. 219.   3.]\n"," [  1.   0.   1.   4.   9.   4.   0.   4.   0. 242.]]\n","Accuracy Macro 0.868616914877235 Precision Macro 0.8762410338351513\n","epoch 2\n","The cost at the end of this epoch is  0.16894625374103434\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   2.   3.   1.   7.   2.   1.   5.   0.]\n"," [  0. 291.   7.   1.   0.   1.   1.   1.   6.   0.]\n"," [  5.   5. 243.   5.   2.   2.   7.   8.   9.   2.]\n"," [  1.   5.  23. 244.   0.  16.   1.   6.   5.   2.]\n"," [  2.   1.   1.   1. 295.   2.   6.   3.   6.   3.]\n"," [  3.   3.   2.  19.   0. 245.   2.   0.  15.   1.]\n"," [  8.   3.   3.   0.   5.   9. 259.   0.   5.   0.]\n"," [  2.   4.   5.   1.   1.   0.   0. 268.   4.   7.]\n"," [  5.   6.   9.   7.   1.  13.   2.   0. 274.   7.]\n"," [  1.   0.   0.   0.  12.   2.   0.   9.   3. 238.]]\n","Accuracy Macro 0.8843087313656633 Precision Macro 0.8850423641594158\n","Change of the performance: 0.015691816488428323 0.008801330324264556 \n","Change of cost:  0.05964444561081533\n","epoch 3\n","The cost at the end of this epoch is  0.1457517564947777\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   3.   0.   4.   5.   0.   4.   0.]\n"," [  0. 285.   4.   4.   0.   2.   1.   0.  10.   2.]\n"," [  5.   1. 235.   8.   2.   3.   9.   9.  14.   2.]\n"," [  2.   4.  17. 251.   0.  14.   1.   5.   6.   3.]\n"," [  1.   1.   0.   0. 303.   2.   4.   2.   3.   4.]\n"," [  6.   3.   1.  18.   0. 246.   5.   0.  11.   0.]\n"," [ 10.   2.   2.   0.   6.   6. 261.   0.   5.   0.]\n"," [  2.   8.   3.   0.   3.   0.   0. 264.   1.  11.]\n"," [  4.   4.   8.   6.   1.  15.   2.   1. 278.   5.]\n"," [  1.   0.   0.   0.  12.   2.   0.   9.   1. 240.]]\n","Accuracy Macro 0.8876146406686856 Precision Macro 0.8881765459361393\n","Change of the performance: 0.003305909303022214 0.0031341817767234215 \n","Change of cost:  0.0010187444042153437\n","epoch 4\n","The cost at the end of this epoch is  0.1589175198576708\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   0.   4.   4.   1.   3.   0.]\n"," [  0. 291.   4.   2.   0.   2.   1.   1.   6.   1.]\n"," [  5.   2. 241.   7.   2.   2.   7.  12.   9.   1.]\n"," [  2.   6.  19. 245.   1.  19.   0.   6.   4.   1.]\n"," [  1.   1.   0.   0. 303.   1.   5.   2.   5.   2.]\n"," [  6.   3.   2.  15.   0. 253.   4.   0.   7.   0.]\n"," [  7.   3.   3.   0.   6.   8. 260.   0.   5.   0.]\n"," [  2.   6.   4.   1.   1.   0.   0. 270.   2.   6.]\n"," [  5.   7.  10.   8.   2.  18.   2.   2. 268.   2.]\n"," [  1.   0.   0.   0.  17.   2.   0.  12.   2. 231.]]\n","Accuracy Macro 0.8873093036326594 Precision Macro 0.8886049413768238\n","Change of the performance: 0.00030533703602619866 0.00042839544068451474 \n","Change of cost:  0.00930890923915384\n","epoch 5\n","The cost at the end of this epoch is  0.13736242589572265\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   3.   3.   0.   4.   0.]\n"," [  0. 287.   4.   2.   0.   4.   0.   0.   9.   2.]\n"," [  5.   1. 241.   8.   2.   3.   7.   8.  11.   2.]\n"," [  2.   2.  20. 252.   0.  16.   0.   5.   5.   1.]\n"," [  2.   1.   0.   0. 302.   0.   4.   2.   4.   5.]\n"," [  6.   3.   2.  19.   0. 244.   4.   0.  12.   0.]\n"," [ 12.   2.   2.   0.   6.   6. 257.   0.   7.   0.]\n"," [  2.   7.   3.   2.   4.   0.   0. 262.   2.  10.]\n"," [  4.   5.   9.   5.   2.  13.   2.   0. 278.   6.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   3. 240.]]\n","Accuracy Macro 0.887934873370513 Precision Macro 0.8889616437671597\n","Change of the performance: 0.0006255697378536595 0.0003567023903359168 \n","Change of cost:  0.005553065238551397\n","epoch 6\n","The cost at the end of this epoch is  0.13272332857822025\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 290.   4.   1.   0.   4.   0.   0.   7.   2.]\n"," [  5.   2. 239.   9.   2.   3.   6.   8.  12.   2.]\n"," [  2.   6.  16. 249.   1.  21.   0.   5.   3.   0.]\n"," [  2.   0.   1.   0. 302.   0.   4.   2.   4.   5.]\n"," [  5.   3.   1.  16.   0. 253.   4.   0.   8.   0.]\n"," [ 10.   2.   2.   0.   6.   9. 257.   0.   6.   0.]\n"," [  2.   6.   4.   3.   5.   0.   0. 262.   1.   9.]\n"," [  4.   6.   7.   8.   2.  19.   2.   2. 270.   4.]\n"," [  1.   0.   0.   0.  12.   1.   0.   7.   2. 242.]]\n","Accuracy Macro 0.8886133853447185 Precision Macro 0.8894942662392943\n","Change of the performance: 0.0006785119742054313 0.0005326224721345918 \n","Change of cost:  0.0015921416443079317\n","epoch 7\n","The cost at the end of this epoch is  0.13268441918997873\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   0.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 291.   3.   3.   0.   2.   1.   0.   6.   2.]\n"," [  5.   2. 237.  10.   2.   4.   7.   9.  10.   2.]\n"," [  2.   4.  15. 260.   0.  13.   1.   5.   2.   1.]\n"," [  2.   1.   0.   0. 298.   0.   4.   2.   5.   8.]\n"," [  6.   3.   2.  21.   0. 245.   4.   0.   9.   0.]\n"," [ 11.   2.   2.   0.   6.   8. 258.   0.   5.   0.]\n"," [  2.   6.   5.   3.   2.   0.   0. 263.   0.  11.]\n"," [  4.   9.   7.   8.   1.  14.   2.   1. 271.   7.]\n"," [  1.   0.   0.   0.   9.   1.   0.   9.   1. 244.]]\n","Accuracy Macro 0.889928114443693 Precision Macro 0.8899285402490712\n","Change of the performance: 0.0013147290989745652 0.00043427400977691377 \n","Change of cost:  0.0017437747004082071\n","epoch 8\n","The cost at the end of this epoch is  0.12928232577665516\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 287.   5.   1.   0.   4.   0.   0.   9.   2.]\n"," [  5.   0. 244.   8.   2.   4.   8.   5.  10.   2.]\n"," [  2.   3.  19. 248.   0.  20.   0.   5.   5.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  6.   3.   2.  17.   0. 250.   4.   0.   8.   0.]\n"," [  8.   2.   3.   0.   5.   7. 261.   0.   6.   0.]\n"," [  2.   6.   5.   2.   3.   0.   0. 266.   0.   8.]\n"," [  4.   6.   9.   8.   2.  17.   2.   2. 268.   6.]\n"," [  1.   0.   0.   0.  13.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8886868559161595 Precision Macro 0.8888773543196337\n","Change of the performance: 0.0012412585275335397 0.001051185929437537 \n","Change of cost:  1.4780242997280979e-05\n","epoch 9\n","The cost at the end of this epoch is  0.12783233513374118\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 289.   4.   1.   0.   4.   0.   0.   8.   2.]\n"," [  5.   0. 239.   9.   2.   4.   7.   8.  12.   2.]\n"," [  2.   6.  16. 251.   0.  18.   0.   5.   4.   1.]\n"," [  2.   0.   0.   0. 302.   0.   5.   2.   3.   6.]\n"," [  6.   3.   2.  16.   1. 250.   4.   0.   8.   0.]\n"," [ 11.   2.   2.   0.   6.   7. 260.   0.   4.   0.]\n"," [  2.   5.   4.   3.   5.   0.   0. 264.   0.   9.]\n"," [  3.   6.   6.   8.   4.  16.   2.   1. 270.   8.]\n"," [  1.   0.   0.   0.  11.   1.   0.  10.   1. 241.]]\n","Accuracy Macro 0.8892492635445803 Precision Macro 0.8894693086896309\n","Change of the performance: 0.0005624076284208579 0.0005919543699972607 \n","Change of cost:  0.0002387508858448517\n","epoch 10\n","The cost at the end of this epoch is  0.12714653692166694\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   1.   4.   0.]\n"," [  0. 289.   4.   2.   0.   3.   0.   0.   8.   2.]\n"," [  5.   0. 239.   9.   2.   4.   7.   8.  12.   2.]\n"," [  2.   5.  16. 250.   1.  19.   0.   5.   5.   0.]\n"," [  2.   1.   0.   0. 301.   0.   4.   2.   4.   6.]\n"," [  6.   3.   2.  16.   1. 250.   4.   0.   8.   0.]\n"," [ 11.   2.   2.   0.   6.   6. 259.   0.   6.   0.]\n"," [  2.   6.   3.   3.   4.   0.   0. 264.   1.   9.]\n"," [  3.   5.   7.   8.   2.  17.   2.   1. 273.   6.]\n"," [  1.   0.   0.   0.  14.   1.   0.  10.   2. 237.]]\n","Accuracy Macro 0.8870518259339072 Precision Macro 0.8878841882167243\n","Change of the performance: 0.0021974376106731475 0.0015851204729065982 \n","Change of cost:  0.0007142543803274892\n","epoch 11\n","The cost at the end of this epoch is  0.12783311338681072\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 292.   3.   2.   0.   4.   0.   0.   5.   2.]\n"," [  5.   1. 243.   9.   2.   4.   7.   6.   9.   2.]\n"," [  2.   4.  15. 253.   1.  20.   0.   5.   2.   1.]\n"," [  2.   1.   0.   0. 302.   0.   4.   2.   4.   5.]\n"," [  5.   3.   2.  18.   0. 252.   4.   0.   6.   0.]\n"," [  8.   2.   2.   0.   6.  10. 260.   0.   4.   0.]\n"," [  2.   6.   5.   3.   3.   0.   0. 264.   0.   9.]\n"," [  5.  12.   6.  11.   1.  19.   2.   2. 259.   7.]\n"," [  1.   0.   0.   0.  14.   1.   0.  10.   1. 238.]]\n","Accuracy Macro 0.8884347623864166 Precision Macro 0.8888094389520363\n","Change of the performance: 0.00138293645250942 0.0009252507353120221 \n","Change of cost:  0.006695485822218433\n","epoch 12\n","The cost at the end of this epoch is  0.12331927450874466\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 289.   4.   1.   0.   4.   0.   0.   8.   2.]\n"," [  5.   0. 241.   9.   2.   4.   8.   8.   9.   2.]\n"," [  2.   5.  16. 251.   1.  19.   0.   5.   4.   0.]\n"," [  2.   1.   1.   0. 301.   0.   4.   2.   4.   5.]\n"," [  6.   3.   2.  16.   0. 251.   4.   0.   8.   0.]\n"," [  9.   2.   2.   0.   6.   9. 260.   0.   4.   0.]\n"," [  2.   6.   5.   3.   4.   0.   0. 261.   0.  11.]\n"," [  4.   6.   7.   9.   1.  18.   2.   2. 269.   6.]\n"," [  1.   0.   0.   0.  15.   1.   0.   8.   2. 238.]]\n","Accuracy Macro 0.887507920867951 Precision Macro 0.8880220219047704\n","Change of the performance: 0.0009268415184655598 0.0007874170472659259 \n","Change of cost:  0.0001624683342808242\n","epoch 13\n","The cost at the end of this epoch is  0.12391677565232596\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 291.   5.   2.   0.   1.   0.   0.   7.   2.]\n"," [  5.   1. 242.   9.   2.   4.   6.   7.  10.   2.]\n"," [  2.   5.  17. 252.   0.  16.   0.   5.   5.   1.]\n"," [  2.   1.   1.   0. 297.   0.   3.   2.   4.  10.]\n"," [  6.   3.   2.  16.   1. 248.   4.   0.   9.   1.]\n"," [ 11.   2.   2.   0.   6.   9. 257.   0.   5.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 261.   0.  11.]\n"," [  4.   7.   7.   9.   1.  16.   2.   2. 270.   6.]\n"," [  1.   0.   0.   0.  10.   1.   0.   9.   2. 242.]]\n","Accuracy Macro 0.8873407226615022 Precision Macro 0.88740584854454\n","Change of the performance: 0.00016719820644883754 0.0006161733602304542 \n","Change of cost:  0.0007857864879514537\n","epoch 14\n","The cost at the end of this epoch is  0.12210976554211095\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 292.   5.   1.   0.   2.   0.   0.   6.   2.]\n"," [  5.   1. 244.   9.   2.   4.   7.   5.   9.   2.]\n"," [  2.   5.  15. 253.   0.  18.   0.   5.   4.   1.]\n"," [  2.   1.   1.   0. 298.   0.   3.   2.   4.   9.]\n"," [  6.   3.   2.  16.   1. 250.   4.   0.   8.   0.]\n"," [ 11.   2.   2.   0.   6.   9. 258.   0.   4.   0.]\n"," [  2.   6.   5.   3.   4.   0.   0. 264.   0.   8.]\n"," [  5.  11.   7.   9.   1.  19.   2.   2. 261.   7.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   1. 243.]]\n","Accuracy Macro 0.888661474332823 Precision Macro 0.8886512110027693\n","Change of the performance: 0.0013207516713208411 0.001245362458229371 \n","Change of cost:  0.00027218015285292163\n","epoch 15\n","The cost at the end of this epoch is  0.12109199873123908\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 291.   5.   1.   0.   2.   0.   0.   7.   2.]\n"," [  5.   1. 243.   9.   2.   4.   6.   6.  10.   2.]\n"," [  2.   7.  16. 248.   1.  19.   0.   5.   5.   0.]\n"," [  2.   1.   1.   0. 301.   0.   3.   2.   4.   6.]\n"," [  6.   3.   2.  16.   1. 250.   4.   0.   8.   0.]\n"," [ 11.   2.   2.   0.   6.   9. 258.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 261.   0.  11.]\n"," [  4.   9.   7.   9.   1.  19.   2.   2. 264.   7.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   3. 239.]]\n","Accuracy Macro 0.8856660064728118 Precision Macro 0.8861021169428565\n","Change of the performance: 0.0029954678600112583 0.002549094059912882 \n","Change of cost:  0.0003070041760656339\n","epoch 16\n","The cost at the end of this epoch is  0.12185517198018571\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 293.   4.   3.   0.   2.   0.   0.   4.   2.]\n"," [  5.   1. 242.  10.   2.   4.   7.   6.   9.   2.]\n"," [  2.   6.  16. 253.   1.  16.   0.   5.   3.   1.]\n"," [  2.   1.   1.   0. 301.   0.   3.   2.   4.   6.]\n"," [  5.   3.   2.  16.   1. 252.   4.   0.   7.   0.]\n"," [ 11.   2.   2.   0.   6.   9. 258.   0.   4.   0.]\n"," [  2.   8.   5.   1.   4.   0.   0. 262.   0.  10.]\n"," [  4.  11.   5.  10.   1.  19.   2.   2. 263.   7.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   3. 239.]]\n","Accuracy Macro 0.8880273134581665 Precision Macro 0.8883221133946805\n","Change of the performance: 0.0023613069853547497 0.0022199964518240245 \n","Change of cost:  0.0008920506709442777\n","epoch 17\n","The cost at the end of this epoch is  0.1211796954933346\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 293.   4.   2.   0.   3.   0.   0.   4.   2.]\n"," [  5.   1. 242.  10.   2.   4.   7.   6.   9.   2.]\n"," [  2.   8.  16. 251.   1.  16.   0.   5.   3.   1.]\n"," [  2.   1.   1.   0. 300.   0.   3.   2.   4.   7.]\n"," [  6.   3.   2.  16.   1. 250.   4.   0.   7.   1.]\n"," [ 11.   2.   2.   0.   6.   9. 258.   0.   4.   0.]\n"," [  2.   8.   5.   1.   4.   0.   0. 262.   0.  10.]\n"," [  4.  11.   6.  10.   1.  19.   2.   2. 262.   7.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   3. 239.]]\n","Accuracy Macro 0.8860564503038434 Precision Macro 0.8862625247543597\n","Change of the performance: 0.0019708631543231547 0.002059588640320742 \n","Change of cost:  0.0007596350213852632\n","epoch 18\n","The cost at the end of this epoch is  0.12008031055258594\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 291.   4.   1.   0.   3.   0.   0.   7.   2.]\n"," [  5.   1. 243.   9.   2.   4.   7.   6.   9.   2.]\n"," [  2.   7.  15. 250.   1.  19.   0.   5.   4.   0.]\n"," [  2.   1.   0.   0. 300.   0.   4.   2.   4.   7.]\n"," [  6.   3.   2.  16.   1. 249.   4.   0.   8.   1.]\n"," [ 11.   2.   2.   0.   6.   8. 259.   0.   4.   0.]\n"," [  2.   8.   5.   1.   4.   0.   0. 261.   0.  11.]\n"," [  4.  10.   6.   9.   1.  19.   2.   2. 264.   7.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8863885691371962 Precision Macro 0.8866588307378376\n","Change of the performance: 0.00033211883335282355 0.0003963059834778404 \n","Change of cost:  2.477718366855619e-05\n","epoch 19\n","The cost at the end of this epoch is  0.11987746783007253\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 291.   4.   1.   0.   3.   0.   0.   7.   2.]\n"," [  5.   1. 243.   9.   2.   4.   7.   6.   9.   2.]\n"," [  2.   5.  15. 252.   1.  19.   0.   5.   4.   0.]\n"," [  2.   1.   1.   0. 300.   0.   3.   2.   4.   7.]\n"," [  6.   3.   2.  16.   1. 250.   4.   0.   8.   0.]\n"," [ 11.   2.   2.   0.   6.   9. 258.   0.   4.   0.]\n"," [  2.   6.   5.   3.   4.   0.   0. 261.   0.  11.]\n"," [  4.   9.   7.   9.   1.  19.   2.   2. 265.   6.]\n"," [  1.   0.   0.   0.  14.   1.   0.   8.   3. 238.]]\n","Accuracy Macro 0.8866049219707556 Precision Macro 0.8871308905176208\n","Change of the performance: 0.0002163528335593634 0.00047205977978326263 \n","Change of cost:  8.144556912323409e-06\n","epoch 20\n","The cost at the end of this epoch is  0.11968312577864813\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 291.   5.   1.   0.   2.   0.   0.   7.   2.]\n"," [  5.   1. 244.   9.   2.   4.   7.   5.   9.   2.]\n"," [  2.   6.  16. 251.   1.  18.   0.   5.   4.   0.]\n"," [  2.   1.   1.   0. 300.   0.   3.   2.   4.   7.]\n"," [  6.   3.   2.  16.   1. 249.   4.   0.   8.   1.]\n"," [ 11.   2.   2.   0.   6.   9. 258.   0.   4.   0.]\n"," [  2.   8.   5.   1.   4.   0.   0. 261.   0.  11.]\n"," [  4.  11.   7.   9.   1.  19.   2.   2. 262.   7.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   3. 239.]]\n","Accuracy Macro 0.8857287161681107 Precision Macro 0.8859989522526666\n","Change of the performance: 0.0008762058026449138 0.0011319382649542797 \n","Change of cost:  8.557425743957459e-05\n","epoch 21\n","The cost at the end of this epoch is  0.11943622052878346\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 292.   5.   1.   0.   2.   0.   0.   6.   2.]\n"," [  5.   1. 243.   9.   2.   4.   6.   6.  10.   2.]\n"," [  2.   8.  17. 248.   1.  18.   0.   5.   4.   0.]\n"," [  2.   1.   1.   0. 300.   0.   3.   2.   4.   7.]\n"," [  6.   3.   2.  16.   1. 249.   4.   0.   8.   1.]\n"," [ 12.   2.   2.   0.   6.   8. 258.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 261.   0.  11.]\n"," [  4.  10.   7.   9.   1.  19.   2.   2. 264.   6.]\n"," [  1.   0.   0.   0.  13.   1.   0.   9.   3. 238.]]\n","Accuracy Macro 0.8849559957207142 Precision Macro 0.8853063209289221\n","Change of the performance: 0.0007727204473965132 0.0006926313237444193 \n","Change of cost:  2.6234138014114006e-05\n","epoch 22\n","The cost at the end of this epoch is  0.11929573410898378\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   3.   1.   3.   3.   0.   3.   0.]\n"," [  0. 292.   5.   1.   0.   2.   0.   0.   6.   2.]\n"," [  5.   1. 243.   9.   2.   4.   7.   6.   9.   2.]\n"," [  2.   8.  17. 249.   1.  18.   0.   5.   3.   0.]\n"," [  2.   1.   1.   0. 300.   0.   3.   2.   4.   7.]\n"," [  6.   3.   2.  16.   1. 249.   4.   0.   8.   1.]\n"," [ 12.   2.   2.   0.   6.   8. 258.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 261.   0.  11.]\n"," [  4.  10.   7.   9.   1.  19.   2.   2. 264.   6.]\n"," [  1.   0.   0.   0.  14.   1.   0.   8.   3. 238.]]\n","Accuracy Macro 0.8856004941328195 Precision Macro 0.8859290494869368\n","Change of the performance: 0.0006444984121053432 0.0006227285580147068 \n","Change of cost:  3.1059665346194754e-05\n","epoch 23\n","The cost at the end of this epoch is  0.11917229119092558\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 291.   5.   1.   0.   2.   0.   0.   7.   2.]\n"," [  5.   1. 243.   9.   2.   4.   6.   6.  10.   2.]\n"," [  2.   8.  17. 248.   1.  18.   0.   5.   4.   0.]\n"," [  2.   1.   1.   0. 300.   0.   3.   2.   4.   7.]\n"," [  6.   3.   2.  16.   1. 249.   4.   0.   8.   1.]\n"," [ 12.   2.   2.   0.   6.   9. 257.   0.   4.   0.]\n"," [  2.   8.   5.   1.   4.   0.   0. 261.   0.  11.]\n"," [  4.   9.   6.   9.   1.  19.   2.   2. 266.   6.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   3. 239.]]\n","Accuracy Macro 0.8852834970837975 Precision Macro 0.885762381208832\n","Change of the performance: 0.0003169970490219942 0.0001666682781048534 \n","Change of cost:  9.19093335019494e-06\n","epoch 24\n","The cost at the end of this epoch is  0.1190827223673305\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 291.   5.   1.   0.   2.   0.   0.   7.   2.]\n"," [  5.   1. 243.   9.   2.   4.   6.   6.  10.   2.]\n"," [  2.   8.  17. 248.   1.  18.   0.   5.   4.   0.]\n"," [  2.   1.   1.   0. 300.   0.   3.   2.   4.   7.]\n"," [  6.   3.   2.  16.   1. 249.   4.   0.   8.   1.]\n"," [ 12.   2.   2.   0.   6.   9. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 261.   0.  11.]\n"," [  4.  10.   7.   9.   1.  19.   2.   2. 264.   6.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   3. 239.]]\n","Accuracy Macro 0.8846662131331803 Precision Macro 0.8850671970570246\n","Change of the performance: 0.0006172839506172201 0.0006951841518073598 \n","Change of cost:  1.1545927198070016e-06\n","epoch 25\n","The cost at the end of this epoch is  0.1190147768841965\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 291.   5.   1.   0.   2.   0.   0.   7.   2.]\n"," [  5.   1. 243.   9.   2.   4.   6.   6.  10.   2.]\n"," [  2.   8.  16. 249.   1.  18.   0.   5.   4.   0.]\n"," [  2.   1.   1.   0. 300.   0.   3.   2.   4.   7.]\n"," [  6.   3.   2.  16.   1. 249.   4.   0.   8.   1.]\n"," [ 12.   2.   2.   0.   6.   9. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 261.   0.  11.]\n"," [  4.   9.   7.   9.   1.  19.   2.   2. 265.   6.]\n"," [  1.   0.   0.   0.  14.   1.   0.   8.   3. 238.]]\n","Accuracy Macro 0.884927529621223 Precision Macro 0.885428164004006\n","Change of the performance: 0.0002613164880427288 0.0003609669469814003 \n","Change of cost:  4.179678659121944e-06\n","epoch 26\n","The cost at the end of this epoch is  0.11896248892231492\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 292.   5.   1.   0.   2.   0.   0.   6.   2.]\n"," [  5.   1. 243.   9.   2.   4.   6.   6.  10.   2.]\n"," [  2.   8.  17. 248.   1.  18.   0.   5.   4.   0.]\n"," [  2.   1.   1.   0. 300.   0.   3.   2.   4.   7.]\n"," [  6.   3.   2.  16.   1. 249.   4.   0.   8.   1.]\n"," [ 12.   2.   2.   0.   6.   9. 257.   0.   4.   0.]\n"," [  2.   7.   5.   2.   4.   0.   0. 261.   0.  11.]\n"," [  4.   9.   7.   9.   1.  19.   2.   2. 265.   6.]\n"," [  1.   0.   0.   0.  14.   1.   0.   8.   3. 238.]]\n","Accuracy Macro 0.884922171942598 Precision Macro 0.8853856803554259\n","Change of the performance: 5.357678624973161e-06 4.248364858017162e-05 \n","Change of cost:  1.1180985133182886e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_11_250x785_10x251\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [300  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (300, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 301)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 300)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.21674869890444023\n","Now let's test the model after this epoch:\n","Confusion array  [[292.   0.   2.   3.   1.  10.   7.   0.   3.   0.]\n"," [  0. 294.   3.   3.   1.   3.   0.   0.   3.   1.]\n"," [  3.   2. 245.  10.   3.   7.   8.   5.   5.   0.]\n"," [  0.   5.  14. 258.   1.  17.   0.   6.   1.   1.]\n"," [  0.   1.   1.   0. 306.   2.   5.   2.   1.   2.]\n"," [  2.   3.   2.  16.   1. 262.   1.   0.   3.   0.]\n"," [  4.   3.   2.   0.   4.  12. 264.   0.   3.   0.]\n"," [  1.   7.   4.   3.   5.   0.   0. 264.   0.   8.]\n"," [  2.  19.   5.  13.   9.  35.   4.   2. 227.   8.]\n"," [  1.   0.   0.   1.  28.   2.   0.  10.   2. 221.]]\n","Accuracy Macro 0.8777461043261263 Precision Macro 0.8819566178394831\n","epoch 1\n","The cost at the end of this epoch is  0.18795283353174064\n","Now let's test the model after this epoch:\n","Confusion array  [[292.   0.   4.   3.   1.   9.   4.   2.   3.   0.]\n"," [  0. 290.   5.   3.   1.   2.   0.   1.   4.   2.]\n"," [  2.   5. 232.  11.   3.   2.   7.  15.   9.   2.]\n"," [  0.   9.  16. 248.   0.  14.   1.   9.   5.   1.]\n"," [  2.   1.   1.   0. 300.   1.   2.   2.   4.   7.]\n"," [  1.   5.   1.  19.   1. 249.   2.   0.  10.   2.]\n"," [  8.   2.   2.   0.   6.  12. 254.   0.   8.   0.]\n"," [  0.   5.   2.   4.   3.   0.   0. 271.   0.   7.]\n"," [  3.  11.   8.   9.   2.  22.   1.   3. 261.   4.]\n"," [  1.   0.   0.   1.   9.   1.   0.  11.   1. 241.]]\n","Accuracy Macro 0.879289025196384 Precision Macro 0.879783524811636\n","epoch 2\n","The cost at the end of this epoch is  0.1780798375651305\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   9.   2.   0.   3.   0.]\n"," [  0. 289.   3.   1.   0.   5.   0.   0.   9.   1.]\n"," [  5.   3. 226.   8.   2.   7.   7.  11.  18.   1.]\n"," [  2.   1.  15. 245.   0.  20.   1.   4.   9.   6.]\n"," [  4.   1.   0.   0. 284.   0.   4.   1.   5.  21.]\n"," [  4.   3.   1.  15.   1. 253.   2.   0.  10.   1.]\n"," [ 13.   2.   3.   0.   5.   8. 254.   0.   7.   0.]\n"," [  2.   9.   3.   1.   2.   0.   0. 260.   2.  13.]\n"," [  7.   4.   5.   6.   0.  21.   2.   1. 270.   8.]\n"," [  1.   0.   0.   0.   9.   1.   0.   6.   3. 245.]]\n","Accuracy Macro 0.8753060395961129 Precision Macro 0.8773705016222835\n","Change of the performance: 0.003982985600271105 0.0024130231893525478 \n","Change of cost:  0.08926069507284709\n","epoch 3\n","The cost at the end of this epoch is  0.1332786106814676\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   3.   1.   5.   2.   0.   2.   0.]\n"," [  0. 291.   4.   1.   0.   3.   0.   0.   7.   2.]\n"," [  5.   2. 236.   8.   3.   6.   8.   8.  11.   1.]\n"," [  2.   4.  15. 248.   1.  20.   1.   6.   5.   1.]\n"," [  2.   2.   2.   0. 298.   0.   4.   3.   3.   6.]\n"," [  3.   3.   1.  17.   1. 254.   3.   0.   8.   0.]\n"," [  8.   2.   2.   0.   5.   9. 262.   0.   4.   0.]\n"," [  2.   6.   4.   1.   3.   0.   0. 266.   0.  10.]\n"," [  4.   5.   5.  10.   2.  23.   2.   1. 265.   7.]\n"," [  1.   0.   0.   1.  10.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8881372774081516 Precision Macro 0.8884848191070391\n","Change of the performance: 0.012831237812038765 0.011114317484755665 \n","Change of cost:  0.0022242553193154435\n","epoch 4\n","The cost at the end of this epoch is  0.13822663268275415\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   0.   3.   1.   4.   3.   0.   3.   0.]\n"," [  0. 290.   5.   1.   0.   3.   0.   0.   8.   1.]\n"," [  5.   4. 236.   6.   2.   3.   7.   8.  15.   2.]\n"," [  3.   8.  18. 236.   0.  18.   1.   5.  10.   4.]\n"," [  3.   1.   0.   0. 300.   0.   3.   2.   4.   7.]\n"," [  4.   4.   1.  15.   1. 247.   3.   0.  13.   2.]\n"," [  7.   3.   2.   0.   6.   5. 261.   0.   8.   0.]\n"," [  1.   5.   4.   1.   5.   0.   0. 262.   2.  12.]\n"," [  2.   6.   6.   7.   2.   9.   2.   2. 282.   6.]\n"," [  1.   0.   0.   0.   9.   1.   0.   7.   4. 243.]]\n","Accuracy Macro 0.8863527147346797 Precision Macro 0.8875084941643706\n","Change of the performance: 0.0017845626734719344 0.0009763249426685272 \n","Change of cost:  0.0020379750375489614\n","epoch 5\n","The cost at the end of this epoch is  0.12404389331372906\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   3.   1.   4.   3.   1.   1.   0.]\n"," [  0. 292.   4.   3.   0.   1.   0.   0.   7.   1.]\n"," [  5.   5. 238.   8.   2.   3.   7.  10.   9.   1.]\n"," [  3.   7.  16. 254.   1.  13.   1.   4.   2.   2.]\n"," [  2.   1.   1.   0. 301.   0.   3.   2.   4.   6.]\n"," [  6.   3.   2.  17.   1. 249.   4.   0.   7.   1.]\n"," [  9.   3.   2.   0.   6.   7. 261.   0.   4.   0.]\n"," [  2.   8.   3.   2.   3.   0.   0. 264.   1.   9.]\n"," [  4.   8.   5.   8.   1.  16.   2.   2. 272.   6.]\n"," [  1.   0.   0.   0.   9.   1.   0.   9.   4. 241.]]\n","Accuracy Macro 0.8914830538329251 Precision Macro 0.8916992841837654\n","Change of the performance: 0.005130339098245451 0.004190790019394819 \n","Change of cost:  0.0015850852329685194\n","epoch 6\n","The cost at the end of this epoch is  0.12274173172523642\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   3.   1.   4.   3.   0.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   0.   7.   1.]\n"," [  5.   1. 240.   9.   2.   4.   8.   9.   9.   1.]\n"," [  2.   9.  16. 248.   1.  18.   0.   5.   2.   2.]\n"," [  2.   1.   1.   0. 303.   0.   3.   2.   3.   5.]\n"," [  4.   3.   2.  16.   1. 252.   4.   0.   8.   0.]\n"," [  8.   3.   2.   0.   6.  10. 258.   0.   5.   0.]\n"," [  2.   8.   4.   2.   3.   0.   0. 262.   1.  10.]\n"," [  4.  10.   4.  11.   1.  22.   2.   2. 259.   9.]\n"," [  1.   0.   0.   0.  14.   1.   0.   8.   4. 237.]]\n","Accuracy Macro 0.8846226746077888 Precision Macro 0.8850634672819678\n","Change of the performance: 0.0068603792251363815 0.006635816901797598 \n","Change of cost:  0.008921187098790417\n","epoch 7\n","The cost at the end of this epoch is  0.11924430536541543\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 291.   5.   1.   0.   3.   0.   0.   6.   2.]\n"," [  5.   0. 242.   8.   2.   4.   9.   7.   9.   2.]\n"," [  3.   7.  17. 244.   1.  20.   0.   5.   4.   2.]\n"," [  2.   1.   1.   0. 303.   0.   3.   2.   3.   5.]\n"," [  6.   3.   2.  16.   1. 250.   4.   0.   7.   1.]\n"," [  9.   2.   2.   0.   6.   8. 260.   0.   5.   0.]\n"," [  2.   7.   4.   1.   4.   0.   0. 259.   0.  15.]\n"," [  4.   4.   7.   7.   1.  16.   2.   2. 274.   7.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8880874304810404 Precision Macro 0.8881926009917889\n","Change of the performance: 0.0034647558732516792 0.0031291337098210414 \n","Change of cost:  0.004922524228357247\n","epoch 8\n","The cost at the end of this epoch is  0.11730731142529291\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   3.   1.   4.   3.   0.   2.   0.]\n"," [  0. 291.   4.   1.   0.   3.   0.   0.   8.   1.]\n"," [  5.   1. 244.   7.   2.   4.   8.   6.   9.   2.]\n"," [  3.   5.  17. 251.   1.  17.   0.   4.   3.   2.]\n"," [  2.   1.   1.   0. 302.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 249.   4.   0.   7.   2.]\n"," [  9.   2.   2.   0.   6.   7. 261.   0.   5.   0.]\n"," [  2.   7.   4.   3.   4.   0.   0. 259.   1.  12.]\n"," [  4.   8.   5.   8.   1.  18.   2.   2. 268.   8.]\n"," [  1.   0.   0.   0.  15.   1.   0.   8.   4. 236.]]\n","Accuracy Macro 0.8877304237104943 Precision Macro 0.8881353168824189\n","Change of the performance: 0.00035700677054617547 5.728410937000383e-05 \n","Change of cost:  0.0005186395255251941\n","epoch 9\n","The cost at the end of this epoch is  0.11666145964900916\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 291.   4.   1.   0.   3.   0.   0.   8.   1.]\n"," [  5.   1. 242.  10.   2.   4.   6.   7.   9.   2.]\n"," [  2.   9.  16. 244.   1.  20.   0.   5.   3.   3.]\n"," [  2.   1.   1.   0. 302.   0.   3.   2.   4.   5.]\n"," [  4.   3.   2.  16.   1. 253.   3.   0.   8.   0.]\n"," [  8.   3.   2.   0.   6.  12. 255.   0.   6.   0.]\n"," [  2.   7.   3.   2.   4.   0.   0. 261.   1.  12.]\n"," [  3.   8.   5.   8.   1.  22.   2.   2. 265.   8.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   4. 238.]]\n","Accuracy Macro 0.8839350558116725 Precision Macro 0.8847254411327634\n","Change of the performance: 0.003795367898821733 0.0034098757496554555 \n","Change of cost:  0.0002445678031158388\n","epoch 10\n","The cost at the end of this epoch is  0.11536605844374956\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   3.   1.   4.   3.   0.   2.   0.]\n"," [  0. 291.   4.   1.   0.   3.   0.   0.   8.   1.]\n"," [  5.   2. 242.   8.   2.   4.   7.   6.  10.   2.]\n"," [  3.   9.  16. 244.   1.  19.   0.   4.   4.   3.]\n"," [  2.   1.   2.   0. 301.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 248.   4.   0.   7.   3.]\n"," [  9.   2.   2.   0.   6.   8. 260.   0.   5.   0.]\n"," [  2.   7.   4.   3.   4.   0.   0. 258.   1.  13.]\n"," [  4.   6.   4.   7.   1.  19.   2.   1. 271.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   7.   4. 239.]]\n","Accuracy Macro 0.8854414905475153 Precision Macro 0.8859420166968054\n","Change of the performance: 0.0015064347358427765 0.0012165755640419773 \n","Change of cost:  0.0003282731804534894\n","epoch 11\n","The cost at the end of this epoch is  0.11512428336093666\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 290.   4.   1.   0.   3.   0.   0.   9.   1.]\n"," [  5.   0. 239.   8.   2.   4.   9.   9.  11.   1.]\n"," [  3.   9.  15. 248.   1.  18.   0.   4.   3.   2.]\n"," [  2.   1.   1.   0. 302.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 250.   4.   0.   7.   1.]\n"," [  8.   2.   2.   0.   6.   8. 261.   0.   5.   0.]\n"," [  2.   7.   3.   2.   4.   0.   0. 262.   1.  11.]\n"," [  4.   5.   5.   9.   1.  17.   2.   2. 271.   8.]\n"," [  1.   0.   0.   0.  15.   1.   0.   8.   4. 236.]]\n","Accuracy Macro 0.8866632236284087 Precision Macro 0.8872088898822803\n","Change of the performance: 0.0012217330808933502 0.001266873185474915 \n","Change of cost:  0.000825536791282791\n","epoch 12\n","The cost at the end of this epoch is  0.11392338823863496\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   4.   0.   2.   0.]\n"," [  0. 291.   4.   1.   0.   3.   0.   0.   7.   2.]\n"," [  5.   2. 242.   8.   2.   4.   8.   6.   9.   2.]\n"," [  2.   9.  16. 246.   1.  18.   0.   5.   4.   2.]\n"," [  2.   1.   1.   0. 302.   0.   3.   2.   4.   5.]\n"," [  5.   4.   2.  16.   1. 248.   3.   0.   8.   3.]\n"," [  8.   2.   2.   0.   6.   9. 260.   0.   5.   0.]\n"," [  2.   7.   3.   2.   4.   0.   0. 261.   1.  12.]\n"," [  3.   6.   5.   8.   1.  18.   2.   2. 270.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   4. 239.]]\n","Accuracy Macro 0.8868183464302761 Precision Macro 0.8870130507876862\n","Change of the performance: 0.00015512280186746885 0.00019583909459408577 \n","Change of cost:  0.0001928193365489106\n","epoch 13\n","The cost at the end of this epoch is  0.11355019813591419\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 291.   4.   1.   0.   3.   0.   0.   8.   1.]\n"," [  5.   1. 242.   8.   2.   4.   9.   6.   9.   2.]\n"," [  2.   9.  16. 246.   1.  18.   0.   5.   4.   2.]\n"," [  2.   1.   2.   0. 302.   0.   3.   2.   3.   5.]\n"," [  6.   3.   2.  16.   1. 249.   3.   0.   7.   3.]\n"," [  8.   2.   2.   0.   6.   9. 260.   0.   5.   0.]\n"," [  2.   7.   3.   2.   4.   0.   0. 260.   1.  13.]\n"," [  4.   5.   5.   8.   1.  18.   2.   2. 271.   8.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   4. 238.]]\n","Accuracy Macro 0.886437526338996 Precision Macro 0.8866637035677446\n","Change of the performance: 0.00038082009128015404 0.0003493472199416203 \n","Change of cost:  6.442292664464444e-05\n","epoch 14\n","The cost at the end of this epoch is  0.11296475233825341\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 292.   4.   1.   0.   3.   0.   0.   7.   1.]\n"," [  5.   0. 242.   8.   2.   4.   9.   9.   8.   1.]\n"," [  2.   9.  17. 245.   1.  18.   0.   5.   4.   2.]\n"," [  2.   1.   1.   0. 302.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 250.   3.   0.   7.   2.]\n"," [  8.   2.   2.   0.   6.   9. 260.   0.   5.   0.]\n"," [  2.   6.   3.   2.   3.   0.   0. 265.   1.  10.]\n"," [  3.   5.   5.   9.   1.  19.   2.   2. 269.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   9.   4. 237.]]\n","Accuracy Macro 0.8874946825725178 Precision Macro 0.8876083775133268\n","Change of the performance: 0.001057156233521872 0.0009446739455821751 \n","Change of cost:  0.00014939304461648872\n","epoch 15\n","The cost at the end of this epoch is  0.11235858230885841\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 291.   4.   1.   0.   3.   0.   0.   8.   1.]\n"," [  5.   1. 242.   7.   2.   4.   8.   7.  10.   2.]\n"," [  2.   9.  17. 245.   1.  18.   0.   5.   4.   2.]\n"," [  2.   1.   2.   0. 301.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 250.   3.   0.   7.   2.]\n"," [  8.   2.   2.   0.   6.   9. 260.   0.   5.   0.]\n"," [  2.   6.   3.   2.   4.   0.   0. 262.   1.  12.]\n"," [  3.   5.   5.   8.   1.  17.   2.   2. 272.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   9.   4. 237.]]\n","Accuracy Macro 0.8867560359134945 Precision Macro 0.8870009238717502\n","Change of the performance: 0.0007386466590233454 0.0006074536415765497 \n","Change of cost:  5.4165065526107226e-05\n","epoch 16\n","The cost at the end of this epoch is  0.11229163034635974\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 292.   4.   1.   0.   3.   0.   0.   7.   1.]\n"," [  5.   1. 242.   8.   2.   5.   8.   8.   8.   1.]\n"," [  2.   8.  16. 248.   1.  18.   0.   4.   3.   3.]\n"," [  2.   1.   2.   0. 301.   0.   3.   2.   4.   5.]\n"," [  5.   3.   2.  16.   1. 251.   3.   0.   7.   2.]\n"," [  9.   2.   2.   0.   6.   9. 259.   0.   5.   0.]\n"," [  2.   7.   3.   2.   4.   0.   0. 261.   1.  12.]\n"," [  3.   9.   5.   8.   1.  19.   2.   2. 266.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   4. 239.]]\n","Accuracy Macro 0.8866335714567086 Precision Macro 0.8867790394408441\n","Change of the performance: 0.0001224644567858757 0.0002218844309060941 \n","Change of cost:  0.00018986508253721057\n","epoch 17\n","The cost at the end of this epoch is  0.11173642058144478\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 292.   4.   1.   0.   3.   0.   0.   7.   1.]\n"," [  5.   0. 243.   8.   2.   4.   9.   8.   8.   1.]\n"," [  2.   9.  16. 246.   1.  18.   0.   4.   4.   3.]\n"," [  2.   1.   2.   0. 301.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 250.   3.   0.   7.   2.]\n"," [  9.   2.   2.   0.   6.   9. 259.   0.   5.   0.]\n"," [  2.   6.   3.   2.   3.   0.   0. 263.   1.  12.]\n"," [  3.   6.   5.   8.   1.  19.   2.   2. 269.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   4. 239.]]\n","Accuracy Macro 0.8875867575188986 Precision Macro 0.8876490880346323\n","Change of the performance: 0.0009531860621899702 0.0008700485937881419 \n","Change of cost:  0.00010193991811760506\n","epoch 18\n","The cost at the end of this epoch is  0.11152194187718924\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 291.   4.   1.   0.   3.   0.   0.   8.   1.]\n"," [  5.   1. 242.   8.   2.   4.   9.   6.   9.   2.]\n"," [  2.   9.  17. 245.   1.  18.   0.   5.   4.   2.]\n"," [  2.   1.   2.   0. 301.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 249.   3.   0.   7.   3.]\n"," [  8.   2.   2.   0.   6.   9. 260.   0.   5.   0.]\n"," [  2.   6.   3.   2.   4.   0.   0. 262.   1.  12.]\n"," [  3.   7.   5.   8.   1.  21.   2.   2. 267.   8.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   4. 238.]]\n","Accuracy Macro 0.8852453569413106 Precision Macro 0.8854036643143915\n","Change of the performance: 0.0023414005775880264 0.0022454237202407246 \n","Change of cost:  1.7870199475411574e-05\n","epoch 19\n","The cost at the end of this epoch is  0.11129519626516085\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 292.   4.   1.   0.   3.   0.   0.   7.   1.]\n"," [  5.   0. 243.   8.   2.   4.   9.   8.   8.   1.]\n"," [  2.   9.  16. 246.   1.  18.   0.   5.   4.   2.]\n"," [  2.   1.   1.   0. 302.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 250.   3.   0.   7.   2.]\n"," [  9.   2.   2.   0.   6.   9. 259.   0.   5.   0.]\n"," [  2.   6.   3.   2.   4.   0.   0. 262.   1.  12.]\n"," [  3.   7.   5.   8.   1.  21.   2.   2. 267.   8.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   4. 238.]]\n","Accuracy Macro 0.8865621493242906 Precision Macro 0.8867988631294258\n","Change of the performance: 0.0013167923829799921 0.0013951988150342487 \n","Change of cost:  3.6140760812167216e-05\n","epoch 20\n","The cost at the end of this epoch is  0.11110248474697224\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 292.   4.   1.   0.   3.   0.   0.   7.   1.]\n"," [  5.   1. 243.   7.   2.   4.   8.   7.   9.   2.]\n"," [  2.   8.  16. 247.   1.  18.   0.   4.   4.   3.]\n"," [  2.   1.   2.   0. 301.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 249.   3.   0.   7.   3.]\n"," [  8.   2.   2.   0.   6.   9. 260.   0.   5.   0.]\n"," [  2.   6.   3.   2.   4.   0.   0. 262.   1.  12.]\n"," [  3.   8.   5.   8.   1.  19.   2.   2. 267.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   4. 239.]]\n","Accuracy Macro 0.8869546789853748 Precision Macro 0.8870040033651199\n","Change of the performance: 0.00039252966108427323 0.00020514023569406792 \n","Change of cost:  2.0915391242798398e-05\n","epoch 21\n","The cost at the end of this epoch is  0.11096209571861675\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 292.   4.   1.   0.   3.   0.   0.   7.   1.]\n"," [  5.   1. 242.   7.   2.   4.   8.   8.  10.   1.]\n"," [  2.   9.  17. 245.   1.  18.   0.   4.   4.   3.]\n"," [  2.   1.   2.   0. 301.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 249.   3.   0.   7.   3.]\n"," [  8.   2.   2.   0.   6.   9. 260.   0.   5.   0.]\n"," [  2.   6.   3.   2.   4.   0.   0. 262.   1.  12.]\n"," [  3.   8.   5.   8.   1.  19.   2.   2. 267.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   4. 238.]]\n","Accuracy Macro 0.8855700322659859 Precision Macro 0.88566973740924\n","Change of the performance: 0.0013846467193889822 0.0013342659558798209 \n","Change of cost:  3.3282667882897354e-05\n","epoch 22\n","The cost at the end of this epoch is  0.11088015011382181\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 293.   4.   1.   0.   3.   0.   0.   6.   1.]\n"," [  5.   1. 243.   7.   2.   4.   9.   7.   8.   2.]\n"," [  2.   9.  17. 245.   1.  18.   0.   5.   4.   2.]\n"," [  2.   1.   2.   0. 301.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 249.   3.   0.   7.   3.]\n"," [  9.   2.   2.   0.   6.   9. 259.   0.   5.   0.]\n"," [  2.   6.   3.   2.   4.   0.   0. 262.   1.  12.]\n"," [  3.   8.   5.   8.   1.  19.   2.   2. 267.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   4. 238.]]\n","Accuracy Macro 0.8858994640594586 Precision Macro 0.8859492599061365\n","Change of the performance: 0.0003294317934727786 0.00027952249689644493 \n","Change of cost:  2.551803004467723e-05\n","epoch 23\n","The cost at the end of this epoch is  0.11078005065548885\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 292.   4.   1.   0.   3.   0.   0.   7.   1.]\n"," [  5.   1. 242.   7.   2.   4.   9.   7.   9.   2.]\n"," [  2.   9.  17. 245.   1.  18.   0.   4.   4.   3.]\n"," [  2.   1.   1.   0. 302.   0.   3.   2.   4.   5.]\n"," [  6.   3.   2.  16.   1. 249.   3.   0.   7.   3.]\n"," [  9.   2.   2.   0.   6.   9. 259.   0.   5.   0.]\n"," [  2.   6.   3.   2.   4.   0.   0. 262.   1.  12.]\n"," [  3.   8.   5.   8.   1.  20.   2.   2. 267.   8.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   4. 239.]]\n","Accuracy Macro 0.8859174250031272 Precision Macro 0.886033657569644\n","Change of the performance: 1.796094366857126e-05 8.439766350754052e-05 \n","Change of cost:  8.444288120232346e-06\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_12_300x785_10x301\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [350  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (350, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 351)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 350)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.11693031421075914\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   3.   4.   1.   3.   0.]\n"," [  0. 288.   4.   1.   0.   4.   0.   1.   9.   1.]\n"," [  5.   1. 238.  10.   3.   4.   6.   9.  11.   1.]\n"," [  2.   9.  16. 244.   1.  20.   0.   4.   5.   2.]\n"," [  2.   1.   1.   0. 303.   0.   3.   2.   3.   5.]\n"," [  6.   3.   2.  15.   1. 252.   3.   0.   7.   1.]\n"," [  7.   2.   2.   0.   6.   9. 260.   0.   6.   0.]\n"," [  2.   5.   3.   3.   4.   0.   0. 264.   1.  10.]\n"," [  3.   6.   3.   8.   1.  18.   2.   2. 274.   7.]\n"," [  1.   0.   0.   0.  16.   1.   0.   7.   4. 236.]]\n","Accuracy Macro 0.8863026001865937 Precision Macro 0.8873380986660889\n","epoch 1\n","The cost at the end of this epoch is  0.1715147770232599\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   4.   4.   0.   3.   0.]\n"," [  0. 292.   3.   2.   0.   2.   1.   0.   7.   1.]\n"," [  5.   1. 235.   9.   2.   2.  10.   9.  14.   1.]\n"," [  2.  10.  16. 249.   1.  17.   0.   3.   4.   1.]\n"," [  1.   1.   1.   0. 299.   0.   5.   3.   7.   3.]\n"," [  5.   3.   1.  26.   0. 237.   6.   0.   9.   3.]\n"," [  7.   2.   1.   0.   4.   7. 267.   0.   4.   0.]\n"," [  3.   8.   4.   3.   3.   0.   0. 261.   2.   8.]\n"," [  4.   4.   5.  10.   0.   8.   3.   0. 286.   4.]\n"," [  1.   0.   0.   1.  20.   1.   0.  11.   3. 228.]]\n","Accuracy Macro 0.8841565502437057 Precision Macro 0.8859639752607456\n","epoch 2\n","The cost at the end of this epoch is  0.11889261201661537\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   5.   5.   1.   4.   0.]\n"," [  0. 293.   4.   1.   0.   3.   0.   0.   6.   1.]\n"," [  5.   1. 248.   7.   2.   4.   8.   5.   6.   2.]\n"," [  2.  11.  18. 247.   1.  14.   0.   5.   3.   2.]\n"," [  3.   1.   1.   0. 303.   0.   3.   2.   3.   4.]\n"," [  4.   3.   2.  15.   1. 253.   2.   0.   8.   2.]\n"," [  7.   2.   2.   0.   6.  10. 260.   0.   5.   0.]\n"," [  2.   8.   3.   1.   4.   0.   0. 261.   1.  12.]\n"," [  3.  11.   5.   7.   2.  17.   2.   2. 268.   7.]\n"," [  1.   0.   0.   0.  12.   1.   0.   7.   3. 241.]]\n","Accuracy Macro 0.8904828073337848 Precision Macro 0.8906895672118177\n","Change of the performance: 0.006326257090079168 0.004725591951072139 \n","Change of cost:  0.003850180049616181\n","epoch 3\n","The cost at the end of this epoch is  0.12280115696500372\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   2.   3.   1.   3.   4.   0.   3.   0.]\n"," [  0. 291.   5.   1.   0.   2.   0.   1.   7.   1.]\n"," [  5.   3. 243.   8.   1.   3.   7.   9.   8.   1.]\n"," [  2.  10.  19. 243.   1.  15.   1.   5.   4.   3.]\n"," [  4.   1.   1.   0. 301.   0.   4.   1.   2.   6.]\n"," [  4.   4.   2.  15.   1. 245.   3.   0.  12.   4.]\n"," [  6.   2.   2.   0.   5.   6. 265.   0.   6.   0.]\n"," [  1.   8.   3.   2.   4.   0.   0. 263.   2.   9.]\n"," [  3.   9.   5.   8.   2.  12.   2.   2. 274.   7.]\n"," [  1.   0.   0.   0.  12.   1.   0.   5.   3. 243.]]\n","Accuracy Macro 0.889655283612643 Precision Macro 0.8895425277739237\n","Change of the performance: 0.0008275237211418096 0.0011470394378939597 \n","Change of cost:  0.02104611502042443\n","epoch 4\n","The cost at the end of this epoch is  0.12593429211480267\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   3.   5.   1.   1.   0.]\n"," [  0. 293.   5.   1.   0.   2.   0.   0.   6.   1.]\n"," [  5.   1. 245.   9.   2.   5.   7.   7.   6.   1.]\n"," [  2.   8.  16. 250.   1.  15.   0.   6.   3.   2.]\n"," [  2.   1.   3.   1. 299.   0.   5.   3.   2.   4.]\n"," [  5.   3.   2.  17.   1. 254.   3.   0.   5.   0.]\n"," [  7.   2.   2.   0.   5.  10. 262.   0.   4.   0.]\n"," [  2.   6.   3.   1.   3.   0.   0. 268.   1.   8.]\n"," [  5.   9.   6.  14.   1.  22.   3.   2. 255.   7.]\n"," [  1.   0.   1.   1.  12.   1.   0.   9.   1. 239.]]\n","Accuracy Macro 0.8894135234279286 Precision Macro 0.8893105523056246\n","Change of the performance: 0.00024176018471444571 0.00023197546829911708 \n","Change of cost:  0.006673796855848055\n","epoch 5\n","The cost at the end of this epoch is  0.11963956913262334\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   3.   2.   3.   0.]\n"," [  0. 293.   5.   1.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 241.  10.   2.   4.   7.  10.   6.   1.]\n"," [  2.   6.  17. 251.   1.  14.   0.   5.   4.   3.]\n"," [  2.   1.   4.   0. 298.   0.   4.   2.   2.   7.]\n"," [  4.   3.   2.  17.   1. 252.   2.   0.   9.   0.]\n"," [ 10.   2.   3.   0.   5.  11. 257.   0.   4.   0.]\n"," [  2.   7.   3.   1.   3.   0.   0. 269.   1.   6.]\n"," [  4.   8.   9.   9.   0.  14.   2.   1. 271.   6.]\n"," [  1.   0.   0.   0.  11.   1.   0.  10.   4. 238.]]\n","Accuracy Macro 0.8896001662441849 Precision Macro 0.8897979606981833\n","Change of the performance: 0.00018664281625635493 0.00048740839255867474 \n","Change of cost:  0.0020060178740317625\n","epoch 6\n","The cost at the end of this epoch is  0.11102316944866784\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 292.   3.   1.   0.   4.   0.   0.   7.   1.]\n"," [  5.   1. 242.  10.   2.   4.   8.   7.   8.   1.]\n"," [  2.   9.  17. 247.   1.  18.   0.   4.   2.   3.]\n"," [  3.   1.   2.   0. 300.   0.   5.   1.   3.   5.]\n"," [  6.   3.   2.  16.   1. 250.   4.   0.   6.   2.]\n"," [  7.   2.   3.   0.   5.   8. 262.   0.   5.   0.]\n"," [  2.   8.   3.   2.   4.   0.   0. 260.   1.  12.]\n"," [  4.  10.   4.   9.   1.  20.   2.   1. 264.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   7.   4. 239.]]\n","Accuracy Macro 0.8853993930146284 Precision Macro 0.8854323006957898\n","Change of the performance: 0.004200773229556476 0.004365660002393468 \n","Change of cost:  0.0012828199229484444\n","epoch 7\n","The cost at the end of this epoch is  0.10980153837306972\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   2.   3.   1.   3.   4.   1.   1.   0.]\n"," [  0. 291.   4.   1.   0.   4.   0.   0.   7.   1.]\n"," [  5.   2. 245.   8.   2.   4.   7.   7.   7.   1.]\n"," [  2.   8.  16. 248.   1.  18.   0.   4.   3.   3.]\n"," [  4.   1.   2.   0. 302.   0.   3.   1.   2.   5.]\n"," [  6.   3.   2.  16.   1. 250.   3.   0.   7.   2.]\n"," [  7.   2.   3.   0.   5.   9. 260.   0.   6.   0.]\n"," [  2.   7.   3.   2.   3.   0.   0. 264.   1.  10.]\n"," [  4.   7.   5.   9.   1.  17.   2.   1. 270.   8.]\n"," [  1.   0.   0.   0.  13.   1.   0.   7.   4. 239.]]\n","Accuracy Macro 0.8902371315362313 Precision Macro 0.890487474817298\n","Change of the performance: 0.004837738521602852 0.0050551741215081325 \n","Change of cost:  0.0004574278072841387\n","epoch 8\n","The cost at the end of this epoch is  0.10767899982187121\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   4.   1.   3.   0.]\n"," [  0. 288.   4.   2.   0.   4.   0.   1.   8.   1.]\n"," [  5.   1. 240.   7.   3.   5.   7.   9.  10.   1.]\n"," [  2.   9.  16. 243.   1.  20.   0.   4.   3.   5.]\n"," [  3.   1.   1.   0. 303.   0.   3.   1.   2.   6.]\n"," [  6.   3.   2.  16.   1. 248.   4.   0.   8.   2.]\n"," [  7.   2.   3.   0.   5.   8. 260.   0.   7.   0.]\n"," [  2.   5.   3.   2.   4.   0.   0. 263.   1.  12.]\n"," [  4.   5.   5.   8.   1.  16.   2.   1. 273.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   7.   3. 241.]]\n","Accuracy Macro 0.8862089205982022 Precision Macro 0.8863398740780151\n","Change of the performance: 0.004028210938029075 0.004147600739282886 \n","Change of cost:  2.7970276121114246e-05\n","epoch 9\n","The cost at the end of this epoch is  0.10602720603164939\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 290.   5.   2.   0.   4.   0.   0.   6.   1.]\n"," [  5.   1. 247.   6.   2.   5.   8.   7.   6.   1.]\n"," [  2.   8.  17. 245.   1.  17.   0.   5.   4.   4.]\n"," [  3.   1.   3.   0. 299.   0.   3.   1.   2.   8.]\n"," [  6.   3.   2.  15.   1. 250.   3.   0.   8.   2.]\n"," [  7.   2.   3.   0.   5.   9. 260.   0.   6.   0.]\n"," [  2.   6.   3.   2.   3.   0.   0. 264.   1.  11.]\n"," [  4.   7.   6.  10.   1.  17.   2.   2. 268.   7.]\n"," [  1.   0.   0.   0.  11.   1.   0.  10.   3. 239.]]\n","Accuracy Macro 0.887433086877872 Precision Macro 0.8872041393770715\n","Change of the performance: 0.0012241662796698138 0.000864265299056477 \n","Change of cost:  0.003018204655230061\n","epoch 10\n","The cost at the end of this epoch is  0.10480773976227267\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   4.   1.   3.   0.]\n"," [  0. 291.   3.   1.   0.   4.   0.   1.   7.   1.]\n"," [  4.   1. 243.   8.   2.   5.   9.   7.   8.   1.]\n"," [  2.   9.  17. 246.   1.  17.   0.   4.   3.   4.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   3.   5.]\n"," [  6.   3.   2.  16.   1. 250.   3.   0.   8.   1.]\n"," [  7.   2.   3.   0.   5.   9. 260.   0.   6.   0.]\n"," [  1.   6.   3.   2.   4.   0.   0. 264.   1.  11.]\n"," [  3.   8.   5.   8.   1.  17.   2.   1. 270.   9.]\n"," [  1.   0.   0.   0.  14.   1.   0.   8.   4. 237.]]\n","Accuracy Macro 0.8871845078776388 Precision Macro 0.8873534760789005\n","Change of the performance: 0.0002485790002332289 0.00014933670182892822 \n","Change of cost:  7.481687394153558e-05\n","epoch 11\n","The cost at the end of this epoch is  0.10401855225199853\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   4.   1.   3.   0.]\n"," [  0. 290.   4.   1.   0.   4.   0.   1.   7.   1.]\n"," [  5.   1. 247.   6.   2.   5.   8.   7.   6.   1.]\n"," [  2.   9.  17. 244.   1.  17.   0.   5.   4.   4.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  6.   3.   2.  16.   1. 249.   3.   0.   8.   2.]\n"," [  7.   2.   3.   0.   5.   9. 260.   0.   6.   0.]\n"," [  2.   7.   3.   2.   3.   0.   0. 263.   1.  11.]\n"," [  3.   7.   5.  10.   1.  14.   2.   1. 272.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   4. 239.]]\n","Accuracy Macro 0.8882733630273698 Precision Macro 0.8881948077809432\n","Change of the performance: 0.001088855149731005 0.0008413317020427025 \n","Change of cost:  0.0004565822548526499\n","epoch 12\n","The cost at the end of this epoch is  0.10450938069980768\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   4.   1.   3.   0.]\n"," [  0. 288.   4.   3.   0.   4.   0.   1.   7.   1.]\n"," [  5.   1. 243.   7.   3.   5.   7.   6.   9.   2.]\n"," [  2.   6.  17. 247.   1.  18.   0.   4.   3.   5.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  5.   3.   2.  16.   1. 249.   3.   0.   9.   2.]\n"," [  7.   2.   3.   0.   5.   9. 260.   0.   6.   0.]\n"," [  2.   5.   3.   3.   4.   0.   0. 262.   1.  12.]\n"," [  2.   5.   6.   9.   1.  19.   2.   2. 270.   8.]\n"," [  1.   0.   0.   0.  13.   1.   0.   7.   3. 240.]]\n","Accuracy Macro 0.8869572966943602 Precision Macro 0.8870967343279117\n","Change of the performance: 0.0013160663330096245 0.0010980734530314784 \n","Change of cost:  0.00018005879773345945\n","epoch 13\n","The cost at the end of this epoch is  0.10287766349604233\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 290.   4.   2.   0.   4.   0.   1.   6.   1.]\n"," [  5.   1. 247.   6.   2.   5.   8.   7.   6.   1.]\n"," [  2.   8.  17. 247.   1.  17.   0.   4.   3.   4.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  6.   3.   2.  16.   1. 250.   4.   0.   6.   2.]\n"," [  7.   2.   3.   0.   5.   8. 261.   0.   6.   0.]\n"," [  2.   6.   3.   2.   3.   0.   0. 264.   1.  11.]\n"," [  3.   7.   6.  10.   1.  17.   2.   2. 267.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   7.   3. 240.]]\n","Accuracy Macro 0.8897563005619599 Precision Macro 0.889507667600413\n","Change of the performance: 0.002799003867599681 0.0024109332725013033 \n","Change of cost:  0.0006101374766071394\n","epoch 14\n","The cost at the end of this epoch is  0.10273910511877875\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 288.   4.   1.   0.   4.   0.   1.   9.   1.]\n"," [  5.   1. 244.   6.   2.   5.   8.   6.   9.   2.]\n"," [  2.   9.  17. 242.   1.  19.   0.   5.   4.   4.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  6.   3.   2.  16.   1. 249.   3.   0.   8.   2.]\n"," [  7.   2.   3.   0.   5.   8. 261.   0.   6.   0.]\n"," [  2.   6.   3.   1.   4.   0.   0. 264.   1.  11.]\n"," [  2.   5.   5.   8.   1.  17.   2.   2. 273.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   4. 239.]]\n","Accuracy Macro 0.8875447840045199 Precision Macro 0.8876664519427437\n","Change of the performance: 0.0022115165574400075 0.0018412156576692595 \n","Change of cost:  0.00010572218721158211\n","epoch 15\n","The cost at the end of this epoch is  0.10207018378598394\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 290.   4.   1.   0.   4.   0.   1.   7.   1.]\n"," [  5.   1. 244.   7.   2.   5.   8.   6.   8.   2.]\n"," [  2.   8.  17. 244.   1.  18.   0.   5.   4.   4.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  6.   3.   2.  16.   1. 249.   3.   0.   8.   2.]\n"," [  7.   2.   3.   0.   5.   9. 260.   0.   6.   0.]\n"," [  2.   6.   3.   1.   3.   0.   0. 265.   1.  11.]\n"," [  3.   6.   6.  10.   1.  16.   2.   2. 269.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   4. 238.]]\n","Accuracy Macro 0.8872422742686705 Precision Macro 0.8871641366323313\n","Change of the performance: 0.0003025097358493323 0.0005023153104124489 \n","Change of cost:  1.4078522140581473e-06\n","epoch 16\n","The cost at the end of this epoch is  0.1018802661680156\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 291.   4.   1.   0.   4.   0.   1.   6.   1.]\n"," [  5.   1. 245.   6.   2.   5.   8.   6.   8.   2.]\n"," [  2.   9.  17. 246.   1.  18.   0.   4.   3.   3.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  6.   3.   2.  15.   1. 251.   3.   0.   7.   2.]\n"," [  7.   2.   3.   0.   5.   8. 261.   0.   6.   0.]\n"," [  2.   7.   3.   2.   4.   0.   0. 262.   1.  11.]\n"," [  3.   6.   5.   9.   1.  17.   2.   1. 271.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   4. 238.]]\n","Accuracy Macro 0.8895107108471555 Precision Macro 0.8897118551066828\n","Change of the performance: 0.002268436578484967 0.0025477184743515346 \n","Change of cost:  0.00014863931445656398\n","epoch 17\n","The cost at the end of this epoch is  0.10181100947244312\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   1.   3.   0.]\n"," [  0. 289.   4.   1.   0.   4.   0.   1.   8.   1.]\n"," [  5.   1. 244.   6.   3.   5.   7.   6.   9.   2.]\n"," [  2.   8.  17. 244.   1.  18.   0.   5.   3.   5.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  6.   3.   2.  16.   1. 250.   3.   0.   7.   2.]\n"," [  7.   2.   3.   0.   5.   9. 260.   0.   6.   0.]\n"," [  2.   6.   3.   2.   4.   0.   0. 262.   1.  12.]\n"," [  2.   6.   5.   8.   1.  18.   2.   0. 272.  10.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   4. 239.]]\n","Accuracy Macro 0.8875383136864201 Precision Macro 0.8877772412362643\n","Change of the performance: 0.001972397160735384 0.001934613870418489 \n","Change of cost:  0.00018920155964143037\n","epoch 18\n","The cost at the end of this epoch is  0.10143053677497942\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 290.   5.   2.   0.   4.   0.   0.   6.   1.]\n"," [  5.   1. 245.   6.   2.   5.   8.   6.   8.   2.]\n"," [  2.   8.  18. 244.   1.  18.   0.   5.   3.   4.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  6.   3.   2.  15.   1. 250.   3.   0.   8.   2.]\n"," [  7.   2.   3.   0.   5.   8. 261.   0.   6.   0.]\n"," [  2.   6.   3.   2.   4.   0.   0. 263.   1.  11.]\n"," [  3.   6.   6.   9.   1.  16.   3.   2. 269.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   4. 238.]]\n","Accuracy Macro 0.88790632373248 Precision Macro 0.8878349680941794\n","Change of the performance: 0.00036801004605990784 5.77268579150525e-05 \n","Change of cost:  3.5933821342440386e-05\n","epoch 19\n","The cost at the end of this epoch is  0.10116178511021487\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 290.   4.   2.   0.   4.   0.   1.   6.   1.]\n"," [  5.   1. 245.   6.   3.   5.   7.   6.   8.   2.]\n"," [  2.   9.  17. 244.   1.  17.   0.   5.   3.   5.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  6.   3.   2.  16.   1. 250.   3.   0.   7.   2.]\n"," [  7.   2.   3.   0.   5.   8. 261.   0.   6.   0.]\n"," [  2.   6.   3.   1.   3.   0.   0. 265.   1.  11.]\n"," [  3.   6.   6.  10.   1.  17.   2.   2. 268.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   3. 239.]]\n","Accuracy Macro 0.8886599717545867 Precision Macro 0.8885064666547571\n","Change of the performance: 0.0007536480221066455 0.000671498560577688 \n","Change of cost:  4.043209546303328e-05\n","epoch 20\n","The cost at the end of this epoch is  0.10103430794323673\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 290.   4.   2.   0.   4.   0.   1.   6.   1.]\n"," [  5.   1. 245.   6.   3.   5.   7.   6.   8.   2.]\n"," [  2.   8.  17. 245.   1.  17.   0.   5.   3.   5.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  6.   3.   2.  16.   1. 250.   3.   0.   7.   2.]\n"," [  7.   2.   3.   0.   5.   8. 261.   0.   6.   0.]\n"," [  2.   6.   3.   2.   4.   0.   0. 263.   1.  11.]\n"," [  3.   6.   6.   9.   1.  17.   2.   2. 269.   9.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   3. 239.]]\n","Accuracy Macro 0.8886137152263464 Precision Macro 0.8885478620134359\n","Change of the performance: 4.6256528240307127e-05 4.1395358678864014e-05 \n","Change of cost:  3.888083650402385e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_13_350x785_10x351\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [400  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (400, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 401)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 400)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.11111507453599112\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 286.   5.   1.   0.   4.   0.   0.  11.   1.]\n"," [  5.   1. 241.   6.   3.   7.   7.   7.  10.   1.]\n"," [  2.   8.  17. 241.   1.  19.   0.   5.   4.   6.]\n"," [  4.   1.   2.   0. 300.   0.   4.   2.   2.   5.]\n"," [  7.   3.   2.  15.   1. 249.   5.   0.   7.   1.]\n"," [  9.   2.   4.   0.   4.  10. 258.   0.   5.   0.]\n"," [  2.   6.   4.   0.   3.   0.   0. 265.   1.  11.]\n"," [  4.   4.   7.   9.   1.  18.   3.   0. 268.  10.]\n"," [  1.   0.   0.   0.  14.   1.   0.   8.   4. 237.]]\n","Accuracy Macro 0.8822303407294825 Precision Macro 0.8825782926426526\n","epoch 1\n","The cost at the end of this epoch is  0.18724613763137582\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   3.   3.   1.   6.   1.   1.   3.   0.]\n"," [  0. 287.   5.   2.   0.   3.   0.   0.  10.   1.]\n"," [  5.   1. 247.   6.   0.   5.   8.   6.   9.   1.]\n"," [  3.   6.  25. 242.   0.  16.   0.   7.   3.   1.]\n"," [  4.   1.   2.   1. 281.   0.   3.   4.   4.  20.]\n"," [  5.   3.   2.  15.   0. 253.   3.   0.   9.   0.]\n"," [ 17.   3.   4.   0.   3.  12. 243.   0.   9.   1.]\n"," [  2.   3.   4.   1.   3.   1.   0. 273.   3.   2.]\n"," [  3.   4.   9.   6.   0.  13.   2.   1. 277.   9.]\n"," [  1.   0.   0.   1.   7.   1.   0.  16.   5. 234.]]\n","Accuracy Macro 0.8787152385413112 Precision Macro 0.8802291590377915\n","epoch 2\n","The cost at the end of this epoch is  0.12264861527654981\n","Now let's test the model after this epoch:\n","Confusion array  [[294.   0.   2.   3.   1.   9.   3.   1.   5.   0.]\n"," [  0. 293.   4.   1.   0.   4.   0.   0.   5.   1.]\n"," [  4.   2. 247.   7.   2.   4.   8.   5.   7.   2.]\n"," [  0.   9.  18. 246.   1.  16.   1.   4.   4.   4.]\n"," [  2.   1.   2.   1. 294.   3.   5.   2.   3.   7.]\n"," [  1.   3.   2.  16.   0. 257.   1.   0.  10.   0.]\n"," [  7.   2.   3.   0.   7.  12. 255.   0.   6.   0.]\n"," [  2.   6.   3.   2.   3.   0.   0. 264.   1.  11.]\n"," [  1.   9.   6.   9.   1.  18.   2.   1. 270.   7.]\n"," [  1.   0.   0.   0.  10.   1.   0.   7.   6. 240.]]\n","Accuracy Macro 0.8866694947710716 Precision Macro 0.8873409345881242\n","Change of the performance: 0.007954256229760426 0.007111775550332711 \n","Change of cost:  0.005744625093266523\n","epoch 3\n","The cost at the end of this epoch is  0.1774457287107038\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   2.   1.   6.   4.   0.   3.   0.]\n"," [  0. 284.   2.   1.   0.   5.   0.   0.  13.   3.]\n"," [  7.   6. 218.   7.   4.   8.   8.   8.  21.   1.]\n"," [  2.  10.  14. 229.   1.  29.   1.   3.   8.   6.]\n"," [  2.   1.   1.   0. 298.   1.   3.   1.   9.   4.]\n"," [  6.   3.   1.  13.   0. 255.   3.   0.   9.   0.]\n"," [  7.   2.   0.   0.   7.   9. 260.   0.   7.   0.]\n"," [  2.   8.   3.   2.   3.   0.   0. 258.   5.  11.]\n"," [  4.   5.   2.   7.   1.  16.   2.   0. 281.   6.]\n"," [  1.   0.   0.   0.  12.   1.   0.   7.   7. 237.]]\n","Accuracy Macro 0.8730639999497424 Precision Macro 0.8778298134930529\n","Change of the performance: 0.013605494821329223 0.009511121095071351 \n","Change of cost:  0.03823189292711743\n","epoch 4\n","The cost at the end of this epoch is  0.1375165663134493\n","Now let's test the model after this epoch:\n","Confusion array  [[295.   0.   2.   3.   1.   8.   3.   2.   4.   0.]\n"," [  0. 291.   5.   3.   0.   2.   0.   1.   5.   1.]\n"," [  4.   3. 240.  11.   2.   6.   5.   9.   7.   1.]\n"," [  0.   6.  16. 254.   1.  15.   0.   6.   2.   3.]\n"," [  0.   2.   3.   1. 296.   2.   3.   3.   3.   7.]\n"," [  2.   3.   1.  18.   0. 256.   1.   0.   8.   1.]\n"," [  9.   3.   6.   0.   5.  12. 246.   0.  11.   0.]\n"," [  2.   5.   3.   2.   2.   0.   0. 269.   1.   8.]\n"," [  2.  10.   9.  12.   1.  17.   1.   2. 264.   6.]\n"," [  1.   0.   0.   1.  11.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8839801340401816 Precision Macro 0.8848398602229459\n","Change of the performance: 0.010916134090439233 0.007010046729893027 \n","Change of cost:  0.005168394827109873\n","epoch 5\n","The cost at the end of this epoch is  0.10583791045953041\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 290.   4.   1.   0.   4.   0.   1.   7.   1.]\n"," [  5.   1. 243.   7.   2.   5.   8.   6.   9.   2.]\n"," [  2.   9.  19. 242.   1.  17.   1.   5.   2.   5.]\n"," [  3.   0.   2.   0. 295.   0.   4.   2.   3.  11.]\n"," [  7.   3.   1.  17.   1. 249.   3.   0.   7.   2.]\n"," [  8.   2.   3.   0.   5.   9. 259.   0.   6.   0.]\n"," [  2.   4.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  3.   6.   6.   8.   1.  15.   2.   1. 273.   9.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8867914879033464 Precision Macro 0.8863435747557732\n","Change of the performance: 0.0028113538631647783 0.0015037145328272716 \n","Change of cost:  4.9713182425026314e-05\n","epoch 6\n","The cost at the end of this epoch is  0.1034932516753065\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   3.   3.   1.   3.   4.   2.   2.   0.]\n"," [  0. 291.   4.   2.   0.   3.   0.   1.   6.   1.]\n"," [  4.   1. 247.   6.   2.   5.   9.   7.   6.   1.]\n"," [  2.   9.  20. 245.   1.  15.   1.   5.   1.   4.]\n"," [  2.   1.   3.   0. 303.   0.   3.   1.   3.   4.]\n"," [  4.   3.   2.  16.   1. 253.   2.   0.   8.   1.]\n"," [  7.   2.   3.   0.   5.   9. 259.   0.   7.   0.]\n"," [  2.   4.   3.   2.   2.   0.   0. 270.   1.   8.]\n"," [  2.   9.   7.   9.   1.  16.   2.   2. 270.   6.]\n"," [  1.   0.   0.   0.  14.   1.   0.  10.   3. 236.]]\n","Accuracy Macro 0.8909253167984057 Precision Macro 0.8909339388618316\n","Change of the performance: 0.0041338288950593105 0.004590364106058398 \n","Change of cost:  0.0008593883531584218\n","epoch 7\n","The cost at the end of this epoch is  0.10221288702254072\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   2.   3.   1.   3.   3.   1.   2.   0.]\n"," [  0. 291.   4.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   1. 244.   7.   2.   6.   8.   7.   7.   1.]\n"," [  3.   8.  18. 245.   1.  16.   1.   5.   1.   5.]\n"," [  3.   0.   2.   0. 302.   0.   4.   1.   2.   6.]\n"," [  7.   3.   2.  16.   1. 247.   5.   0.   6.   3.]\n"," [  8.   2.   3.   0.   5.   9. 259.   0.   6.   0.]\n"," [  1.   4.   3.   2.   2.   0.   0. 268.   1.  11.]\n"," [  3.   8.   6.   9.   1.  14.   2.   2. 270.   9.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8896474417868934 Precision Macro 0.8890774491883132\n","Change of the performance: 0.0012778750115123305 0.001856489673518369 \n","Change of cost:  0.0011203757968418493\n","epoch 8\n","The cost at the end of this epoch is  0.10046817268443722\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   3.   1.   4.   4.   2.   2.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   1.   7.   1.]\n"," [  5.   1. 245.   6.   3.   5.   7.   7.   8.   1.]\n"," [  2.   7.  17. 246.   1.  17.   0.   5.   3.   5.]\n"," [  2.   0.   2.   0. 302.   0.   4.   1.   3.   6.]\n"," [  5.   3.   2.  16.   1. 250.   3.   0.   8.   2.]\n"," [  8.   2.   3.   0.   5.   9. 258.   0.   7.   0.]\n"," [  2.   4.   3.   2.   2.   0.   0. 265.   1.  13.]\n"," [  2.   7.   5.   9.   1.  14.   2.   1. 273.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   3. 240.]]\n","Accuracy Macro 0.8898987434592176 Precision Macro 0.8896899716741146\n","Change of the performance: 0.0002513016723242334 0.0006125224858013478 \n","Change of cost:  0.0001852604064296326\n","epoch 9\n","The cost at the end of this epoch is  0.10157264387251097\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   4.   4.   3.   2.   0.]\n"," [  0. 291.   4.   1.   0.   4.   0.   1.   6.   1.]\n"," [  4.   1. 243.   7.   3.   5.   8.   6.   9.   2.]\n"," [  2.   8.  20. 243.   1.  17.   0.   5.   3.   4.]\n"," [  3.   1.   2.   0. 301.   0.   3.   1.   3.   6.]\n"," [  6.   3.   2.  16.   1. 249.   3.   0.   8.   2.]\n"," [  7.   2.   4.   0.   5.   9. 259.   0.   6.   0.]\n"," [  2.   5.   3.   3.   2.   0.   0. 262.   1.  14.]\n"," [  3.   8.   5.   8.   1.  17.   2.   2. 269.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   6.   2. 243.]]\n","Accuracy Macro 0.8864651929893448 Precision Macro 0.8861195297950317\n","Change of the performance: 0.0034335504698728148 0.003570441879082842 \n","Change of cost:  0.0016237069798353543\n","epoch 10\n","The cost at the end of this epoch is  0.09856032897211325\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   4.   4.   1.   2.   0.]\n"," [  0. 291.   4.   1.   0.   4.   0.   1.   6.   1.]\n"," [  5.   1. 246.   6.   3.   5.   7.   5.   8.   2.]\n"," [  2.   7.  17. 243.   1.  19.   0.   5.   4.   5.]\n"," [  1.   0.   2.   0. 302.   1.   4.   1.   2.   7.]\n"," [  5.   3.   2.  14.   1. 252.   4.   0.   8.   1.]\n"," [  7.   2.   3.   0.   5.   9. 260.   0.   6.   0.]\n"," [  2.   4.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  2.   8.   5.   8.   1.  18.   2.   2. 269.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8897485611188622 Precision Macro 0.8896154271996576\n","Change of the performance: 0.003283368129517461 0.0034958974046258584 \n","Change of cost:  0.0016146678126973957\n","epoch 11\n","The cost at the end of this epoch is  0.09894149394498726\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   3.   3.   3.   2.   0.]\n"," [  0. 292.   4.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 246.   7.   3.   5.   7.   6.   6.   2.]\n"," [  2.   9.  17. 246.   1.  16.   0.   5.   3.   4.]\n"," [  2.   1.   3.   0. 302.   0.   3.   1.   2.   6.]\n"," [  7.   3.   1.  16.   1. 248.   4.   0.   7.   3.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  2.   6.   3.   1.   2.   0.   0. 266.   1.  11.]\n"," [  3.   9.   5.   9.   1.  15.   2.   2. 268.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   3. 240.]]\n","Accuracy Macro 0.8886624512818335 Precision Macro 0.8883778165995802\n","Change of the performance: 0.0010861098370287259 0.0012376106000774323 \n","Change of cost:  5.298518161289678e-05\n","epoch 12\n","The cost at the end of this epoch is  0.09818860429614876\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 292.   4.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 244.   7.   3.   5.   7.   6.   8.   2.]\n"," [  2.   9.  19. 243.   1.  17.   0.   5.   2.   5.]\n"," [  2.   1.   2.   0. 302.   0.   3.   1.   2.   7.]\n"," [  6.   3.   2.  15.   1. 250.   4.   0.   7.   2.]\n"," [  8.   2.   3.   0.   5.   9. 258.   0.   7.   0.]\n"," [  2.   5.   3.   2.   2.   0.   0. 264.   1.  13.]\n"," [  3.   8.   5.   8.   1.  18.   2.   2. 268.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   7.   3. 241.]]\n","Accuracy Macro 0.8877024557370433 Precision Macro 0.8875100020692015\n","Change of the performance: 0.0009599955447902042 0.0008678145303786522 \n","Change of cost:  0.0004173191038300411\n","epoch 13\n","The cost at the end of this epoch is  0.09739666581525126\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   4.   2.   2.   0.]\n"," [  0. 291.   4.   1.   0.   4.   0.   1.   6.   1.]\n"," [  5.   1. 245.   6.   3.   5.   7.   6.   8.   2.]\n"," [  2.   8.  17. 243.   1.  17.   1.   5.   4.   5.]\n"," [  2.   1.   2.   0. 302.   0.   3.   1.   2.   7.]\n"," [  7.   3.   1.  15.   1. 252.   3.   0.   7.   1.]\n"," [  8.   2.   3.   0.   5.   9. 258.   0.   7.   0.]\n"," [  2.   4.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  3.   8.   5.   9.   1.  18.   2.   2. 267.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8880991234391736 Precision Macro 0.8879228428797014\n","Change of the performance: 0.00039666770213031555 0.0004128408104998593 \n","Change of cost:  0.00041103580418960783\n","epoch 14\n","The cost at the end of this epoch is  0.09694863396082297\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 292.   4.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 246.   7.   3.   5.   7.   5.   7.   2.]\n"," [  2.   8.  17. 244.   1.  17.   0.   5.   4.   5.]\n"," [  3.   0.   2.   0. 302.   0.   4.   1.   2.   6.]\n"," [  6.   3.   2.  15.   1. 251.   3.   0.   7.   2.]\n"," [  9.   2.   4.   0.   5.   9. 256.   0.   7.   0.]\n"," [  2.   4.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  2.   8.   5.   9.   1.  17.   2.   2. 269.   9.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8893804027463034 Precision Macro 0.8892163042118982\n","Change of the performance: 0.0012812793071297346 0.0012934613321968769 \n","Change of cost:  2.4406386935668656e-05\n","epoch 15\n","The cost at the end of this epoch is  0.09690544266651306\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 291.   4.   1.   0.   4.   0.   1.   6.   1.]\n"," [  5.   1. 246.   6.   3.   5.   7.   5.   8.   2.]\n"," [  2.   7.  19. 243.   1.  18.   0.   5.   3.   5.]\n"," [  2.   0.   2.   0. 301.   0.   5.   1.   2.   7.]\n"," [  7.   3.   1.  14.   1. 252.   3.   0.   7.   2.]\n"," [  9.   2.   3.   0.   5.   9. 258.   0.   6.   0.]\n"," [  2.   4.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  3.   8.   6.   9.   1.  18.   2.   2. 267.   8.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.889140134969572 Precision Macro 0.8889721681112339\n","Change of the performance: 0.00024026777673136213 0.00024413610066431612 \n","Change of cost:  0.00021315380681775908\n","epoch 16\n","The cost at the end of this epoch is  0.09649956493211223\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 292.   4.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 246.   7.   3.   5.   7.   5.   7.   2.]\n"," [  2.   8.  18. 244.   1.  18.   0.   5.   3.   4.]\n"," [  3.   1.   2.   0. 302.   0.   3.   1.   2.   6.]\n"," [  7.   3.   1.  14.   1. 252.   4.   0.   6.   2.]\n"," [  9.   2.   4.   0.   5.   9. 256.   0.   7.   0.]\n"," [  2.   6.   3.   2.   2.   0.   0. 265.   1.  11.]\n"," [  2.   8.   5.   9.   1.  16.   2.   2. 269.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8893827645790857 Precision Macro 0.8893138785908403\n","Change of the performance: 0.00024262960951371149 0.0003417104796064052 \n","Change of cost:  3.252292208544283e-06\n","epoch 17\n","The cost at the end of this epoch is  0.09623171282948245\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 291.   4.   1.   0.   4.   0.   1.   6.   1.]\n"," [  5.   1. 245.   7.   3.   5.   7.   6.   8.   1.]\n"," [  2.   8.  18. 243.   1.  18.   0.   5.   3.   5.]\n"," [  3.   0.   2.   0. 302.   0.   4.   1.   2.   6.]\n"," [  7.   3.   1.  14.   1. 253.   3.   0.   7.   1.]\n"," [  9.   2.   3.   0.   5.   9. 258.   0.   6.   0.]\n"," [  2.   4.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  2.   8.   5.   9.   1.  17.   2.   2. 268.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.88944441690006 Precision Macro 0.8893052655265865\n","Change of the performance: 6.165232097432582e-05 8.61306425381514e-06 \n","Change of cost:  8.67240607380082e-06\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_14_400x785_10x401\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [450  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (450, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 451)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 450)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.1276111428060553\n","Now let's test the model after this epoch:\n","Confusion array  [[293.   0.   2.   2.   1.  11.   3.   0.   6.   0.]\n"," [  0. 286.   4.   2.   0.   4.   0.   1.  10.   1.]\n"," [  4.   1. 241.   7.   3.   7.   7.   8.   9.   1.]\n"," [  0.   8.  14. 241.   1.  23.   0.   5.   5.   6.]\n"," [  0.   1.   1.   0. 301.   3.   3.   2.   2.   7.]\n"," [  2.   3.   1.  13.   1. 257.   1.   0.  10.   2.]\n"," [  8.   2.   3.   0.   8.  14. 250.   0.   7.   0.]\n"," [  1.   4.   3.   1.   2.   0.   0. 269.   1.  11.]\n"," [  1.   5.   4.   8.   1.  20.   2.   1. 271.  11.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   3. 239.]]\n","Accuracy Macro 0.882467587224447 Precision Macro 0.8846283367673893\n","epoch 1\n","The cost at the end of this epoch is  0.18237940712872322\n","Now let's test the model after this epoch:\n","Confusion array  [[305.   0.   3.   1.   1.   2.   3.   0.   2.   1.]\n"," [  0. 288.   4.   2.   0.   3.   0.   1.   9.   1.]\n"," [  9.   1. 240.   6.   2.   2.  11.   3.  12.   2.]\n"," [  3.   7.  22. 240.   1.  17.   0.   4.   5.   4.]\n"," [  3.   1.   2.   1. 295.   0.  11.   1.   3.   3.]\n"," [  8.   6.   1.  16.   1. 230.  10.   0.  15.   3.]\n"," [ 10.   1.   4.   0.   5.   6. 262.   0.   4.   0.]\n"," [  2.   3.   4.   0.   6.   0.   0. 255.   3.  19.]\n"," [  2.   7.   6.   6.   1.  17.   7.   1. 268.   9.]\n"," [  1.   0.   1.   0.  13.   1.   0.   4.   3. 242.]]\n","Accuracy Macro 0.874549140765272 Precision Macro 0.8749101257861955\n","epoch 2\n","The cost at the end of this epoch is  0.14384148692000745\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   2.   3.   1.   2.   4.   2.   1.   0.]\n"," [  0. 289.   2.   5.   0.   3.   1.   2.   6.   0.]\n"," [  4.   1. 241.  12.   3.   4.   7.   8.   7.   1.]\n"," [  2.   2.  16. 255.   1.  13.   0.   7.   3.   4.]\n"," [  0.   2.   2.   1. 301.   2.   4.   3.   2.   3.]\n"," [  5.   3.   2.  14.   1. 257.   1.   0.   7.   0.]\n"," [  5.   3.   4.   0.   5.  10. 260.   0.   5.   0.]\n"," [  2.   3.   2.   1.   2.   0.   0. 274.   2.   6.]\n"," [  2.   8.   9.  11.   2.  24.   2.   2. 258.   6.]\n"," [  1.   0.   0.   1.  15.   1.   0.  13.   2. 232.]]\n","Accuracy Macro 0.8896898605211229 Precision Macro 0.8903510353833036\n","Change of the performance: 0.015140719755850851 0.015440909597108088 \n","Change of cost:  0.004624032730503463\n","epoch 3\n","The cost at the end of this epoch is  0.10656303138132214\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   2.   3.   1.   2.   3.   1.   2.   0.]\n"," [  0. 289.   4.   1.   0.   4.   0.   1.   8.   1.]\n"," [  6.   1. 240.   6.   3.   8.   8.   8.   7.   1.]\n"," [  3.   5.  16. 244.   1.  21.   0.   6.   2.   5.]\n"," [  2.   1.   2.   0. 302.   1.   4.   1.   3.   4.]\n"," [  8.   3.   1.  13.   1. 254.   3.   0.   6.   1.]\n"," [  6.   2.   5.   0.   5.   8. 258.   0.   8.   0.]\n"," [  2.   2.   3.   1.   2.   0.   0. 267.   3.  12.]\n"," [  4.   4.   5.   8.   1.  18.   3.   1. 270.  10.]\n"," [  1.   0.   1.   1.  12.   1.   0.   8.   1. 240.]]\n","Accuracy Macro 0.8889451377601916 Precision Macro 0.889207913178921\n","Change of the performance: 0.0007447227609312934 0.0011431222043826184 \n","Change of cost:  0.0012093319376786232\n","epoch 4\n","The cost at the end of this epoch is  0.10249278857428888\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   4.   1.   5.   4.   1.   2.   0.]\n"," [  0. 293.   2.   3.   0.   3.   0.   1.   5.   1.]\n"," [  4.   2. 242.   8.   3.   5.   7.   8.   8.   1.]\n"," [  2.   8.  16. 248.   1.  17.   0.   4.   2.   5.]\n"," [  1.   1.   2.   1. 297.   2.   3.   2.   3.   8.]\n"," [  4.   3.   2.  16.   1. 252.   2.   0.   8.   2.]\n"," [  7.   2.   4.   0.   5.   9. 258.   0.   7.   0.]\n"," [  1.   4.   3.   3.   2.   0.   0. 266.   1.  12.]\n"," [  2.   9.   4.  11.   1.  18.   3.   1. 261.  14.]\n"," [  1.   0.   0.   1.  11.   1.   0.   7.   2. 242.]]\n","Accuracy Macro 0.8860684067500293 Precision Macro 0.8856460621843887\n","Change of the performance: 0.002876731010162281 0.003561850994532323 \n","Change of cost:  0.0007348350568134737\n","epoch 5\n","The cost at the end of this epoch is  0.10376799454527796\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 289.   3.   2.   0.   4.   0.   1.   8.   1.]\n"," [  4.   1. 243.   7.   3.   8.   8.   7.   6.   1.]\n"," [  2.   7.  19. 245.   1.  17.   0.   5.   2.   5.]\n"," [  1.   1.   2.   0. 300.   1.   3.   2.   3.   7.]\n"," [  4.   3.   2.  16.   1. 251.   2.   0.  10.   1.]\n"," [  8.   2.   4.   0.   5.   8. 257.   0.   8.   0.]\n"," [  2.   4.   6.   2.   2.   0.   0. 263.   1.  12.]\n"," [  2.   3.   5.   9.   1.  16.   3.   1. 274.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.887928021478605 Precision Macro 0.8879154219820411\n","Change of the performance: 0.0018596147285756537 0.002269359797652415 \n","Change of cost:  0.00449073917499386\n","epoch 6\n","The cost at the end of this epoch is  0.09638123724462283\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   5.   3.   2.   3.   0.]\n"," [  0. 292.   4.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 242.   7.   3.   7.   7.   7.   8.   1.]\n"," [  2.   8.  18. 245.   1.  15.   1.   5.   3.   5.]\n"," [  2.   1.   2.   0. 296.   2.   3.   1.   4.   9.]\n"," [  4.   3.   2.  16.   1. 252.   2.   0.   8.   2.]\n"," [  8.   2.   3.   0.   5.   9. 258.   0.   7.   0.]\n"," [  2.   5.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  2.   7.   5.   9.   1.  14.   4.   1. 271.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8874646590867785 Precision Macro 0.8871543752444051\n","Change of the performance: 0.00046336239182642736 0.0007610467376359953 \n","Change of cost:  0.0009677769557515925\n","epoch 7\n","The cost at the end of this epoch is  0.10008809858222836\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   2.   3.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   4. 237.   7.   3.   4.   7.  11.   9.   1.]\n"," [  2.  11.  17. 243.   1.  15.   1.   5.   3.   5.]\n"," [  1.   1.   1.   0. 299.   1.   3.   1.   3.  10.]\n"," [  6.   3.   2.  16.   1. 247.   2.   0.   9.   4.]\n"," [  8.   2.   3.   0.   5.   8. 258.   0.   8.   0.]\n"," [  1.   4.   3.   2.   2.   0.   0. 268.   1.  11.]\n"," [  4.   8.   5.   8.   1.  11.   3.   2. 272.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8859145582536705 Precision Macro 0.8855820797413264\n","Change of the performance: 0.0015501008331080257 0.0015722955030786911 \n","Change of cost:  0.003916979724954486\n","epoch 8\n","The cost at the end of this epoch is  0.09713422491241366\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 293.   3.   1.   0.   5.   0.   1.   4.   1.]\n"," [  4.   1. 244.   7.   3.   6.   8.   6.   7.   2.]\n"," [  2.   8.  19. 246.   1.  16.   0.   5.   2.   4.]\n"," [  1.   1.   3.   0. 300.   1.   4.   2.   2.   6.]\n"," [  5.   3.   2.  15.   1. 251.   2.   0.   8.   3.]\n"," [  7.   2.   5.   0.   5.   9. 257.   0.   7.   0.]\n"," [  2.   5.   3.   3.   2.   0.   0. 262.   1.  14.]\n"," [  2.  10.   5.   8.   1.  19.   4.   2. 264.   9.]\n"," [  1.   0.   0.   0.  11.   1.   0.   5.   3. 244.]]\n","Accuracy Macro 0.8876071679680161 Precision Macro 0.8872413005093108\n","Change of the performance: 0.0016926097143455943 0.001659220767984415 \n","Change of cost:  0.0032327369400065725\n","epoch 9\n","The cost at the end of this epoch is  0.09350013411367931\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   1.   7.   1.]\n"," [  5.   1. 242.   7.   3.   8.   7.   7.   7.   1.]\n"," [  2.   7.  18. 245.   1.  18.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 300.   1.   5.   1.   2.   8.]\n"," [  6.   3.   2.  14.   1. 254.   2.   0.   7.   1.]\n"," [  9.   2.   3.   0.   5.   8. 258.   0.   7.   0.]\n"," [  2.   5.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  3.   7.   5.   9.   1.  13.   4.   1. 271.  10.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8890065359368856 Precision Macro 0.8887971081969297\n","Change of the performance: 0.0013993679688695249 0.001555807687618871 \n","Change of cost:  0.001731240548531604\n","epoch 10\n","The cost at the end of this epoch is  0.09281363093668632\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   5.   3.   2.   3.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  4.   1. 245.   8.   3.   6.   7.   7.   6.   1.]\n"," [  1.   8.  17. 245.   1.  19.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 299.   2.   5.   1.   2.   8.]\n"," [  5.   3.   2.  14.   1. 255.   2.   0.   7.   1.]\n"," [  8.   2.   4.   0.   5.   9. 257.   0.   7.   0.]\n"," [  2.   5.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   7.   5.   9.   1.  15.   4.   2. 270.   9.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.889809410354583 Precision Macro 0.8895676015908285\n","Change of the performance: 0.0008028744176974412 0.0007704933938987857 \n","Change of cost:  0.0009219323734515339\n","epoch 11\n","The cost at the end of this epoch is  0.09245632397358128\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 244.   7.   3.   6.   7.   7.   7.   1.]\n"," [  2.   8.  17. 244.   1.  19.   0.   5.   2.   5.]\n"," [  2.   0.   1.   0. 300.   1.   5.   1.   2.   8.]\n"," [  6.   3.   2.  14.   1. 254.   2.   0.   7.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  2.   5.   3.   3.   2.   0.   0. 263.   1.  13.]\n"," [  2.   8.   5.   9.   1.  17.   4.   1. 266.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8877463658706188 Precision Macro 0.8876326706745955\n","Change of the performance: 0.002063044483964216 0.0019349309162329797 \n","Change of cost:  0.0008738226617678729\n","epoch 12\n","The cost at the end of this epoch is  0.09180802771205551\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   5.   3.   2.   3.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 244.   7.   3.   6.   7.   7.   7.   1.]\n"," [  1.   7.  17. 247.   1.  18.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 299.   2.   5.   1.   2.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  1.   5.   3.   2.   2.   0.   0. 265.   1.  13.]\n"," [  2.   7.   5.   9.   1.  14.   4.   1. 271.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8904308961142704 Precision Macro 0.8901729228202264\n","Change of the performance: 0.0026845302436515617 0.002540252145630917 \n","Change of cost:  0.00014230131902912002\n","epoch 13\n","The cost at the end of this epoch is  0.09168008743647399\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   5.   3.   1.   3.   0.]\n"," [  0. 293.   3.   1.   0.   5.   0.   1.   4.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  1.   7.  19. 245.   1.  18.   0.   5.   2.   5.]\n"," [  2.   0.   1.   0. 302.   1.   5.   1.   2.   6.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  8.   2.   4.   0.   5.   9. 257.   0.   7.   0.]\n"," [  2.   4.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  3.   7.   5.   9.   1.  21.   4.   2. 262.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8889347057143437 Precision Macro 0.8888110454743495\n","Change of the performance: 0.0014961903999266557 0.001361877345876894 \n","Change of cost:  0.0005525265757011233\n","epoch 14\n","The cost at the end of this epoch is  0.09070279023923013\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 244.   7.   3.   6.   7.   7.   7.   1.]\n"," [  2.   7.  19. 247.   1.  14.   1.   5.   2.   5.]\n"," [  2.   0.   2.   0. 298.   2.   5.   1.   3.   7.]\n"," [  4.   3.   2.  14.   1. 254.   2.   0.   9.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  2.   5.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   7.   5.   9.   1.  14.   4.   2. 269.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8900996808038611 Precision Macro 0.8896730838121375\n","Change of the performance: 0.001164975089517406 0.0008620383377879737 \n","Change of cost:  0.00012113969688057336\n","epoch 15\n","The cost at the end of this epoch is  0.09027533214872337\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  1.   7.  18. 247.   1.  17.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 299.   2.   5.   1.   2.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  2.   5.   3.   2.   2.   0.   0. 264.   1.  13.]\n"," [  3.   7.   5.   9.   1.  16.   4.   2. 268.   9.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.890138657474752 Precision Macro 0.8899237545214799\n","Change of the performance: 3.897667089081125e-05 0.000250670709342371 \n","Change of cost:  3.327207812135746e-05\n","epoch 16\n","The cost at the end of this epoch is  0.09010220198667945\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 244.   7.   3.   6.   7.   7.   7.   1.]\n"," [  2.   8.  19. 244.   1.  17.   0.   5.   2.   5.]\n"," [  2.   0.   2.   0. 298.   2.   5.   1.   3.   7.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  2.   5.   3.   2.   2.   0.   0. 264.   1.  13.]\n"," [  2.   7.   5.   9.   1.  15.   4.   2. 270.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.88872876170268 Precision Macro 0.8885762871386532\n","Change of the performance: 0.0014098957720719563 0.0013474673828266504 \n","Change of cost:  8.125443046440306e-05\n","epoch 17\n","The cost at the end of this epoch is  0.08990406834669552\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   6.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  1.   7.  19. 246.   1.  17.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 297.   2.   6.   1.   3.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  2.   5.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  2.   7.   5.   9.   1.  15.   4.   2. 270.   9.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8901713745201132 Precision Macro 0.8899222413818842\n","Change of the performance: 0.0014426128174331865 0.001345954243231029 \n","Change of cost:  5.382515330110138e-07\n","epoch 18\n","The cost at the end of this epoch is  0.08963585774582623\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  2.   7.  19. 246.   1.  16.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 299.   1.   5.   1.   3.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  1.   5.   3.   2.   2.   0.   0. 265.   1.  13.]\n"," [  3.   7.   5.   9.   1.  15.   4.   2. 269.   9.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8907741976089898 Precision Macro 0.8904168002908582\n","Change of the performance: 0.0006028230888766029 0.0004945589089739855 \n","Change of cost:  6.281166868994659e-05\n","epoch 19\n","The cost at the end of this epoch is  0.08947490386360715\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  1.   7.  19. 246.   1.  17.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 298.   2.   5.   1.   3.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  2.   5.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  2.   7.   5.   9.   1.  15.   4.   2. 269.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8904896979536095 Precision Macro 0.8902073526971991\n","Change of the performance: 0.0002844996553802437 0.0002094475936591511 \n","Change of cost:  2.6501249103860758e-05\n","epoch 20\n","The cost at the end of this epoch is  0.08936879483843467\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   3.   1.   4.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  2.   7.  19. 246.   1.  15.   1.   5.   2.   5.]\n"," [  1.   0.   2.   0. 298.   2.   5.   1.   3.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  1.   5.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  3.   7.   5.   9.   1.  14.   4.   2. 269.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8908041633624146 Precision Macro 0.8903556835154856\n","Change of the performance: 0.0003144654088050869 0.00014833081828646844 \n","Change of cost:  1.440437629239566e-05\n","epoch 21\n","The cost at the end of this epoch is  0.08924268055393075\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  2.   7.  18. 246.   1.  17.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 298.   2.   5.   1.   3.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  1.   5.   3.   2.   2.   0.   0. 265.   1.  13.]\n"," [  3.   7.   5.   9.   1.  15.   4.   1. 268.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8898385902248762 Precision Macro 0.8895528334171979\n","Change of the performance: 0.0009655731375384224 0.0008028500982876219 \n","Change of cost:  2.052846003255948e-06\n","epoch 22\n","The cost at the end of this epoch is  0.08916060547042627\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  2.   7.  19. 246.   1.  16.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 298.   2.   5.   1.   3.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  1.   5.   3.   2.   2.   0.   0. 265.   1.  13.]\n"," [  3.   7.   5.   9.   1.  15.   4.   2. 267.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8895299482495677 Precision Macro 0.8891521841270242\n","Change of the performance: 0.00030864197530855453 0.00040064929017369355 \n","Change of cost:  4.677891876955775e-06\n","epoch 23\n","The cost at the end of this epoch is  0.08910394923622485\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  2.   7.  19. 246.   1.  16.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 298.   2.   5.   1.   3.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  1.   5.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  2.   7.   5.   9.   1.  15.   4.   2. 269.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8904896979536095 Precision Macro 0.8901560910100945\n","Change of the performance: 0.0009597497040418901 0.0010039068830702824 \n","Change of cost:  8.100054778442667e-06\n","epoch 24\n","The cost at the end of this epoch is  0.08905022933634091\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  2.   7.  19. 246.   1.  16.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 298.   2.   5.   1.   3.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  1.   5.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  2.   7.   5.   9.   1.  15.   4.   2. 268.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8901810559783009 Precision Macro 0.8898087646914776\n","Change of the performance: 0.00030864197530866555 0.0003473263186168918 \n","Change of cost:  6.106390701282605e-07\n","epoch 25\n","The cost at the end of this epoch is  0.0890100017506292\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   1.   0.   4.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   7.   7.   6.   1.]\n"," [  2.   7.  19. 246.   1.  16.   0.   5.   2.   5.]\n"," [  1.   0.   2.   0. 298.   2.   5.   1.   3.   8.]\n"," [  4.   3.   2.  14.   1. 255.   2.   0.   8.   1.]\n"," [  9.   2.   4.   0.   5.   9. 257.   0.   6.   0.]\n"," [  1.   5.   3.   2.   2.   0.   0. 266.   1.  12.]\n"," [  2.   7.   5.   9.   1.  15.   4.   2. 268.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8901810559783009 Precision Macro 0.8898087646914776\n","Change of the performance: 0.0 0.0 \n","Change of cost:  5.278664000518685e-06\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_15_450x785_10x451\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [500  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (500, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 501)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 500)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.09829787014738554\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   5.   3.   1.   3.   0.]\n"," [  0. 291.   3.   1.   0.   4.   0.   1.   7.   1.]\n"," [  5.   0. 242.   8.   3.   6.   8.   8.   7.   1.]\n"," [  2.   7.  18. 246.   1.  19.   0.   4.   2.   4.]\n"," [  2.   1.   1.   0. 297.   1.   4.   1.   4.   9.]\n"," [  5.   3.   1.  15.   1. 253.   2.   0.  10.   0.]\n"," [ 10.   2.   4.   0.   5.   9. 255.   0.   7.   0.]\n"," [  2.   3.   3.   3.   2.   0.   0. 267.   2.  10.]\n"," [  2.   5.   5.   9.   1.  16.   3.   0. 272.  11.]\n"," [  1.   0.   0.   1.  11.   1.   0.   7.   2. 242.]]\n","Accuracy Macro 0.8884428787194407 Precision Macro 0.8885960960191188\n","epoch 1\n","The cost at the end of this epoch is  0.09138302583690189\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   4.   1.   4.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 243.   7.   3.   6.   7.   7.   8.   1.]\n"," [  2.   8.  16. 246.   1.  17.   0.   5.   3.   5.]\n"," [  2.   0.   0.   0. 297.   2.   5.   2.   4.   8.]\n"," [  4.   3.   1.  14.   1. 254.   2.   0.  10.   1.]\n"," [  6.   2.   5.   0.   5.   9. 258.   0.   7.   0.]\n"," [  1.   7.   3.   1.   2.   0.   0. 263.   1.  14.]\n"," [  2.   7.   5.   8.   1.  14.   4.   2. 271.  10.]\n"," [  1.   0.   0.   0.  12.   1.   0.   7.   4. 240.]]\n","Accuracy Macro 0.8883784544673551 Precision Macro 0.8882467259574908\n","epoch 2\n","The cost at the end of this epoch is  0.09031738225127993\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   0. 244.   8.   3.   7.   7.   7.   6.   1.]\n"," [  1.   7.  18. 245.   1.  19.   0.   5.   2.   5.]\n"," [  2.   0.   1.   0. 297.   2.   4.   3.   4.   7.]\n"," [  5.   3.   2.  14.   1. 255.   2.   0.   8.   0.]\n"," [ 11.   2.   4.   0.   6.   9. 254.   0.   6.   0.]\n"," [  2.   5.   3.   3.   2.   0.   0. 266.   1.  10.]\n"," [  2.   7.   4.   9.   1.  15.   3.   1. 270.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8884565121184463 Precision Macro 0.8885047422566871\n","Change of the performance: 7.805765109125673e-05 0.0002580162991963064 \n","Change of cost:  0.0010719864156326087\n","epoch 3\n","The cost at the end of this epoch is  0.09367178290450068\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   2.   1.   7.   3.   1.   4.   0.]\n"," [  0. 290.   4.   2.   0.   3.   0.   1.   7.   1.]\n"," [  5.   1. 242.   7.   3.   6.   8.   7.   8.   1.]\n"," [  1.   8.  17. 243.   1.  19.   1.   6.   2.   5.]\n"," [  1.   0.   1.   0. 302.   2.   3.   1.   3.   7.]\n"," [  4.   4.   2.  13.   1. 254.   2.   0.   8.   2.]\n"," [  8.   2.   5.   0.   7.   9. 254.   0.   7.   0.]\n"," [  1.   5.   3.   1.   3.   0.   0. 268.   1.  10.]\n"," [  2.   6.   4.  10.   1.  14.   3.   1. 270.  13.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.887411858712278 Precision Macro 0.8874295061112945\n","Change of the performance: 0.0010446534061683277 0.0010752361453926218 \n","Change of cost:  0.0013956415580711895\n","epoch 4\n","The cost at the end of this epoch is  0.09046297844999092\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   2.   1.   6.   3.   1.   2.   0.]\n"," [  0. 290.   3.   2.   0.   3.   0.   1.   8.   1.]\n"," [  5.   1. 242.   7.   2.   6.   9.   6.   8.   2.]\n"," [  2.   8.  18. 242.   1.  20.   0.   5.   2.   5.]\n"," [  2.   0.   1.   0. 297.   2.   5.   1.   4.   8.]\n"," [  4.   3.   1.  13.   1. 256.   2.   0.   9.   1.]\n"," [  9.   2.   5.   0.   5.   9. 256.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 263.   1.  14.]\n"," [  2.   7.   5.   8.   1.  17.   3.   0. 270.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.   7.   2. 241.]]\n","Accuracy Macro 0.8861249798475324 Precision Macro 0.8862842544890446\n","Change of the performance: 0.0012868788647456553 0.0011452516222498765 \n","Change of cost:  0.00011874254234950365\n","epoch 5\n","The cost at the end of this epoch is  0.12390253731495839\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   1.   4.   1.   5.   1.   0.   3.   0.]\n"," [  0. 296.   2.   3.   0.   2.   0.   1.   4.   0.]\n"," [  4.   3. 240.   9.   3.   5.   7.   6.  10.   1.]\n"," [  2.   9.  16. 250.   0.  14.   0.   7.   2.   3.]\n"," [  3.   2.   2.   0. 291.   1.   4.   2.   3.  12.]\n"," [  4.   3.   1.  16.   0. 255.   2.   0.   8.   1.]\n"," [ 11.   3.   6.   0.   7.   8. 250.   0.   7.   0.]\n"," [  2.   8.   3.   0.   2.   1.   0. 269.   2.   5.]\n"," [  4.   9.   8.   9.   0.  15.   3.   1. 259.  16.]\n"," [  1.   1.   0.   1.  11.   1.   0.  12.   2. 236.]]\n","Accuracy Macro 0.8828316350189157 Precision Macro 0.882788238101529\n","Change of the performance: 0.003293344828616651 0.0034960163875156214 \n","Change of cost:  0.01687496756065955\n","epoch 6\n","The cost at the end of this epoch is  0.09721542133072512\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   4.   1.   6.   3.   0.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  3.   2. 244.   6.   3.   7.   9.   5.   8.   1.]\n"," [  1.   9.  21. 237.   1.  22.   0.   7.   1.   4.]\n"," [  1.   1.   2.   0. 302.   2.   5.   2.   1.   4.]\n"," [  4.   3.   1.  14.   0. 257.   2.   0.   9.   0.]\n"," [  7.   2.   3.   0.   6.   8. 260.   0.   6.   0.]\n"," [  1.   7.   3.   0.   3.   0.   0. 265.   1.  12.]\n"," [  4.   9.   6.   9.   1.  18.   4.   1. 261.  11.]\n"," [  1.   0.   0.   0.  14.   1.   0.   9.   3. 237.]]\n","Accuracy Macro 0.8855037302074091 Precision Macro 0.885582326871597\n","Change of the performance: 0.0026720951884934285 0.0027940887700680372 \n","Change of cost:  0.0021674951096864598\n","epoch 7\n","The cost at the end of this epoch is  0.0931221602209242\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   5.   4.   1.   3.   0.]\n"," [  0. 294.   3.   2.   0.   3.   0.   0.   5.   1.]\n"," [  4.   1. 244.   8.   3.   8.   7.   6.   6.   1.]\n"," [  1.   7.  19. 244.   1.  20.   0.   5.   2.   4.]\n"," [  1.   1.   2.   0. 297.   2.   4.   3.   3.   7.]\n"," [  4.   3.   1.  13.   0. 259.   2.   0.   7.   1.]\n"," [  6.   2.   3.   0.   6.   8. 260.   0.   7.   0.]\n"," [  1.   7.   3.   1.   2.   0.   0. 267.   1.  10.]\n"," [  3.   9.   7.   9.   1.  17.   3.   2. 264.   9.]\n"," [  1.   0.   0.   1.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8896942592232688 Precision Macro 0.8895943159954134\n","Change of the performance: 0.004190529015859701 0.004011989123816395 \n","Change of cost:  0.0007891742234476667\n","epoch 8\n","The cost at the end of this epoch is  0.08925149042346966\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   5.   4.   1.   3.   0.]\n"," [  0. 294.   3.   2.   0.   3.   0.   0.   5.   1.]\n"," [  5.   1. 242.   7.   3.   6.   8.   7.   8.   1.]\n"," [  1.   7.  18. 244.   1.  19.   0.   6.   2.   5.]\n"," [  1.   0.   1.   0. 299.   2.   5.   1.   3.   8.]\n"," [  4.   3.   1.  14.   0. 257.   2.   0.   8.   1.]\n"," [  6.   2.   4.   0.   5.   9. 259.   0.   7.   0.]\n"," [  1.   6.   3.   0.   2.   0.   0. 265.   1.  14.]\n"," [  3.   8.   5.   9.   1.  14.   4.   1. 267.  12.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8892110467626286 Precision Macro 0.8888299851228091\n","Change of the performance: 0.0004832124606402033 0.0007643308726043019 \n","Change of cost:  0.0017086053343520619\n","epoch 9\n","The cost at the end of this epoch is  0.08766982395849011\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 295.   3.   2.   0.   3.   0.   0.   4.   1.]\n"," [  5.   1. 242.   8.   3.   6.   8.   6.   8.   1.]\n"," [  2.   7.  19. 243.   1.  17.   1.   6.   2.   5.]\n"," [  1.   0.   1.   0. 299.   2.   5.   1.   3.   8.]\n"," [  5.   3.   1.  15.   0. 254.   2.   0.  10.   0.]\n"," [  5.   2.   4.   0.   5.   8. 261.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   8.   6.   8.   1.  14.   4.   2. 268.  10.]\n"," [  1.   0.   0.   1.  11.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.889416352134585 Precision Macro 0.888861646275217\n","Change of the performance: 0.00020530537195639909 3.1661152407935766e-05 \n","Change of cost:  5.334446904778356e-05\n","epoch 10\n","The cost at the end of this epoch is  0.08676295950601767\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 295.   3.   2.   0.   3.   0.   0.   4.   1.]\n"," [  5.   1. 245.   7.   3.   6.   8.   6.   6.   1.]\n"," [  2.   9.  19. 242.   1.  19.   0.   6.   1.   4.]\n"," [  1.   0.   2.   0. 299.   2.   5.   2.   2.   7.]\n"," [  5.   3.   1.  14.   0. 257.   2.   0.   8.   0.]\n"," [  7.   2.   5.   0.   5.   8. 259.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  3.   9.   6.   9.   1.  16.   4.   2. 263.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8900315099077363 Precision Macro 0.8895098799601566\n","Change of the performance: 0.0006151577731512425 0.0006482336849396031 \n","Change of cost:  0.0001149916267549067\n","epoch 11\n","The cost at the end of this epoch is  0.08607491179987083\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   3.   1.   6.   4.   1.   3.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 242.   7.   3.   6.   8.   7.   8.   1.]\n"," [  1.   8.  17. 244.   1.  20.   0.   6.   1.   5.]\n"," [  2.   0.   0.   0. 298.   2.   5.   2.   3.   8.]\n"," [  4.   3.   1.  14.   0. 257.   2.   0.   8.   1.]\n"," [  6.   2.   3.   0.   5.   9. 260.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   8.   5.   9.   1.  16.   4.   2. 264.  12.]\n"," [  1.   0.   0.   1.  11.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8876759458566472 Precision Macro 0.8873268672452636\n","Change of the performance: 0.002355564051089054 0.0021830127148930734 \n","Change of cost:  0.00022194254632290633\n","epoch 12\n","The cost at the end of this epoch is  0.08534630151171647\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   6.   4.   1.   2.   0.]\n"," [  0. 294.   3.   2.   0.   3.   0.   0.   5.   1.]\n"," [  5.   1. 244.   8.   3.   6.   8.   6.   6.   1.]\n"," [  1.   9.  18. 243.   1.  19.   0.   6.   1.   5.]\n"," [  2.   0.   0.   0. 299.   2.   5.   2.   2.   8.]\n"," [  4.   3.   1.  14.   0. 257.   2.   0.   8.   1.]\n"," [  5.   2.   5.   0.   5.   8. 260.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   9.   6.   9.   1.  14.   4.   2. 265.  11.]\n"," [  1.   0.   0.   1.  11.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.88930064000658 Precision Macro 0.8887624619278472\n","Change of the performance: 0.001624694149932826 0.0014355946825836963 \n","Change of cost:  0.000245539915106896\n","epoch 13\n","The cost at the end of this epoch is  0.0846595620745099\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   6.   3.   1.   2.   0.]\n"," [  0. 294.   3.   2.   0.   3.   0.   1.   4.   1.]\n"," [  5.   1. 244.   7.   3.   6.   8.   7.   6.   1.]\n"," [  1.   9.  18. 243.   1.  19.   0.   6.   1.   5.]\n"," [  2.   0.   0.   0. 298.   2.   5.   2.   3.   8.]\n"," [  5.   3.   1.  14.   0. 258.   2.   0.   7.   0.]\n"," [  6.   2.   4.   0.   5.   9. 259.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  3.   9.   6.   9.   1.  15.   4.   2. 264.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8897161495168495 Precision Macro 0.889292065166198\n","Change of the performance: 0.0004155095102694739 0.0005296032383507177 \n","Change of cost:  6.70778591101151e-06\n","epoch 14\n","The cost at the end of this epoch is  0.08461431887977758\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   3.   1.   6.   4.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   3.   0.   1.   4.   1.]\n"," [  5.   1. 244.   8.   3.   6.   8.   6.   6.   1.]\n"," [  1.   8.  18. 248.   1.  16.   0.   6.   1.   4.]\n"," [  2.   0.   0.   0. 298.   2.   5.   2.   3.   8.]\n"," [  4.   3.   1.  14.   0. 257.   2.   0.   8.   1.]\n"," [  6.   2.   5.   0.   5.   9. 259.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 264.   1.  13.]\n"," [  3.   8.   7.   9.   1.  14.   4.   2. 264.  12.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8897076246226849 Precision Macro 0.8890634305419557\n","Change of the performance: 8.524894164585461e-06 0.00022863462424227432 \n","Change of cost:  0.00021145621641645296\n","epoch 15\n","The cost at the end of this epoch is  0.0840938517419408\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   6.   3.   1.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 243.   7.   3.   6.   8.   6.   8.   1.]\n"," [  1.   9.  19. 241.   1.  20.   0.   6.   1.   5.]\n"," [  2.   0.   1.   0. 298.   2.   5.   2.   2.   8.]\n"," [  5.   3.   1.  14.   0. 257.   2.   0.   8.   0.]\n"," [  6.   2.   5.   0.   5.   9. 259.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   8.   6.   9.   1.  14.   4.   2. 266.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.888314176574337 Precision Macro 0.8878710026504422\n","Change of the performance: 0.001393448048347956 0.0011924278915135256 \n","Change of cost:  0.00014481914623011571\n","epoch 16\n","The cost at the end of this epoch is  0.08373935544165055\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 244.   7.   3.   6.   8.   7.   6.   1.]\n"," [  1.   9.  18. 244.   1.  19.   0.   6.   1.   4.]\n"," [  2.   0.   0.   0. 298.   2.   5.   2.   3.   8.]\n"," [  5.   3.   1.  14.   0. 256.   2.   0.   9.   0.]\n"," [  5.   2.   5.   0.   5.   9. 259.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 264.   1.  13.]\n"," [  3.   9.   6.   9.   1.  14.   4.   2. 265.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.888970027900325 Precision Macro 0.8884779633023818\n","Change of the performance: 0.0006558513259879994 0.0006069606519396586 \n","Change of cost:  3.449366157669276e-05\n","epoch 17\n","The cost at the end of this epoch is  0.0837445719503719\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   6.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 244.   7.   3.   6.   8.   7.   6.   1.]\n"," [  1.   9.  18. 244.   1.  19.   0.   6.   1.   4.]\n"," [  2.   0.   0.   0. 298.   2.   5.   2.   3.   8.]\n"," [  4.   3.   1.  14.   0. 258.   2.   0.   7.   1.]\n"," [  5.   2.   5.   0.   5.   9. 259.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  3.   9.   7.   9.   1.  14.   4.   2. 264.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8894070417866693 Precision Macro 0.8888919626608027\n","Change of the performance: 0.00043701388634431737 0.0004139993584209023 \n","Change of cost:  1.0922038511523846e-06\n","epoch 18\n","The cost at the end of this epoch is  0.08348871825376239\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 245.   7.   3.   6.   8.   6.   6.   1.]\n"," [  2.   9.  19. 244.   1.  17.   0.   6.   1.   4.]\n"," [  2.   0.   0.   0. 299.   2.   5.   2.   2.   8.]\n"," [  5.   3.   1.  14.   0. 257.   2.   0.   8.   0.]\n"," [  6.   2.   5.   0.   5.   9. 259.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  3.   9.   7.   9.   1.  14.   4.   2. 264.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8903508672402948 Precision Macro 0.889740495894312\n","Change of the performance: 0.0009438254536254798 0.0008485332335093076 \n","Change of cost:  1.1014264408013008e-05\n","epoch 19\n","The cost at the end of this epoch is  0.08324117568982509\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   6.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 244.   7.   3.   6.   8.   7.   6.   1.]\n"," [  1.   8.  18. 245.   1.  19.   0.   6.   1.   4.]\n"," [  2.   0.   0.   0. 298.   2.   5.   2.   3.   8.]\n"," [  5.   3.   2.  14.   0. 255.   2.   0.   9.   0.]\n"," [  5.   2.   5.   0.   5.   9. 259.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  3.   8.   6.   9.   1.  14.   4.   2. 266.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8893198759819663 Precision Macro 0.8888365745478184\n","Change of the performance: 0.0010309912583285064 0.0009039213464936413 \n","Change of cost:  3.016320311093057e-05\n","epoch 20\n","The cost at the end of this epoch is  0.083164996802343\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   5.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   2. 243.   7.   3.   6.   8.   7.   6.   1.]\n"," [  2.   9.  18. 243.   1.  18.   0.   6.   1.   5.]\n"," [  2.   0.   0.   0. 298.   2.   5.   2.   3.   8.]\n"," [  5.   3.   2.  14.   0. 256.   2.   0.   8.   0.]\n"," [  6.   2.   5.   0.   5.   9. 259.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  3.   8.   6.   9.   1.  11.   4.   2. 269.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8898978066740814 Precision Macro 0.8893318797750025\n","Change of the performance: 0.0005779306921150917 0.0004953052271841063 \n","Change of cost:  8.040153014400586e-05\n","epoch 21\n","The cost at the end of this epoch is  0.08297654522064526\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 244.   8.   3.   6.   8.   6.   6.   1.]\n"," [  1.   9.  18. 243.   1.  20.   0.   6.   1.   4.]\n"," [  2.   0.   0.   0. 298.   2.   5.   2.   3.   8.]\n"," [  5.   3.   1.  14.   0. 256.   2.   0.   9.   0.]\n"," [  6.   2.   5.   0.   5.   9. 259.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   8.   6.   9.   1.  14.   4.   2. 266.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.889291102625758 Precision Macro 0.8888472311286909\n","Change of the performance: 0.0006067040483234143 0.00048464864631159177 \n","Change of cost:  1.219758816298211e-06\n","epoch 22\n","The cost at the end of this epoch is  0.08288873042252247\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   5.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 244.   8.   3.   6.   8.   6.   6.   1.]\n"," [  1.   9.  18. 242.   1.  20.   0.   6.   1.   5.]\n"," [  2.   0.   0.   0. 298.   2.   5.   2.   3.   8.]\n"," [  5.   3.   1.  14.   0. 256.   2.   0.   9.   0.]\n"," [  6.   2.   5.   0.   5.   9. 259.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  3.   8.   6.   9.   1.  14.   4.   2. 266.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8889890699670773 Precision Macro 0.8884959728743624\n","Change of the performance: 0.0003020326586806732 0.00035125825432846813 \n","Change of cost:  1.340627752705048e-05\n","epoch 23\n","The cost at the end of this epoch is  0.08282664623663842\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   5.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   5.   1.]\n"," [  5.   1. 244.   8.   3.   6.   8.   6.   6.   1.]\n"," [  1.   9.  19. 243.   1.  19.   0.   6.   1.   4.]\n"," [  2.   0.   0.   0. 298.   2.   5.   2.   3.   8.]\n"," [  5.   3.   2.  14.   0. 255.   2.   0.   9.   0.]\n"," [  6.   2.   5.   0.   5.   9. 259.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  3.   8.   6.   9.   1.  14.   4.   2. 266.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8889742753841707 Precision Macro 0.8884401521444593\n","Change of the performance: 1.479458290654101e-05 5.582072990317766e-05 \n","Change of cost:  1.381653772156155e-06\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_16_500x785_10x501\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [550  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (550, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 551)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 550)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.26098384389329315\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   1.   4.   0.   3.   4.   1.   1.   0.]\n"," [  0. 295.   3.   2.   0.   1.   0.   2.   2.   3.]\n"," [  6.   2. 243.  11.   1.   3.   8.   9.   4.   1.]\n"," [  3.   8.  16. 257.   1.   6.   1.   6.   1.   4.]\n"," [  1.   2.   2.   2. 273.   0.   9.   4.   1.  26.]\n"," [  8.   3.   3.  39.   0. 218.  10.   0.   4.   5.]\n"," [ 12.   4.   9.   0.   4.   6. 250.   0.   6.   1.]\n"," [  1.   4.   4.   1.   1.   0.   0. 271.   0.  10.]\n"," [  6.  23.  17.  23.   0.   8.   3.   2. 219.  23.]\n"," [  1.   0.   0.   0.   8.   1.   0.   9.   0. 246.]]\n","Accuracy Macro 0.8599025395033231 Precision Macro 0.8621603685358614\n","epoch 1\n","The cost at the end of this epoch is  0.21642315338172988\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   5.   3.   1.   4.   4.   2.   3.   0.]\n"," [  0. 289.   7.   1.   0.   1.   0.   2.   8.   0.]\n"," [  5.   3. 245.   7.   2.   1.   5.  12.   7.   1.]\n"," [  2.   9.  21. 251.   1.   6.   1.   5.   4.   3.]\n"," [  0.   1.   4.   3. 285.   1.   4.   6.   6.  10.]\n"," [  3.   5.   2.  31.   0. 232.   0.   0.  16.   1.]\n"," [  9.   3.   6.   0.   7.   7. 249.   0.  11.   0.]\n"," [  1.   5.   3.   0.   1.   0.   0. 271.   5.   6.]\n"," [  2.   7.  10.  11.   1.   5.   2.   0. 281.   5.]\n"," [  1.   1.   0.   1.   9.   0.   0.  16.   2. 235.]]\n","Accuracy Macro 0.8773729902358547 Precision Macro 0.8799520039889996\n","epoch 2\n","The cost at the end of this epoch is  0.09386860505379323\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   4.   1.   6.   3.   1.   1.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   1. 239.   6.   3.   5.   8.  10.  10.   1.]\n"," [  1.   7.  18. 241.   1.  22.   1.   6.   1.   5.]\n"," [  2.   1.   0.   0. 298.   2.   6.   3.   2.   6.]\n"," [  6.   3.   1.  14.   0. 258.   1.   0.   7.   0.]\n"," [  8.   2.   3.   0.   8.  10. 257.   0.   4.   0.]\n"," [  1.   5.   3.   1.   2.   0.   0. 271.   1.   8.]\n"," [  3.   7.   4.   9.   1.  14.   4.   1. 270.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8894971876960222 Precision Macro 0.8894283026423248\n","Change of the performance: 0.012124197460167463 0.00947629865332511 \n","Change of cost:  0.00025053382585242534\n","epoch 3\n","The cost at the end of this epoch is  0.09802204462600182\n","Now let's test the model after this epoch:\n","Confusion array  [[294.   0.   1.   3.   1.  12.   3.   1.   3.   0.]\n"," [  0. 290.   2.   3.   0.   3.   0.   1.   8.   1.]\n"," [  4.   2. 239.   7.   3.   8.   7.   7.  10.   1.]\n"," [  1.   8.  14. 248.   1.  19.   0.   4.   4.   4.]\n"," [  0.   1.   1.   0. 300.   3.   3.   3.   2.   7.]\n"," [  1.   3.   1.  14.   0. 261.   2.   0.   8.   0.]\n"," [  6.   2.   4.   0.   7.  10. 256.   0.   7.   0.]\n"," [  1.   7.   3.   1.   2.   0.   0. 266.   1.  11.]\n"," [  2.   8.   4.   9.   1.  16.   3.   1. 267.  13.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   4. 239.]]\n","Accuracy Macro 0.886556180214478 Precision Macro 0.8876336556268696\n","Change of the performance: 0.0029410074815441334 0.0017946470154551752 \n","Change of cost:  0.007928252945087949\n","epoch 4\n","The cost at the end of this epoch is  0.0882158493586694\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   4.   1.   4.   4.   1.   3.   0.]\n"," [  0. 292.   2.   3.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 242.   9.   3.   3.   8.   7.   8.   1.]\n"," [  1.   8.  14. 249.   1.  21.   0.   4.   1.   4.]\n"," [  2.   1.   1.   0. 293.   2.   5.   3.   3.  10.]\n"," [  3.   4.   1.  15.   0. 256.   2.   0.   8.   1.]\n"," [  7.   3.   4.   0.   5.   9. 257.   0.   7.   0.]\n"," [  2.   5.   3.   3.   1.   0.   0. 266.   1.  11.]\n"," [  3.   7.   5.   8.   1.  15.   4.   2. 269.  10.]\n"," [  1.   0.   0.   1.  11.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8879523863319603 Precision Macro 0.8876974064998121\n","Change of the performance: 0.001396206117482257 6.375087294252513e-05 \n","Change of cost:  0.0005814181066827462\n","epoch 5\n","The cost at the end of this epoch is  0.08671099362043151\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 291.   3.   2.   0.   3.   0.   1.   7.   1.]\n"," [  5.   4. 240.   7.   3.   3.   8.   7.   9.   2.]\n"," [  1.  10.  15. 243.   1.  18.   1.   6.   3.   5.]\n"," [  2.   0.   0.   0. 298.   2.   6.   3.   2.   7.]\n"," [  5.   3.   1.  14.   0. 251.   3.   0.  12.   1.]\n"," [  7.   2.   4.   0.   8.   8. 257.   0.   6.   0.]\n"," [  1.   5.   3.   1.   2.   0.   0. 268.   1.  11.]\n"," [  2.   7.   5.   8.   1.  11.   4.   1. 274.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   6.   3. 243.]]\n","Accuracy Macro 0.8884032197941387 Precision Macro 0.8880527269020021\n","Change of the performance: 0.000450833462178446 0.00035532040218999583 \n","Change of cost:  0.0013882562207086085\n","epoch 6\n","The cost at the end of this epoch is  0.09171284237601252\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   6.   3.   0.   2.   0.]\n"," [  0. 292.   2.   1.   0.   5.   0.   1.   6.   1.]\n"," [  5.   2. 243.   7.   3.   5.   8.   5.   8.   2.]\n"," [  1.   9.  17. 236.   1.  25.   0.   6.   1.   7.]\n"," [  3.   1.   0.   0. 294.   2.   5.   3.   2.  10.]\n"," [  5.   3.   1.  14.   0. 259.   2.   0.   6.   0.]\n"," [  8.   2.   5.   0.   5.   9. 258.   0.   5.   0.]\n"," [  1.   5.   3.   1.   2.   0.   0. 267.   1.  12.]\n"," [  4.   8.   5.   7.   1.  25.   4.   1. 254.  15.]\n"," [  1.   0.   0.   0.  11.   1.   0.   7.   3. 242.]]\n","Accuracy Macro 0.8824177534552946 Precision Macro 0.8827657263868769\n","Change of the performance: 0.005985466338844114 0.005287000515125206 \n","Change of cost:  0.008861378165551964\n","epoch 7\n","The cost at the end of this epoch is  0.0833922458958215\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   3.   3.   2.   3.   0.]\n"," [  0. 291.   3.   2.   0.   3.   0.   1.   7.   1.]\n"," [  5.   2. 244.   6.   3.   4.   8.   7.   8.   1.]\n"," [  1.   8.  16. 245.   1.  20.   0.   6.   1.   5.]\n"," [  2.   1.   1.   0. 296.   2.   4.   3.   3.   8.]\n"," [  6.   3.   1.  14.   0. 258.   2.   0.   6.   0.]\n"," [  7.   2.   4.   0.   5.   9. 258.   0.   7.   0.]\n"," [  1.   5.   3.   1.   2.   0.   0. 267.   1.  12.]\n"," [  2.   6.   7.   9.   1.  14.   4.   2. 269.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8899430409354012 Precision Macro 0.8895431984168363\n","Change of the performance: 0.007525287480106613 0.006777472029959375 \n","Change of cost:  0.0011641728548360403\n","epoch 8\n","The cost at the end of this epoch is  0.08257927760428077\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   3.   1.   6.   3.   2.   3.   0.]\n"," [  0. 290.   3.   2.   0.   3.   0.   1.   8.   1.]\n"," [  5.   1. 246.   6.   2.   5.   8.   7.   7.   1.]\n"," [  1.   7.  18. 241.   1.  20.   0.   6.   2.   7.]\n"," [  2.   1.   1.   0. 296.   2.   4.   3.   3.   8.]\n"," [  6.   3.   2.  14.   0. 256.   2.   0.   7.   0.]\n"," [  6.   2.   5.   0.   5.   9. 258.   0.   7.   0.]\n"," [  1.   5.   3.   1.   2.   0.   0. 268.   1.  11.]\n"," [  2.   5.   5.   9.   1.  12.   4.   1. 274.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   3. 240.]]\n","Accuracy Macro 0.8891824091913471 Precision Macro 0.8888979781785338\n","Change of the performance: 0.0007606317440541632 0.0006452202383024908 \n","Change of cost:  0.0008750599735721509\n","epoch 9\n","The cost at the end of this epoch is  0.08094442892960235\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   3.   3.   2.   3.   0.]\n"," [  0. 291.   3.   2.   0.   3.   0.   1.   7.   1.]\n"," [  5.   2. 244.   6.   3.   4.   8.   7.   8.   1.]\n"," [  1.   8.  18. 241.   1.  21.   0.   5.   1.   7.]\n"," [  2.   1.   0.   0. 296.   2.   5.   3.   3.   8.]\n"," [  6.   3.   1.  14.   0. 255.   2.   0.   9.   0.]\n"," [  7.   2.   5.   0.   5.   9. 257.   0.   7.   0.]\n"," [  1.   5.   3.   3.   2.   0.   0. 266.   1.  11.]\n"," [  2.   7.   5.   9.   1.  13.   4.   1. 271.  11.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   4. 241.]]\n","Accuracy Macro 0.8878352440161524 Precision Macro 0.8874711923339798\n","Change of the performance: 0.00134716517519462 0.0014267858445540238 \n","Change of cost:  0.00015420077983467617\n","epoch 10\n","The cost at the end of this epoch is  0.08227448728398179\n","Now let's test the model after this epoch:\n","Confusion array  [[295.   0.   1.   3.   1.   9.   4.   3.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  4.   2. 245.   5.   2.   5.   8.   7.   8.   2.]\n"," [  1.   8.  17. 241.   1.  21.   0.   6.   1.   7.]\n"," [  1.   2.   0.   0. 297.   3.   5.   3.   2.   7.]\n"," [  2.   3.   1.  15.   0. 259.   2.   0.   8.   0.]\n"," [  6.   2.   5.   0.   5.   9. 258.   0.   7.   0.]\n"," [  1.   4.   4.   1.   2.   0.   0. 268.   1.  11.]\n"," [  2.   9.   7.   8.   1.  14.   4.   1. 265.  13.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8871732394546642 Precision Macro 0.8868623801327622\n","Change of the performance: 0.0006620045614882386 0.0006088122012175567 \n","Change of cost:  0.0019943588013411617\n","epoch 11\n","The cost at the end of this epoch is  0.07989191569091236\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   3.   3.   3.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 244.   6.   3.   4.   8.   7.   8.   1.]\n"," [  1.   9.  17. 246.   1.  17.   0.   6.   1.   5.]\n"," [  2.   2.   0.   0. 297.   2.   4.   3.   2.   8.]\n"," [  6.   3.   2.  14.   0. 256.   2.   0.   7.   0.]\n"," [  7.   3.   5.   0.   5.  10. 256.   0.   6.   0.]\n"," [  1.   5.   3.   3.   2.   0.   0. 267.   1.  10.]\n"," [  2.   9.   7.   9.   1.  13.   4.   2. 266.  11.]\n"," [  1.   0.   0.   1.  10.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8892386674757979 Precision Macro 0.8887379003592988\n","Change of the performance: 0.0020654280211337417 0.0018755202265365867 \n","Change of cost:  9.361148050879287e-05\n","epoch 12\n","The cost at the end of this epoch is  0.08018450662817829\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   3.   3.   3.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 244.   6.   3.   4.   8.   7.   8.   1.]\n"," [  3.   8.  18. 242.   1.  19.   0.   5.   0.   7.]\n"," [  2.   2.   0.   0. 297.   1.   6.   3.   1.   8.]\n"," [  7.   3.   1.  14.   0. 255.   3.   0.   7.   0.]\n"," [  8.   3.   5.   0.   5.  10. 256.   0.   5.   0.]\n"," [  1.   5.   4.   3.   2.   0.   0. 265.   1.  11.]\n"," [  2.   9.   7.   9.   1.  13.   4.   0. 265.  14.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   4. 241.]]\n","Accuracy Macro 0.8865801343942319 Precision Macro 0.8859582320538818\n","Change of the performance: 0.00265853308156605 0.0027796683054169824 \n","Change of cost:  2.271873215853315e-05\n","epoch 13\n","The cost at the end of this epoch is  0.07893512883668645\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   3.   3.   3.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 245.   6.   2.   4.   8.   7.   8.   1.]\n"," [  1.   8.  19. 242.   1.  19.   0.   5.   1.   7.]\n"," [  2.   2.   0.   0. 296.   2.   5.   3.   2.   8.]\n"," [  6.   3.   2.  14.   0. 256.   2.   0.   7.   0.]\n"," [  7.   3.   5.   0.   5.  10. 256.   0.   6.   0.]\n"," [  1.   5.   3.   3.   2.   0.   0. 266.   1.  11.]\n"," [  2.   9.   7.   9.   1.  13.   4.   0. 266.  13.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   4. 241.]]\n","Accuracy Macro 0.8876107919313941 Precision Macro 0.8870254216614711\n","Change of the performance: 0.0010306575371622495 0.0010671896075893361 \n","Change of cost:  3.210821879467973e-05\n","epoch 14\n","The cost at the end of this epoch is  0.07875717780432963\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   6.   3.   3.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 245.   6.   2.   4.   8.   7.   8.   1.]\n"," [  1.   7.  17. 243.   1.  21.   0.   5.   1.   7.]\n"," [  2.   2.   0.   0. 296.   2.   5.   3.   2.   8.]\n"," [  6.   3.   1.  14.   0. 257.   2.   0.   7.   0.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   5.   3.   3.   2.   0.   0. 266.   1.  11.]\n"," [  2.   9.   7.   8.   1.  14.   4.   0. 265.  14.]\n"," [  1.   0.   0.   1.  10.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8873760800726023 Precision Macro 0.8869631755618943\n","Change of the performance: 0.0002347118587918695 6.22460995768348e-05 \n","Change of cost:  3.611401609857068e-06\n","epoch 15\n","The cost at the end of this epoch is  0.07873511707212393\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   3.   3.   3.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 245.   6.   2.   4.   8.   7.   8.   1.]\n"," [  1.   7.  18. 242.   1.  21.   0.   5.   1.   7.]\n"," [  2.   2.   1.   0. 295.   2.   5.   3.   2.   8.]\n"," [  6.   3.   1.  14.   0. 256.   2.   0.   8.   0.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   5.   3.   2.   2.   0.   0. 267.   1.  11.]\n"," [  2.   9.   7.   9.   1.  13.   4.   1. 267.  11.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   4. 241.]]\n","Accuracy Macro 0.8867195383695272 Precision Macro 0.8863326247572451\n","Change of the performance: 0.0006565417030750531 0.0006305508046492436 \n","Change of cost:  3.240818416952451e-05\n","epoch 16\n","The cost at the end of this epoch is  0.07840163603084255\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   6.   3.   3.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 245.   6.   2.   4.   8.   7.   8.   1.]\n"," [  1.   7.  17. 242.   1.  21.   0.   6.   1.   7.]\n"," [  2.   2.   0.   0. 296.   2.   5.   3.   2.   8.]\n"," [  6.   3.   1.  14.   0. 257.   2.   0.   7.   0.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   5.   3.   3.   2.   0.   0. 266.   1.  11.]\n"," [  2.  10.   7.   8.   1.  14.   4.   1. 266.  11.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   4. 241.]]\n","Accuracy Macro 0.8873546890446107 Precision Macro 0.8869929062841766\n","Change of the performance: 0.0006351506750834623 0.0006602815269315387 \n","Change of cost:  5.3095699861643864e-05\n","epoch 17\n","The cost at the end of this epoch is  0.07834622661903601\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   6.   3.   3.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 245.   6.   2.   4.   8.   7.   8.   1.]\n"," [  1.   7.  17. 243.   1.  21.   0.   5.   1.   7.]\n"," [  2.   2.   0.   0. 296.   2.   5.   3.   2.   8.]\n"," [  6.   3.   1.  14.   0. 257.   2.   0.   7.   0.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  2.  10.   7.   8.   1.  14.   4.   0. 266.  12.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   4. 241.]]\n","Accuracy Macro 0.887684722047911 Precision Macro 0.8873827859177915\n","Change of the performance: 0.00033003300330036733 0.0003898796336149202 \n","Change of cost:  1.887413004983407e-06\n","epoch 18\n","The cost at the end of this epoch is  0.07825261681432574\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 244.   6.   3.   4.   8.   7.   8.   1.]\n"," [  1.   8.  17. 243.   1.  20.   0.   5.   1.   7.]\n"," [  2.   2.   0.   0. 297.   1.   6.   3.   1.   8.]\n"," [  6.   3.   1.  14.   0. 257.   2.   0.   7.   0.]\n"," [  7.   3.   5.   0.   5.  10. 256.   0.   6.   0.]\n"," [  1.   5.   3.   3.   2.   0.   0. 266.   1.  11.]\n"," [  2.  10.   7.   8.   1.  15.   4.   1. 265.  11.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   4. 241.]]\n","Accuracy Macro 0.8876278229145654 Precision Macro 0.8871840853897103\n","Change of the performance: 5.6899133345611475e-05 0.0001987005280812415 \n","Change of cost:  8.560917887798225e-06\n","epoch 19\n","The cost at the end of this epoch is  0.07815857476413803\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   6.   3.   3.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   2.   4.   8.   8.   8.   1.]\n"," [  1.   7.  17. 243.   1.  21.   0.   5.   1.   7.]\n"," [  2.   2.   0.   0. 296.   2.   5.   3.   2.   8.]\n"," [  6.   3.   1.  14.   0. 257.   2.   0.   7.   0.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  2.  10.   7.   8.   1.  14.   4.   1. 266.  11.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   4. 241.]]\n","Accuracy Macro 0.887684722047911 Precision Macro 0.8873891583508373\n","Change of the performance: 5.6899133345611475e-05 0.00020507296112703965 \n","Change of cost:  4.653526344336467e-06\n","epoch 20\n","The cost at the end of this epoch is  0.07809700529261902\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   5.   3.   3.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   2. 245.   6.   2.   4.   8.   7.   8.   1.]\n"," [  1.   7.  18. 242.   1.  21.   0.   5.   1.   7.]\n"," [  2.   2.   0.   0. 296.   2.   5.   3.   2.   8.]\n"," [  6.   3.   1.  14.   0. 257.   2.   0.   7.   0.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   5.   3.   3.   2.   0.   0. 266.   1.  11.]\n"," [  2.  10.   7.   8.   1.  14.   4.   1. 266.  11.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   4. 241.]]\n","Accuracy Macro 0.8876691544534158 Precision Macro 0.8872689669374332\n","Change of the performance: 1.5567594495280446e-05 0.00012019141340413597 \n","Change of cost:  7.698578442127957e-06\n","epoch 21\n","The cost at the end of this epoch is  0.07805307920387422\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   6.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   6.   2.   4.   8.   7.   8.   1.]\n"," [  1.   7.  18. 242.   1.  21.   0.   5.   1.   7.]\n"," [  2.   2.   0.   0. 296.   2.   5.   3.   2.   8.]\n"," [  6.   3.   1.  14.   0. 257.   2.   0.   7.   0.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   5.   3.   3.   2.   0.   0. 266.   1.  11.]\n"," [  2.  10.   7.   8.   1.  14.   4.   0. 266.  12.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   4. 241.]]\n","Accuracy Macro 0.887679364369286 Precision Macro 0.8872774813295081\n","Change of the performance: 1.0209915870196262e-05 8.514392074943089e-06 \n","Change of cost:  1.2396870138764449e-06\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_16_550x785_10x551\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [600  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (600, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 601)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 600)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.07908477299847619\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   5.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 243.   6.   2.   4.   8.   8.   8.   2.]\n"," [  1.   7.  18. 242.   1.  21.   0.   5.   1.   7.]\n"," [  3.   2.   0.   0. 295.   1.   6.   3.   2.   8.]\n"," [  6.   3.   1.  15.   0. 253.   3.   0.   9.   0.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   4.   4.   1.   2.   0.   0. 268.   1.  11.]\n"," [  3.   9.   7.   9.   1.  13.   4.   1. 263.  14.]\n"," [  1.   0.   0.   1.  10.   1.   0.   7.   3. 242.]]\n","Accuracy Macro 0.8857439390603086 Precision Macro 0.8849374524767919\n","epoch 1\n","The cost at the end of this epoch is  0.44779697890868886\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   6.   1.   2.   1.   6.   3.   0.]\n"," [  0. 295.   2.   3.   0.   1.   0.   1.   5.   1.]\n"," [  5.   6. 239.  13.   0.   1.   5.  13.   6.   0.]\n"," [  1.  12.  15. 266.   0.   2.   0.   4.   1.   2.]\n"," [  0.   3.   8.   2. 235.   0.   2.  17.  10.  43.]\n"," [  3.   4.   1.  81.   0. 179.   1.   0.  16.   5.]\n"," [ 15.   5.  14.   1.   2.   8. 228.   1.  15.   3.]\n"," [  1.   6.   3.   2.   2.   0.   0. 271.   2.   5.]\n"," [  3.  17.  11.  22.   0.   3.   2.   0. 255.  11.]\n"," [  1.   1.   0.   4.   4.   0.   0.  29.   1. 225.]]\n","Accuracy Macro 0.8302406809719249 Precision Macro 0.8435123622532273\n","epoch 2\n","The cost at the end of this epoch is  0.1329336183641882\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   3.   3.   4.   3.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   7.   0.]\n"," [  7.   2. 241.   7.   2.   4.   7.   8.   9.   1.]\n"," [  3.   9.  18. 249.   0.   8.   1.   6.   4.   5.]\n"," [  2.   1.   0.   0. 296.   1.   5.   4.   2.   9.]\n"," [  4.   4.   1.  25.   1. 239.   4.   0.  10.   2.]\n"," [  9.   2.   3.   0.   5.   7. 260.   0.   6.   0.]\n"," [  1.   3.   4.   1.   1.   0.   0. 269.   4.   9.]\n"," [  3.   8.   8.   8.   1.  12.   2.   2. 272.   8.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   1. 238.]]\n","Accuracy Macro 0.885482846261282 Precision Macro 0.8852185038539624\n","Change of the performance: 0.055242165289357104 0.04170614160073505 \n","Change of cost:  0.030904309812454483\n","epoch 3\n","The cost at the end of this epoch is  0.11177005270082854\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   8.   4.   1.   3.   0.]\n"," [  0. 287.   4.   3.   0.   2.   0.   1.   9.   2.]\n"," [  6.   1. 241.   6.   3.   5.   7.   7.  11.   1.]\n"," [  2.   7.  21. 243.   1.  15.   1.   4.   5.   4.]\n"," [  1.   1.   2.   0. 293.   2.   6.   3.   4.   8.]\n"," [  4.   3.   1.  16.   1. 249.   3.   0.  10.   3.]\n"," [  8.   2.   4.   0.   5.   8. 259.   0.   6.   0.]\n"," [  1.   3.   3.   1.   1.   0.   0. 268.   4.  11.]\n"," [  3.   4.   8.   8.   1.   9.   2.   1. 281.   7.]\n"," [  1.   0.   0.   0.  12.   1.   0.  10.   3. 238.]]\n","Accuracy Macro 0.8852148222000104 Precision Macro 0.8854016483000933\n","Change of the performance: 0.00026802406127168776 0.00018314444613087844 \n","Change of cost:  0.0023037020339847503\n","epoch 4\n","The cost at the end of this epoch is  0.09872498915307196\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   2.   1.   6.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   1.   0.   5.   1.]\n"," [  5.   3. 245.   6.   3.   4.   8.   7.   6.   1.]\n"," [  3.   8.  19. 242.   1.  23.   0.   3.   2.   2.]\n"," [  1.   1.   0.   0. 302.   2.   5.   3.   2.   4.]\n"," [  5.   4.   1.  13.   1. 256.   1.   0.   7.   2.]\n"," [  7.   3.   4.   0.   7.   9. 256.   0.   6.   0.]\n"," [  1.   6.   4.   3.   2.   0.   0. 262.   2.  12.]\n"," [  3.  10.   7.  11.   1.  17.   4.   2. 259.  10.]\n"," [  1.   0.   0.   0.  13.   1.   0.   7.   3. 240.]]\n","Accuracy Macro 0.8852738211070343 Precision Macro 0.8853844986387882\n","Change of the performance: 5.8998907023988245e-05 1.714966130506035e-05 \n","Change of cost:  0.005543035161476459\n","epoch 5\n","The cost at the end of this epoch is  0.09194648201496053\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   2.   1.   8.   4.   0.   3.   0.]\n"," [  0. 288.   2.   2.   0.   4.   0.   1.  10.   1.]\n"," [  5.   1. 241.   5.   3.   5.   8.   7.  12.   1.]\n"," [  2.   7.  18. 237.   1.  23.   1.   4.   7.   3.]\n"," [  3.   1.   0.   0. 299.   2.   3.   3.   4.   5.]\n"," [  5.   3.   1.  13.   1. 252.   2.   0.  11.   2.]\n"," [  8.   1.   3.   0.   8.  10. 256.   0.   6.   0.]\n"," [  1.   3.   3.   0.   2.   0.   0. 267.   3.  13.]\n"," [  3.   5.   4.   9.   1.  11.   2.   1. 279.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8855508176891258 Precision Macro 0.8868996085734654\n","Change of the performance: 0.00027699658209145994 0.0015151099346771835 \n","Change of cost:  0.0028295684469540477\n","epoch 6\n","The cost at the end of this epoch is  0.08514046901520098\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   8.   3.   1.   3.   0.]\n"," [  0. 292.   4.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   1. 247.   5.   2.   5.   8.   8.   7.   1.]\n"," [  1.   9.  18. 242.   1.  19.   1.   5.   3.   4.]\n"," [  1.   1.   0.   0. 300.   3.   3.   3.   4.   5.]\n"," [  3.   4.   2.  12.   1. 253.   2.   0.  11.   2.]\n"," [  8.   3.   3.   0.   8.  10. 255.   0.   5.   0.]\n"," [  1.   4.   4.   0.   2.   0.   0. 267.   3.  11.]\n"," [  2.   9.   6.   9.   1.  12.   4.   0. 271.  10.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   3. 239.]]\n","Accuracy Macro 0.8877369194686041 Precision Macro 0.8879902884609983\n","Change of the performance: 0.002186101779478311 0.0010906798875328638 \n","Change of cost:  0.001729471114971723\n","epoch 7\n","The cost at the end of this epoch is  0.08063673717137279\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   6.   4.   2.   3.   0.]\n"," [  0. 292.   4.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   1. 246.   7.   2.   5.   8.   6.   7.   1.]\n"," [  1.   6.  19. 244.   1.  19.   1.   4.   2.   6.]\n"," [  1.   1.   0.   0. 298.   3.   5.   3.   4.   5.]\n"," [  6.   3.   1.  13.   1. 255.   2.   0.   7.   2.]\n"," [  9.   2.   4.   0.   6.  10. 256.   0.   5.   0.]\n"," [  1.   4.   4.   1.   2.   0.   0. 268.   2.  10.]\n"," [  2.   8.   7.   9.   1.  13.   4.   0. 269.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8888738898809994 Precision Macro 0.8886312163060625\n","Change of the performance: 0.001136970412395244 0.0006409278450641986 \n","Change of cost:  0.000346669867298921\n","epoch 8\n","The cost at the end of this epoch is  0.07883784510788068\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   5.   3.   2.   3.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   1. 248.   6.   2.   4.   7.   7.   7.   1.]\n"," [  1.   7.  18. 245.   1.  19.   0.   4.   2.   6.]\n"," [  2.   2.   0.   0. 300.   2.   3.   3.   3.   5.]\n"," [  6.   3.   2.  14.   1. 253.   2.   0.   8.   1.]\n"," [  7.   3.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   6.   3.   1.   2.   0.   0. 268.   1.  10.]\n"," [  2.   9.   7.  10.   1.  14.   4.   0. 266.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8888517855411651 Precision Macro 0.88872297737677\n","Change of the performance: 2.2104339834294606e-05 9.176107070751893e-05 \n","Change of cost:  0.0001197268799560669\n","epoch 9\n","The cost at the end of this epoch is  0.0804325483406741\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   8.   3.   2.   3.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   1. 247.   5.   2.   4.   7.   8.   8.   1.]\n"," [  1.   6.  19. 243.   1.  20.   0.   4.   2.   7.]\n"," [  2.   2.   1.   1. 297.   2.   4.   3.   3.   5.]\n"," [  6.   3.   2.  14.   1. 253.   2.   0.   9.   0.]\n"," [  7.   2.   4.   0.   5.  11. 257.   0.   6.   0.]\n"," [  1.   6.   3.   0.   2.   0.   0. 269.   1.  10.]\n"," [  2.   8.   7.  10.   1.  12.   4.   0. 269.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   3. 239.]]\n","Accuracy Macro 0.8878820315349856 Precision Macro 0.8877516761704809\n","Change of the performance: 0.0009697540061794907 0.0009713012062890769 \n","Change of cost:  0.0017392248956440287\n","epoch 10\n","The cost at the end of this epoch is  0.0783031371622003\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   2.   3.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   1. 247.   6.   2.   4.   8.   7.   7.   1.]\n"," [  1.   8.  16. 245.   1.  20.   0.   4.   2.   6.]\n"," [  2.   2.   0.   0. 298.   2.   5.   3.   3.   5.]\n"," [  6.   3.   1.  14.   0. 257.   2.   0.   7.   0.]\n"," [  8.   3.   5.   0.   5.  10. 255.   0.   6.   0.]\n"," [  1.   6.   3.   1.   2.   0.   0. 267.   1.  11.]\n"," [  3.   9.   7.  10.   1.  14.   4.   0. 265.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8876923700532418 Precision Macro 0.8875746832292537\n","Change of the performance: 0.00018966148174381914 0.00017699294122719422 \n","Change of cost:  0.0014586036216998888\n","epoch 11\n","The cost at the end of this epoch is  0.08090306604393567\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   2.   3.   0.]\n"," [  0. 291.   3.   2.   0.   3.   0.   1.   7.   1.]\n"," [  4.   1. 248.   7.   2.   5.   7.   6.   7.   1.]\n"," [  1.   7.  17. 245.   1.  20.   0.   4.   2.   6.]\n"," [  1.   2.   1.   1. 296.   3.   5.   3.   3.   5.]\n"," [  5.   3.   1.  14.   0. 257.   2.   0.   8.   0.]\n"," [  9.   2.   5.   0.   5.  11. 255.   0.   5.   0.]\n"," [  1.   6.   4.   2.   2.   0.   0. 265.   1.  11.]\n"," [  3.   7.   7.  10.   1.  16.   4.   0. 266.  10.]\n"," [  1.   0.   0.   0.  12.   1.   0.   7.   3. 241.]]\n","Accuracy Macro 0.887090985909814 Precision Macro 0.8871816043912493\n","Change of the performance: 0.0006013841434278078 0.00039307883800443477 \n","Change of cost:  0.0019687959092130614\n","epoch 12\n","The cost at the end of this epoch is  0.07860798701031466\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   0.   3.   1.   3.   3.   2.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   1. 247.   6.   2.   4.   8.   7.   7.   1.]\n"," [  3.   8.  18. 243.   1.  17.   1.   5.   0.   7.]\n"," [  2.   2.   0.   0. 299.   2.   4.   3.   3.   5.]\n"," [  8.   4.   1.  14.   1. 248.   6.   0.   7.   1.]\n"," [  7.   3.   5.   0.   7.   9. 254.   0.   7.   0.]\n"," [  1.   6.   3.   1.   2.   0.   0. 267.   1.  11.]\n"," [  3.  10.   7.  10.   1.  12.   4.   0. 266.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8864087898542982 Precision Macro 0.8858806916767323\n","Change of the performance: 0.0006821960555157824 0.001300912714516933 \n","Change of cost:  0.0014601653694103905\n","epoch 13\n","The cost at the end of this epoch is  0.07699791248425711\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   8.   3.   2.   3.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   1. 247.   6.   2.   4.   8.   7.   7.   1.]\n"," [  1.   7.  19. 244.   1.  18.   1.   4.   1.   7.]\n"," [  2.   2.   0.   0. 297.   2.   6.   3.   3.   5.]\n"," [  7.   3.   1.  14.   1. 253.   2.   0.   9.   0.]\n"," [  7.   3.   5.   0.   6.  10. 255.   0.   6.   0.]\n"," [  1.   6.   3.   1.   2.   0.   0. 266.   1.  12.]\n"," [  2.   9.   7.  10.   1.  13.   4.   0. 265.  13.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8856425263604942 Precision Macro 0.8852268593959056\n","Change of the performance: 0.0007662634938039314 0.0006538322808267161 \n","Change of cost:  0.0002766166204499626\n","epoch 14\n","The cost at the end of this epoch is  0.07661055314007117\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   8.   3.   2.   3.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   1.   6.   1.]\n"," [  5.   1. 247.   6.   2.   4.   8.   7.   7.   1.]\n"," [  1.   7.  18. 243.   1.  19.   1.   5.   1.   7.]\n"," [  2.   2.   0.   0. 297.   2.   6.   3.   3.   5.]\n"," [  6.   4.   1.  14.   1. 252.   3.   0.   9.   0.]\n"," [  7.   2.   5.   0.   7.  10. 255.   0.   6.   0.]\n"," [  1.   6.   3.   0.   2.   0.   0. 268.   1.  11.]\n"," [  2.  10.   7.  10.   1.  13.   4.   0. 266.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   3. 239.]]\n","Accuracy Macro 0.8855838807625789 Precision Macro 0.8852424109356235\n","Change of the performance: 5.864559791535218e-05 1.5551539717884033e-05 \n","Change of cost:  2.834490308013804e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_17_600x785_10x601\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [650  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (650, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 651)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 650)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.10628392698013941\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   7.   4.   4.   3.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   1.   5.   1.]\n"," [  5.   8. 235.   7.   2.   3.   7.  13.   7.   1.]\n"," [  1.  14.  14. 240.   1.  18.   1.   7.   1.   6.]\n"," [  2.   2.   0.   0. 298.   2.   5.   3.   3.   5.]\n"," [  6.   5.   1.  14.   1. 250.   3.   0.   8.   2.]\n"," [  8.   4.   4.   0.   8.   9. 254.   0.   5.   0.]\n"," [  1.   6.   3.   1.   2.   0.   0. 267.   1.  11.]\n"," [  2.  13.   6.   8.   1.  15.   4.   2. 261.  12.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8789743138336436 Precision Macro 0.8791528256724194\n","epoch 1\n","The cost at the end of this epoch is  0.07968047528078152\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   0.   3.   1.   3.   3.   2.   2.   0.]\n"," [  0. 290.   3.   3.   0.   3.   0.   1.   7.   1.]\n"," [  5.   1. 246.   5.   3.   4.   7.   8.   8.   1.]\n"," [  2.   7.  16. 248.   1.  17.   0.   4.   2.   6.]\n"," [  2.   2.   1.   0. 296.   2.   6.   3.   2.   6.]\n"," [  7.   4.   1.  14.   1. 250.   5.   0.   8.   0.]\n"," [  7.   3.   5.   0.   6.   9. 255.   0.   7.   0.]\n"," [  1.   6.   3.   1.   2.   0.   0. 266.   1.  12.]\n"," [  3.   7.   7.  10.   1.  13.   4.   2. 266.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8868145371716407 Precision Macro 0.8862898980028724\n","epoch 2\n","The cost at the end of this epoch is  0.07831825723617655\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   7.   3.   2.   2.   0.]\n"," [  0. 292.   3.   3.   0.   3.   0.   1.   5.   1.]\n"," [  5.   3. 243.   5.   3.   4.   7.   9.   8.   1.]\n"," [  1.   7.  17. 247.   1.  19.   1.   4.   1.   5.]\n"," [  2.   2.   0.   0. 297.   2.   5.   3.   3.   6.]\n"," [  7.   4.   1.  15.   1. 249.   4.   0.   8.   1.]\n"," [  7.   3.   4.   0.   8.  10. 254.   0.   6.   0.]\n"," [  1.   6.   3.   1.   2.   0.   0. 267.   1.  11.]\n"," [  2.   9.   7.   9.   1.  15.   4.   0. 265.  12.]\n"," [  1.   0.   0.   1.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8841159984637226 Precision Macro 0.8839133211358667\n","Change of the performance: 0.002698538707918141 0.002376576867005653 \n","Change of cost:  0.001275469347830946\n","epoch 3\n","The cost at the end of this epoch is  0.0795105963627446\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   7.   3.   2.   2.   0.]\n"," [  0. 293.   2.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   1. 247.   6.   2.   4.   8.   7.   7.   1.]\n"," [  1.   8.  16. 252.   1.  16.   0.   4.   1.   4.]\n"," [  2.   2.   1.   0. 295.   2.   6.   3.   3.   6.]\n"," [  7.   4.   2.  15.   1. 250.   4.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.  12. 256.   0.   5.   0.]\n"," [  1.   6.   3.   3.   2.   0.   0. 264.   1.  12.]\n"," [  3.   8.   7.  12.   1.  12.   4.   2. 264.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8865484475512622 Precision Macro 0.8861067247605584\n","Change of the performance: 0.00243244908753959 0.00219340362469167 \n","Change of cost:  0.0021022676871571694\n","epoch 4\n","The cost at the end of this epoch is  0.07906583100953041\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 291.   3.   3.   0.   3.   0.   1.   6.   1.]\n"," [  5.   1. 246.   5.   2.   4.   8.   7.   8.   2.]\n"," [  1.   6.  17. 247.   1.  18.   0.   6.   3.   4.]\n"," [  2.   2.   0.   0. 298.   2.   4.   3.   2.   7.]\n"," [  6.   4.   2.  16.   1. 246.   4.   0.  10.   1.]\n"," [  8.   3.   5.   0.   5.  10. 255.   0.   6.   0.]\n"," [  1.   4.   4.   1.   2.   0.   0. 266.   1.  13.]\n"," [  2.   8.   7.  11.   1.  10.   3.   1. 270.  11.]\n"," [  1.   0.   0.   1.  11.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8867233993135738 Precision Macro 0.8861457795651919\n","Change of the performance: 0.000174951762311637 3.90548046335093e-05 \n","Change of cost:  0.0015246481828477126\n","epoch 5\n","The cost at the end of this epoch is  0.07817741928609638\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   3.   1.   6.   4.   1.   3.   0.]\n"," [  0. 292.   3.   2.   0.   2.   0.   1.   7.   1.]\n"," [  4.   2. 245.   5.   3.   3.   8.   9.   8.   1.]\n"," [  2.   8.  17. 241.   1.  21.   1.   5.   1.   6.]\n"," [  2.   2.   0.   0. 295.   2.   7.   3.   3.   6.]\n"," [  6.   4.   1.  14.   0. 253.   4.   0.   8.   0.]\n"," [  7.   2.   5.   0.   7.  10. 255.   0.   6.   0.]\n"," [  1.   6.   4.   2.   2.   0.   0. 264.   1.  12.]\n"," [  3.   8.   7.   8.   1.  17.   4.   0. 266.  10.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   3. 240.]]\n","Accuracy Macro 0.8832711587834131 Precision Macro 0.8829516227185126\n","Change of the performance: 0.0034522405301606884 0.0031941568466793413 \n","Change of cost:  0.0030062453859177884\n","epoch 6\n","The cost at the end of this epoch is  0.07674482030645143\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   1.   3.   1.   8.   4.   1.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   1. 245.   6.   3.   4.   7.   7.   9.   1.]\n"," [  2.   7.  18. 243.   1.  18.   1.   5.   1.   7.]\n"," [  2.   2.   0.   0. 296.   2.   6.   3.   3.   6.]\n"," [  6.   3.   2.  14.   1. 250.   5.   0.   9.   0.]\n"," [  8.   2.   5.   0.   7.   9. 254.   0.   7.   0.]\n"," [  1.   6.   4.   1.   2.   0.   0. 265.   1.  12.]\n"," [  2.   8.   7.   9.   1.  14.   4.   0. 268.  11.]\n"," [  1.   0.   0.   1.  11.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8831975951644002 Precision Macro 0.8827118013707185\n","Change of the performance: 7.356361901289521e-05 0.00023982134779410025 \n","Change of cost:  0.0003219815707460466\n","epoch 7\n","The cost at the end of this epoch is  0.07540992366375344\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   9.   4.   2.   3.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 247.   5.   3.   4.   7.   6.   7.   2.]\n"," [  2.   8.  18. 243.   1.  19.   1.   5.   1.   5.]\n"," [  2.   2.   0.   0. 295.   2.   7.   3.   3.   6.]\n"," [  6.   3.   2.  14.   1. 253.   2.   0.   9.   0.]\n"," [  8.   3.   5.   0.   7.  10. 254.   0.   5.   0.]\n"," [  1.   6.   4.   2.   2.   0.   0. 263.   1.  13.]\n"," [  2.  10.   7.   8.   1.  15.   4.   1. 265.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   3. 241.]]\n","Accuracy Macro 0.8833907333411265 Precision Macro 0.883146509559503\n","Change of the performance: 0.00019313817672628186 0.0004347081887845494 \n","Change of cost:  0.00026855786754764743\n","epoch 8\n","The cost at the end of this epoch is  0.07553098706790282\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 247.   4.   3.   4.   7.   7.   7.   2.]\n"," [  1.   7.  18. 246.   1.  20.   0.   4.   1.   5.]\n"," [  2.   2.   0.   0. 295.   2.   7.   3.   3.   6.]\n"," [  6.   4.   1.  14.   0. 255.   2.   0.   8.   0.]\n"," [  8.   3.   5.   0.   7.  10. 254.   0.   5.   0.]\n"," [  1.   6.   4.   2.   2.   0.   0. 263.   1.  13.]\n"," [  2.  10.   7.  10.   1.  20.   4.   1. 258.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8824697421239538 Precision Macro 0.8823421828193307\n","Change of the performance: 0.0009209912171727064 0.0008043267401722787 \n","Change of cost:  0.0002829750991864277\n","epoch 9\n","The cost at the end of this epoch is  0.07449669609848533\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   2.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 246.   5.   3.   4.   7.   7.   7.   2.]\n"," [  2.   8.  18. 243.   1.  18.   1.   5.   1.   6.]\n"," [  2.   2.   0.   0. 296.   2.   6.   3.   3.   6.]\n"," [  6.   4.   2.  14.   1. 250.   4.   0.   9.   0.]\n"," [  8.   3.   5.   0.   7.  10. 254.   0.   5.   0.]\n"," [  1.   6.   4.   2.   2.   0.   0. 264.   1.  12.]\n"," [  2.   9.   7.   9.   1.  16.   4.   0. 263.  13.]\n"," [  1.   0.   0.   1.  11.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8822982824901351 Precision Macro 0.881785611487866\n","Change of the performance: 0.00017145963381870466 0.0005565713314646947 \n","Change of cost:  0.00016150691397368022\n","epoch 10\n","The cost at the end of this epoch is  0.07427863904209514\n","Now let's test the model after this epoch:\n","Confusion array  [[295.   0.   0.   3.   1.   9.   4.   3.   3.   0.]\n"," [  0. 291.   3.   3.   0.   2.   0.   1.   7.   1.]\n"," [  5.   1. 247.   6.   3.   4.   7.   6.   7.   2.]\n"," [  2.   8.  19. 242.   1.  19.   1.   5.   1.   5.]\n"," [  2.   2.   0.   0. 295.   2.   6.   3.   3.   7.]\n"," [  6.   3.   2.  14.   0. 253.   2.   0.  10.   0.]\n"," [  8.   2.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   6.   3.   1.   2.   0.   0. 266.   1.  12.]\n"," [  2.   9.   7.  10.   1.  14.   4.   1. 266.  10.]\n"," [  1.   0.   0.   1.  11.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.883055565024687 Precision Macro 0.8826671461702347\n","Change of the performance: 0.000757282534551873 0.0008815346823686232 \n","Change of cost:  0.00035607278916088836\n","epoch 11\n","The cost at the end of this epoch is  0.07513247533661385\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.  10.   3.   2.   3.   0.]\n"," [  0. 292.   3.   2.   0.   2.   0.   1.   7.   1.]\n"," [  5.   1. 247.   6.   3.   4.   7.   6.   7.   2.]\n"," [  2.   7.  21. 240.   1.  20.   1.   5.   1.   5.]\n"," [  2.   2.   0.   0. 295.   2.   6.   3.   3.   7.]\n"," [  5.   3.   1.  15.   0. 253.   2.   0.  11.   0.]\n"," [  8.   2.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  15.   4.   0. 265.  12.]\n"," [  1.   0.   0.   1.  10.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8827608905133996 Precision Macro 0.882435352985776\n","Change of the performance: 0.0002946745112873961 0.00023179318445865071 \n","Change of cost:  0.0013589756075862713\n","epoch 12\n","The cost at the end of this epoch is  0.07325270414784343\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   8.   4.   2.   2.   0.]\n"," [  0. 293.   2.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 247.   5.   3.   4.   7.   6.   7.   2.]\n"," [  2.   7.  18. 244.   1.  19.   1.   6.   1.   4.]\n"," [  2.   2.   0.   0. 295.   2.   6.   3.   3.   7.]\n"," [  7.   3.   1.  14.   0. 252.   3.   0.  10.   0.]\n"," [  8.   3.   5.   0.   7.  10. 253.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.  10.   7.   8.   1.  16.   4.   1. 263.  12.]\n"," [  1.   0.   0.   1.  11.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8833526928880714 Precision Macro 0.8830226720267668\n","Change of the performance: 0.0005918023746718237 0.0005873190409907414 \n","Change of cost:  0.00018891054020224451\n","epoch 13\n","The cost at the end of this epoch is  0.07357186890999133\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   8.   4.   3.   3.   0.]\n"," [  0. 293.   2.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 247.   5.   3.   4.   7.   6.   7.   2.]\n"," [  2.   7.  18. 245.   1.  20.   0.   4.   1.   5.]\n"," [  2.   2.   0.   1. 294.   2.   6.   3.   3.   7.]\n"," [  6.   3.   2.  14.   0. 252.   3.   0.  10.   0.]\n"," [  8.   3.   5.   0.   7.  10. 253.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.  10.   1.  16.   4.   1. 262.  12.]\n"," [  1.   0.   0.   1.  10.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8828100115890191 Precision Macro 0.8824009417209538\n","Change of the performance: 0.0005426812990523278 0.0006217303058129175 \n","Change of cost:  0.0002604049629902627\n","epoch 14\n","The cost at the end of this epoch is  0.07321167260683617\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   9.   4.   2.   3.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 247.   5.   3.   4.   7.   6.   7.   2.]\n"," [  2.   7.  19. 241.   1.  20.   1.   6.   1.   5.]\n"," [  2.   2.   0.   0. 295.   2.   6.   3.   3.   7.]\n"," [  6.   3.   2.  14.   0. 253.   2.   0.  10.   0.]\n"," [  8.   2.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.  10.   7.   8.   1.  15.   4.   0. 264.  13.]\n"," [  1.   0.   0.   1.  11.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8827295983755006 Precision Macro 0.8824041223539052\n","Change of the performance: 8.041321351848207e-05 3.1806329513495157e-06 \n","Change of cost:  1.7890919764562696e-06\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_18_650x785_10x651\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [700  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (700, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 701)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 700)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.07668880477550563\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   1.   3.   1.   9.   4.   1.   3.   0.]\n"," [  0. 289.   6.   2.   0.   2.   0.   1.   7.   1.]\n"," [  5.   1. 247.   6.   3.   4.   7.   6.   7.   2.]\n"," [  2.   7.  21. 242.   1.  20.   0.   5.   1.   4.]\n"," [  2.   2.   3.   0. 292.   2.   6.   3.   3.   7.]\n"," [  6.   3.   1.  15.   0. 253.   2.   0.  10.   0.]\n"," [  8.   3.   5.   0.   7.  10. 253.   0.   6.   0.]\n"," [  1.   5.   4.   1.   2.   0.   0. 267.   1.  11.]\n"," [  2.   7.   7.  11.   1.  12.   4.   0. 269.  11.]\n"," [  1.   0.   0.   1.  11.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8827091057100673 Precision Macro 0.8824290003516874\n","epoch 1\n","The cost at the end of this epoch is  0.07599560105532718\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   5.   4.   3.   2.   0.]\n"," [  0. 294.   2.   4.   0.   2.   0.   0.   5.   1.]\n"," [  5.   4. 241.   7.   3.   3.   7.  10.   7.   1.]\n"," [  1.   8.  16. 246.   1.  19.   1.   5.   1.   5.]\n"," [  2.   2.   0.   0. 296.   2.   6.   3.   3.   6.]\n"," [  7.   3.   2.  14.   1. 250.   4.   0.   9.   0.]\n"," [  8.   3.   5.   0.   7.   9. 253.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.  11.   7.  11.   1.  16.   4.   2. 258.  12.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.880585308164101 Precision Macro 0.880048111245592\n","epoch 2\n","The cost at the end of this epoch is  0.07432190372349724\n","Now let's test the model after this epoch:\n","Confusion array  [[295.   0.   0.   3.   1.   9.   4.   3.   3.   0.]\n"," [  0. 292.   2.   4.   0.   2.   0.   1.   6.   1.]\n"," [  5.   1. 244.   6.   3.   4.   7.   9.   8.   1.]\n"," [  2.   7.  17. 243.   1.  22.   0.   5.   1.   5.]\n"," [  2.   2.   0.   0. 296.   2.   6.   3.   3.   6.]\n"," [  6.   3.   1.  15.   0. 253.   3.   0.   9.   0.]\n"," [  8.   3.   5.   0.   7.  10. 253.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.  10.   7.   9.   1.  16.   4.   0. 264.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8813015327379634 Precision Macro 0.8812145491644712\n","Change of the performance: 0.0007162245738624451 0.0011664379188791596 \n","Change of cost:  0.0010938647462087198\n","epoch 3\n","The cost at the end of this epoch is  0.07371111823843399\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   7.   3.   3.   2.   0.]\n"," [  0. 291.   3.   3.   0.   3.   0.   1.   6.   1.]\n"," [  5.   1. 245.   5.   3.   3.   7.  10.   8.   1.]\n"," [  2.   8.  17. 242.   1.  21.   0.   6.   1.   5.]\n"," [  2.   2.   0.   0. 296.   2.   5.   3.   3.   7.]\n"," [  8.   3.   1.  14.   1. 249.   5.   0.   9.   0.]\n"," [  8.   2.   5.   0.   7.   9. 254.   0.   7.   0.]\n"," [  1.   5.   4.   0.   2.   0.   0. 267.   1.  12.]\n"," [  2.   9.   7.   9.   1.  12.   4.   1. 267.  12.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8835806380899346 Precision Macro 0.883123429718005\n","Change of the performance: 0.002279105351971178 0.001908880553533776 \n","Change of cost:  0.0005874140697633701\n","epoch 4\n","The cost at the end of this epoch is  0.07323942159182738\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 291.   4.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 246.   5.   3.   3.   7.   7.   8.   2.]\n"," [  2.   8.  20. 241.   1.  19.   0.   5.   1.   6.]\n"," [  2.   2.   0.   1. 294.   2.   6.   3.   3.   7.]\n"," [  8.   3.   1.  15.   0. 249.   5.   0.   9.   0.]\n"," [  8.   3.   5.   0.   7.   9. 253.   0.   7.   0.]\n"," [  1.   6.   3.   1.   2.   0.   0. 267.   1.  11.]\n"," [  4.   9.   7.  10.   1.  11.   4.   1. 267.  10.]\n"," [  1.   0.   0.   1.  11.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8831963992912808 Precision Macro 0.8825733182769898\n","Change of the performance: 0.00038423879865379096 0.0005501114410151331 \n","Change of cost:  0.00018775778195122272\n","epoch 5\n","The cost at the end of this epoch is  0.07334889554213815\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   5.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 247.   4.   3.   3.   7.   7.   8.   2.]\n"," [  3.   8.  20. 241.   1.  20.   0.   5.   0.   5.]\n"," [  2.   2.   0.   1. 293.   1.   8.   3.   3.   7.]\n"," [  8.   3.   1.  14.   0. 250.   6.   0.   8.   0.]\n"," [  8.   2.   5.   0.   7.   9. 254.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.  10.   7.   9.   1.  15.   4.   0. 263.  12.]\n"," [  1.   1.   0.   1.  11.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8819564421950303 Precision Macro 0.8813337174242136\n","Change of the performance: 0.0012399570962504658 0.0012396008527761904 \n","Change of cost:  0.0018520722902327924\n","epoch 6\n","The cost at the end of this epoch is  0.07246740531618673\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   8.   4.   3.   3.   0.]\n"," [  0. 291.   4.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   1. 246.   6.   3.   3.   7.   7.   8.   2.]\n"," [  2.   7.  20. 242.   1.  20.   0.   5.   1.   5.]\n"," [  2.   2.   0.   1. 294.   2.   6.   3.   3.   7.]\n"," [  7.   3.   1.  14.   0. 252.   3.   0.  10.   0.]\n"," [  8.   2.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  16.   4.   0. 263.  13.]\n"," [  1.   0.   0.   1.  10.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8814744474362785 Precision Macro 0.8809229902261704\n","Change of the performance: 0.00048199475875188025 0.0004107271980432481 \n","Change of cost:  5.895406900982558e-05\n","epoch 7\n","The cost at the end of this epoch is  0.0729300469885066\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   8.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 246.   5.   3.   4.   7.   6.   8.   2.]\n"," [  2.   7.  20. 243.   1.  20.   0.   5.   1.   4.]\n"," [  2.   2.   0.   1. 294.   2.   6.   3.   3.   7.]\n"," [  6.   3.   1.  14.   0. 254.   2.   0.  10.   0.]\n"," [  7.   1.   5.   0.   7.   9. 256.   0.   7.   0.]\n"," [  1.   5.   4.   1.   2.   0.   0. 265.   1.  13.]\n"," [  2.   9.   7.   9.   1.  15.   4.   0. 266.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8836749513883111 Precision Macro 0.8833508405537731\n","Change of the performance: 0.0022005039520326397 0.002427850327602732 \n","Change of cost:  0.0005551461570778571\n","epoch 8\n","The cost at the end of this epoch is  0.07209259764365818\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   8.   4.   3.   3.   0.]\n"," [  0. 295.   2.   3.   0.   2.   0.   0.   5.   1.]\n"," [  5.   3. 244.   6.   3.   4.   7.   6.   8.   2.]\n"," [  2.   8.  18. 244.   1.  20.   0.   5.   1.   4.]\n"," [  2.   2.   0.   1. 294.   2.   6.   3.   3.   7.]\n"," [  7.   3.   1.  14.   0. 255.   2.   0.   8.   0.]\n"," [  8.   3.   5.   0.   7.   9. 253.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 266.   1.  11.]\n"," [  2.  10.   7.   9.   1.  17.   4.   1. 262.  11.]\n"," [  1.   0.   0.   1.  10.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8834646110804479 Precision Macro 0.8832541841933679\n","Change of the performance: 0.00021034030786315494 9.665636040523395e-05 \n","Change of cost:  0.0001799266176360087\n","epoch 9\n","The cost at the end of this epoch is  0.071997972381736\n","Now let's test the model after this epoch:\n","Confusion array  [[295.   0.   0.   3.   1.  10.   3.   3.   3.   0.]\n"," [  0. 294.   2.   3.   0.   2.   0.   1.   5.   1.]\n"," [  5.   2. 245.   4.   3.   3.   7.   9.   8.   2.]\n"," [  2.   8.  18. 241.   1.  20.   1.   6.   1.   5.]\n"," [  2.   2.   0.   1. 293.   2.   7.   3.   3.   7.]\n"," [  5.   3.   1.  15.   0. 254.   2.   0.  10.   0.]\n"," [  7.   3.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   8.   1.  17.   4.   1. 261.  14.]\n"," [  1.   0.   0.   0.  10.   1.   0.   9.   2. 242.]]\n","Accuracy Macro 0.8815939824883394 Precision Macro 0.8811550315115415\n","Change of the performance: 0.0018706285921085142 0.002099152681826366 \n","Change of cost:  0.00026224822731305\n","epoch 10\n","The cost at the end of this epoch is  0.07152681708889637\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  19. 245.   1.  19.   0.   5.   1.   3.]\n"," [  2.   2.   0.   1. 294.   2.   6.   3.   3.   7.]\n"," [  6.   3.   2.  14.   0. 251.   4.   0.  10.   0.]\n"," [  8.   3.   5.   0.   7.   9. 253.   0.   7.   0.]\n"," [  1.   6.   3.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.  10.   1.  15.   4.   0. 265.  11.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.882958447727208 Precision Macro 0.8825642560365496\n","Change of the performance: 0.001364465238868573 0.0014092245250081348 \n","Change of cost:  0.00013393801545170947\n","epoch 11\n","The cost at the end of this epoch is  0.07095406633067984\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   8.   4.   3.   3.   0.]\n"," [  0. 291.   3.   3.   0.   2.   0.   1.   7.   1.]\n"," [  5.   2. 246.   5.   3.   3.   7.   7.   8.   2.]\n"," [  2.   8.  20. 241.   1.  19.   0.   6.   1.   5.]\n"," [  2.   2.   0.   1. 294.   2.   6.   3.   3.   7.]\n"," [  7.   3.   1.  14.   0. 251.   4.   0.  10.   0.]\n"," [  7.   3.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  17.   4.   0. 263.  12.]\n"," [  1.   0.   0.   1.  10.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8807995868467712 Precision Macro 0.8802424305657844\n","Change of the performance: 0.0021588608804368192 0.002321825470765204 \n","Change of cost:  0.0003413109199322528\n","epoch 12\n","The cost at the end of this epoch is  0.07160156230618878\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   6.   3.   3.   2.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 241.   1.  18.   1.   6.   1.   5.]\n"," [  2.   2.   0.   1. 294.   2.   6.   3.   3.   7.]\n"," [  7.   3.   2.  15.   0. 250.   4.   0.   9.   0.]\n"," [  8.   2.   5.   0.   7.   9. 254.   0.   7.   0.]\n"," [  1.   5.   4.   1.   2.   0.   0. 266.   1.  12.]\n"," [  2.   9.   7.   9.   1.  15.   4.   0. 264.  13.]\n"," [  1.   0.   0.   1.  10.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8823411817269708 Precision Macro 0.8815706400183071\n","Change of the performance: 0.0015415948801996704 0.001328209452522655 \n","Change of cost:  0.0005514098035142578\n","epoch 13\n","The cost at the end of this epoch is  0.07092843142168115\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 241.   1.  19.   0.   6.   1.   5.]\n"," [  2.   2.   0.   1. 294.   2.   6.   3.   3.   7.]\n"," [  6.   3.   2.  14.   0. 251.   4.   0.  10.   0.]\n"," [  8.   3.   5.   0.   7.   9. 253.   0.   7.   0.]\n"," [  1.   5.   4.   1.   2.   0.   0. 266.   1.  12.]\n"," [  2.   9.   7.   8.   1.  15.   4.   0. 264.  14.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.881022788842772 Precision Macro 0.8804349346669984\n","Change of the performance: 0.0013183928841988823 0.0011357053513086912 \n","Change of cost:  4.772757236942704e-05\n","epoch 14\n","The cost at the end of this epoch is  0.07085850493372271\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 246.   4.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  18.   1.   5.   1.   5.]\n"," [  2.   2.   0.   1. 294.   2.   6.   3.   3.   7.]\n"," [  7.   3.   1.  14.   0. 251.   4.   0.  10.   0.]\n"," [  7.   2.   5.   0.   7.   9. 255.   0.   7.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  17.   4.   0. 263.  12.]\n"," [  1.   0.   0.   1.  10.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8824359016616519 Precision Macro 0.8817870098831342\n","Change of the performance: 0.0014131128188799025 0.001352075216135784 \n","Change of cost:  0.00032238171141060756\n","epoch 15\n","The cost at the end of this epoch is  0.07051311013775094\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   8.   4.   3.   3.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  20.   0.   5.   1.   4.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   3.   7.]\n"," [  7.   3.   1.  14.   0. 253.   3.   0.   9.   0.]\n"," [  7.   3.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  17.   4.   0. 263.  12.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8817440449590478 Precision Macro 0.8814048747564257\n","Change of the performance: 0.0006918567026040767 0.0003821351267084827 \n","Change of cost:  6.583714275366914e-05\n","epoch 16\n","The cost at the end of this epoch is  0.07051406419421556\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   8.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  19.   0.   5.   1.   5.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   3.   7.]\n"," [  6.   3.   2.  14.   0. 252.   3.   0.  10.   0.]\n"," [  8.   3.   5.   0.   7.  10. 253.   0.   6.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  15.   4.   0. 264.  13.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8810407182700496 Precision Macro 0.8805745315841541\n","Change of the performance: 0.000703326688998196 0.000830343172271597 \n","Change of cost:  4.326505887788934e-06\n","epoch 17\n","The cost at the end of this epoch is  0.07031751852796217\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 246.   4.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  20.   0.   5.   1.   4.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   3.   7.]\n"," [  6.   3.   2.  14.   0. 253.   3.   0.   9.   0.]\n"," [  7.   3.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  17.   4.   0. 263.  12.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8824057325900752 Precision Macro 0.8820674295067878\n","Change of the performance: 0.0013650143200255593 0.0014928979226337402 \n","Change of cost:  2.3612272523954037e-05\n","epoch 18\n","The cost at the end of this epoch is  0.07019827830102057\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  20.   0.   5.   1.   4.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   3.   7.]\n"," [  7.   3.   1.  14.   0. 251.   4.   0.  10.   0.]\n"," [  7.   2.   5.   0.   7.  10. 255.   0.   6.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  17.   4.   0. 263.  12.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8817113209488637 Precision Macro 0.8812830653701959\n","Change of the performance: 0.0006944116412114232 0.0007843641365919973 \n","Change of cost:  5.265877234733596e-06\n","epoch 19\n","The cost at the end of this epoch is  0.0700646155259264\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  20.   0.   5.   1.   4.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   3.   7.]\n"," [  7.   3.   1.  14.   0. 253.   3.   0.   9.   0.]\n"," [  7.   3.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  17.   4.   0. 263.  12.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8820585103678529 Precision Macro 0.8817199971171877\n","Change of the performance: 0.0003471894189891467 0.0004369317469918865 \n","Change of cost:  1.2530641486860339e-05\n","epoch 20\n","The cost at the end of this epoch is  0.07003239325047352\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  19.   0.   5.   1.   5.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   3.   7.]\n"," [  6.   3.   2.  14.   0. 251.   4.   0.  10.   0.]\n"," [  7.   3.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   5.   4.   1.   2.   0.   0. 266.   1.  12.]\n"," [  2.   9.   7.   9.   1.  16.   4.   1. 263.  12.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8813866456241884 Precision Macro 0.8808593287529348\n","Change of the performance: 0.0006718647436644298 0.0008606683642529145 \n","Change of cost:  1.0065068415804346e-06\n","epoch 21\n","The cost at the end of this epoch is  0.06981667656598814\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  19.   1.   5.   1.   4.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   3.   7.]\n"," [  7.   3.   1.  14.   0. 253.   3.   0.   9.   0.]\n"," [  7.   3.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  17.   4.   0. 263.  12.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8820585103678529 Precision Macro 0.881646686343885\n","Change of the performance: 0.0006718647436644298 0.0007873575909501662 \n","Change of cost:  3.3452236699454962e-06\n","epoch 22\n","The cost at the end of this epoch is  0.069722696991872\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  19.   0.   5.   1.   5.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   3.   7.]\n"," [  6.   3.   2.  14.   0. 252.   3.   0.  10.   0.]\n"," [  7.   3.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   5.   4.   1.   2.   0.   0. 266.   1.  12.]\n"," [  2.   9.   7.   9.   1.  17.   4.   0. 263.  12.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8817314732103952 Precision Macro 0.8812974944863621\n","Change of the performance: 0.0003270371574576325 0.0003491918575229125 \n","Change of cost:  7.483465596092032e-07\n","epoch 23\n","The cost at the end of this epoch is  0.06967952959288551\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  18.   1.   5.   1.   5.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   3.   7.]\n"," [  7.   3.   1.  14.   0. 252.   3.   0.  10.   0.]\n"," [  7.   3.   5.   0.   7.  10. 254.   0.   6.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  2.   9.   7.   9.   1.  17.   4.   0. 263.  12.]\n"," [  1.   1.   0.   1.  10.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8817136827816459 Precision Macro 0.8812416556924362\n","Change of the performance: 1.7790428749386855e-05 5.5838793925899743e-05 \n","Change of cost:  5.496004918231767e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_18_700x785_10x701\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [750  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (750, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 751)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 750)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.3397610290170302\n","Now let's test the model after this epoch:\n","Confusion array  [[295.   0.   1.   2.   1.  11.   3.   0.   4.   1.]\n"," [  0. 297.   0.   1.   1.   3.   2.   0.   3.   1.]\n"," [  5.  17. 223.  11.   3.   5.   8.   0.  15.   1.]\n"," [  1.  21.  12. 225.   1.  29.   0.   3.   8.   3.]\n"," [  1.   3.   2.   0. 296.   1.  11.   1.   2.   3.]\n"," [  1.   3.   1.  11.   0. 253.   2.   0.  16.   3.]\n"," [  9.   2.   4.   1.   4.  11. 259.   0.   2.   0.]\n"," [  1.  10.   7.  10.   5.   1.   0. 204.   3.  51.]\n"," [  1.  17.   2.   7.   1.  25.   9.   1. 248.  13.]\n"," [  1.   2.   1.   0.  12.   1.   0.   5.   3. 240.]]\n","Accuracy Macro 0.8462961190825389 Precision Macro 0.852307464452174\n","epoch 1\n","The cost at the end of this epoch is  0.25917645846863024\n","Now let's test the model after this epoch:\n","Confusion array  [[307.   0.   0.   1.   1.   1.   3.   2.   3.   0.]\n"," [  0. 294.   6.   1.   0.   1.   0.   0.   5.   1.]\n"," [ 14.   9. 226.   9.   3.   1.   4.  11.   9.   2.]\n"," [  7.  13.  17. 241.   1.   8.   0.   6.   6.   4.]\n"," [  3.   2.   2.   0. 289.   0.   3.   7.   7.   7.]\n"," [ 13.   6.   2.  14.   1. 223.   9.   0.  13.   9.]\n"," [ 11.   5.   6.   0.   7.   2. 251.   0.  10.   0.]\n"," [  2.   5.   3.   0.   1.   0.   0. 269.   5.   7.]\n"," [  9.  10.   8.   8.   1.   6.   1.   2. 272.   7.]\n"," [  1.   0.   0.   0.  11.   1.   0.  12.   2. 238.]]\n","Accuracy Macro 0.8690587835189193 Precision Macro 0.872439937360828\n","epoch 2\n","The cost at the end of this epoch is  0.16368049563166673\n","Now let's test the model after this epoch:\n","Confusion array  [[294.   0.   0.   2.   1.   9.   8.   1.   3.   0.]\n"," [  0. 290.   6.   1.   0.   3.   0.   1.   7.   0.]\n"," [  4.   1. 247.   6.   3.   3.   7.   7.   9.   1.]\n"," [  2.   9.  32. 220.   1.  24.   1.   5.   5.   4.]\n"," [  0.   2.   2.   0. 300.   3.   3.   3.   4.   3.]\n"," [  3.   5.   2.  12.   1. 251.   3.   0.  12.   1.]\n"," [  4.   2.   5.   0.   7.   9. 255.   0.  10.   0.]\n"," [  1.   3.   8.   1.   6.   0.   0. 265.   1.   7.]\n"," [  2.   5.   8.   6.   1.   8.   3.   2. 284.   5.]\n"," [  1.   0.   0.   0.  25.   2.   0.   9.   4. 224.]]\n","Accuracy Macro 0.8755463627526845 Precision Macro 0.8785282455784567\n","Change of the performance: 0.006487579233765195 0.006088308217628624 \n","Change of cost:  0.042481252114985366\n","epoch 3\n","The cost at the end of this epoch is  0.09083073179857762\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   5.   3.   1.   2.   0.]\n"," [  0. 293.   3.   2.   0.   2.   0.   1.   7.   0.]\n"," [  5.   2. 244.   5.   2.   5.   8.   9.   7.   1.]\n"," [  2.   9.  19. 242.   1.  19.   0.   5.   2.   4.]\n"," [  2.   3.   1.   0. 292.   2.   6.   4.   2.   8.]\n"," [  7.   4.   1.  17.   0. 250.   2.   0.   7.   2.]\n"," [  8.   3.   6.   0.   4.  10. 256.   0.   5.   0.]\n"," [  1.   4.   3.   1.   2.   0.   0. 268.   4.   9.]\n"," [  5.   8.   6.   9.   1.  16.   4.   0. 265.  10.]\n"," [  1.   0.   0.   0.  10.   1.   0.   9.   2. 242.]]\n","Accuracy Macro 0.8847084621299075 Precision Macro 0.8842895995630193\n","Change of the performance: 0.00916209937722301 0.005761353984562678 \n","Change of cost:  0.008710015201049276\n","epoch 4\n","The cost at the end of this epoch is  0.0890160890797275\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   6.   3.   1.   3.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   1.   6.   0.]\n"," [  4.   2. 243.   4.   2.   5.   9.   8.  10.   1.]\n"," [  2.   9.  17. 249.   1.  16.   0.   5.   3.   1.]\n"," [  2.   4.   1.   0. 291.   2.   4.   3.   3.  10.]\n"," [  6.   4.   1.  17.   0. 250.   3.   0.   8.   1.]\n"," [  7.   3.   5.   0.   4.  10. 258.   0.   5.   0.]\n"," [  1.   5.   3.   2.   2.   0.   0. 265.   2.  12.]\n"," [  4.   7.   8.   8.   1.  10.   3.   1. 274.   8.]\n"," [  1.   0.   0.   0.  11.   1.   0.  10.   2. 240.]]\n","Accuracy Macro 0.8877353104810739 Precision Macro 0.8875684626223472\n","Change of the performance: 0.0030268483511664 0.0032788630593278967 \n","Change of cost:  0.003667428569496506\n","epoch 5\n","The cost at the end of this epoch is  0.07894345557387288\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   8.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   6.   0.]\n"," [  4.   2. 245.   4.   2.   6.   9.   8.   7.   1.]\n"," [  2.   6.  20. 244.   1.  19.   1.   5.   3.   2.]\n"," [  2.   3.   0.   0. 298.   2.   5.   3.   2.   5.]\n"," [  5.   4.   2.  16.   0. 254.   2.   0.   7.   0.]\n"," [  7.   3.   4.   0.   5.  11. 258.   0.   4.   0.]\n"," [  1.   3.   4.   1.   2.   0.   0. 269.   2.  10.]\n"," [  4.   7.   7.   8.   1.  14.   4.   1. 270.   8.]\n"," [  1.   0.   0.   0.  13.   1.   0.  10.   2. 238.]]\n","Accuracy Macro 0.888773372242891 Precision Macro 0.8889529850034574\n","Change of the performance: 0.0010380617618170884 0.001384522381110198 \n","Change of cost:  0.0032235106359609633\n","epoch 6\n","The cost at the end of this epoch is  0.07612253930257631\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   1.   6.   0.]\n"," [  4.   2. 248.   4.   2.   4.   8.   8.   7.   1.]\n"," [  2.   7.  18. 247.   1.  16.   0.   7.   2.   3.]\n"," [  2.   4.   0.   0. 293.   2.   4.   3.   3.   9.]\n"," [  6.   4.   1.  17.   1. 250.   3.   0.   8.   0.]\n"," [  7.   3.   4.   0.   5.  11. 257.   0.   5.   0.]\n"," [  1.   4.   4.   1.   2.   0.   0. 267.   1.  12.]\n"," [  5.   9.   7.   8.   1.  13.   4.   1. 267.   9.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8879956860024147 Precision Macro 0.8874776801372264\n","Change of the performance: 0.0007776862404762497 0.001475304866231042 \n","Change of cost:  0.0004548717311778083\n","epoch 7\n","The cost at the end of this epoch is  0.07366810234931022\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   7.   3.   2.   3.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 247.   5.   3.   4.   7.   7.   7.   1.]\n"," [  2.   7.  17. 245.   1.  20.   0.   5.   2.   4.]\n"," [  2.   4.   0.   0. 295.   2.   4.   3.   2.   8.]\n"," [  6.   4.   1.  14.   0. 258.   2.   0.   5.   0.]\n"," [  6.   3.   4.   0.   6.  11. 256.   0.   6.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 264.   1.  13.]\n"," [  3.   8.   7.   7.   1.  17.   4.   1. 267.   9.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.887671190816697 Precision Macro 0.8878570140952047\n","Change of the performance: 0.0003244951857177547 0.0003793339579782895 \n","Change of cost:  0.0010564287800488154\n","epoch 8\n","The cost at the end of this epoch is  0.07336595238325076\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   5.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 246.   5.   3.   4.   7.   7.   8.   2.]\n"," [  2.   7.  18. 239.   1.  21.   0.   8.   3.   4.]\n"," [  2.   3.   0.   0. 296.   1.   4.   3.   3.   8.]\n"," [  6.   4.   1.  14.   0. 255.   2.   0.   8.   0.]\n"," [  7.   3.   4.   0.   6.  11. 256.   0.   5.   0.]\n"," [  1.   3.   5.   0.   2.   0.   0. 265.   1.  15.]\n"," [  5.   8.   7.   7.   1.  15.   4.   1. 266.  10.]\n"," [  1.   0.   0.   1.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8852216493300171 Precision Macro 0.8850779898684495\n","Change of the performance: 0.0024495414866798626 0.0027790242267551335 \n","Change of cost:  0.00032203460564003694\n","epoch 9\n","The cost at the end of this epoch is  0.07197017915553473\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   6.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 245.   4.   3.   4.   7.   8.   9.   2.]\n"," [  2.   7.  17. 244.   1.  20.   0.   6.   2.   4.]\n"," [  2.   4.   0.   0. 294.   2.   4.   3.   3.   8.]\n"," [  5.   4.   2.  16.   0. 254.   2.   0.   7.   0.]\n"," [  7.   3.   4.   0.   6.  11. 256.   0.   5.   0.]\n"," [  1.   4.   3.   1.   2.   0.   0. 267.   1.  13.]\n"," [  3.   8.   7.   8.   1.  15.   4.   1. 266.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.  11.   1. 238.]]\n","Accuracy Macro 0.8852334067367627 Precision Macro 0.8850711653423853\n","Change of the performance: 1.1757406745527277e-05 6.8245260642640915e-06 \n","Change of cost:  0.0003896838394870511\n","epoch 10\n","The cost at the end of this epoch is  0.07076504722586482\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   6.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   6.   0.]\n"," [  4.   2. 247.   5.   3.   4.   7.   7.   8.   1.]\n"," [  2.   7.  18. 243.   1.  20.   0.   6.   2.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 255.   2.   0.   7.   0.]\n"," [  7.   3.   4.   0.   6.  11. 256.   0.   5.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 266.   1.  12.]\n"," [  3.   8.   7.   9.   1.  17.   4.   1. 264.  10.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.885360254550638 Precision Macro 0.8851270575279487\n","Change of the performance: 0.000126847813875397 5.589218556345532e-05 \n","Change of cost:  7.39146668432833e-05\n","epoch 11\n","The cost at the end of this epoch is  0.07080428804159543\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   4.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 246.   4.   3.   4.   7.   8.   8.   2.]\n"," [  2.   7.  18. 242.   1.  19.   1.   6.   2.   5.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 252.   3.   0.   8.   0.]\n"," [  7.   3.   4.   0.   6.  10. 256.   0.   6.   0.]\n"," [  1.   4.   4.   1.   2.   0.   0. 265.   1.  14.]\n"," [  4.   8.   7.   7.   1.  15.   4.   1. 267.  10.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8845464421478011 Precision Macro 0.8840654420587635\n","Change of the performance: 0.0008138124028369553 0.001061615469185262 \n","Change of cost:  0.0003812098083080112\n","epoch 12\n","The cost at the end of this epoch is  0.07055013505698933\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   2.   3.   1.   7.   3.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 246.   4.   3.   4.   7.   8.   8.   2.]\n"," [  2.   8.  18. 241.   1.  21.   0.   6.   1.   5.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 254.   2.   0.   8.   0.]\n"," [  7.   3.   4.   0.   6.  11. 256.   0.   5.   0.]\n"," [  1.   4.   5.   0.   2.   0.   0. 264.   1.  15.]\n"," [  3.   8.   7.   7.   1.  18.   4.   1. 265.  10.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8836420591199378 Precision Macro 0.8835232819585898\n","Change of the performance: 0.0009043830278633314 0.0005421601001737164 \n","Change of cost:  0.00011214215238632141\n","epoch 13\n","The cost at the end of this epoch is  0.07065505039388678\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   2.   3.   1.   7.   3.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 247.   5.   3.   4.   7.   6.   8.   2.]\n"," [  2.   8.  18. 243.   1.  20.   0.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 255.   2.   0.   7.   0.]\n"," [  7.   3.   5.   0.   6.  11. 256.   0.   4.   0.]\n"," [  1.   4.   5.   3.   2.   0.   0. 263.   1.  13.]\n"," [  3.   9.   7.   8.   1.  17.   4.   1. 264.  10.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8843430672062343 Precision Macro 0.8841316630872418\n","Change of the performance: 0.000701008086296584 0.0006083811286520246 \n","Change of cost:  0.00021996807066924917\n","epoch 14\n","The cost at the end of this epoch is  0.06983166201436637\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   5.   3.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 247.   4.   3.   4.   7.   7.   8.   2.]\n"," [  2.   8.  18. 243.   1.  20.   0.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  14.   0. 255.   2.   0.   8.   0.]\n"," [  7.   3.   4.   0.   6.  11. 257.   0.   4.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 262.   1.  15.]\n"," [  3.   9.   7.   7.   1.  17.   4.   1. 265.  10.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8852806399991531 Precision Macro 0.8850510999013368\n","Change of the performance: 0.0009375727929187283 0.0009194368140950093 \n","Change of cost:  0.00020492436585407836\n","epoch 15\n","The cost at the end of this epoch is  0.06972520094504102\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   6.   3.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 246.   5.   3.   4.   7.   7.   8.   2.]\n"," [  2.   8.  18. 243.   1.  20.   0.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 254.   2.   0.   8.   0.]\n"," [  7.   3.   5.   0.   6.  11. 255.   0.   5.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   9.   7.   8.   1.  17.   4.   1. 263.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8839993065847264 Precision Macro 0.8837045017833323\n","Change of the performance: 0.0012813334144267108 0.0013465981180045272 \n","Change of cost:  9.749473948106324e-06\n","epoch 16\n","The cost at the end of this epoch is  0.06945638009915225\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   4.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 246.   5.   3.   4.   7.   7.   8.   2.]\n"," [  2.   8.  18. 243.   1.  20.   0.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 254.   2.   0.   8.   0.]\n"," [  7.   3.   5.   0.   6.  11. 256.   0.   4.   0.]\n"," [  1.   4.   5.   3.   2.   0.   0. 264.   1.  12.]\n"," [  3.   9.   7.   9.   1.  17.   4.   1. 262.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8840051300182227 Precision Macro 0.8835444339860443\n","Change of the performance: 5.823433496310315e-06 0.00016006779728794385 \n","Change of cost:  2.1932895826276555e-05\n","epoch 17\n","The cost at the end of this epoch is  0.06928756612873743\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 246.   5.   3.   4.   7.   7.   8.   2.]\n"," [  2.   8.  18. 243.   1.  20.   0.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 254.   2.   0.   8.   0.]\n"," [  7.   3.   5.   0.   6.  11. 255.   0.   5.   0.]\n"," [  1.   4.   5.   3.   2.   0.   0. 264.   1.  12.]\n"," [  3.   9.   7.   9.   1.  17.   4.   1. 262.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.883348198855993 Precision Macro 0.8829354160040184\n","Change of the performance: 0.0006569311622296459 0.00060901798202595 \n","Change of cost:  3.3189154861307246e-05\n","epoch 18\n","The cost at the end of this epoch is  0.06924864098273038\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   6.   3.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 246.   5.   3.   4.   7.   7.   8.   2.]\n"," [  2.   8.  18. 243.   1.  19.   1.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 254.   2.   0.   8.   0.]\n"," [  7.   3.   5.   0.   6.  11. 255.   0.   5.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   9.   7.   9.   1.  17.   4.   1. 262.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8836906646094176 Precision Macro 0.8832779273056011\n","Change of the performance: 0.000342465753424559 0.00034251130158269305 \n","Change of cost:  1.3842214278567133e-05\n","epoch 19\n","The cost at the end of this epoch is  0.06916883862760877\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 246.   5.   3.   4.   7.   7.   8.   2.]\n"," [  2.   8.  18. 243.   1.  19.   1.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 254.   2.   0.   8.   0.]\n"," [  7.   3.   5.   0.   6.  11. 255.   0.   5.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 266.   1.  12.]\n"," [  3.   9.   7.   9.   1.  17.   4.   1. 262.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8840331303628423 Precision Macro 0.883550454184722\n","Change of the performance: 0.00034246575342467 0.00027252687912093787 \n","Change of cost:  1.5142693185435374e-05\n","epoch 20\n","The cost at the end of this epoch is  0.06910996610354558\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   4.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 247.   4.   3.   4.   7.   7.   8.   2.]\n"," [  2.   8.  18. 243.   1.  19.   1.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 254.   2.   0.   8.   0.]\n"," [  7.   3.   5.   0.   6.  11. 256.   0.   4.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   9.   7.   9.   1.  17.   4.   1. 262.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8846948179938694 Precision Macro 0.8841783473963879\n","Change of the performance: 0.0006616876310271413 0.0006278932116658975 \n","Change of cost:  2.388225206219341e-05\n","epoch 21\n","The cost at the end of this epoch is  0.0690587327591651\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 247.   4.   3.   4.   7.   7.   8.   2.]\n"," [  2.   8.  18. 243.   1.  19.   1.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 254.   2.   0.   8.   0.]\n"," [  7.   3.   5.   0.   6.  11. 256.   0.   4.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   9.   7.   9.   1.  17.   4.   1. 261.  12.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8840717106097559 Precision Macro 0.8835460648515034\n","Change of the performance: 0.0006231073841135304 0.0006322825448844549 \n","Change of cost:  6.592953738213114e-06\n","epoch 22\n","The cost at the end of this epoch is  0.06902777510136195\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 247.   4.   3.   4.   7.   7.   8.   2.]\n"," [  2.   8.  18. 243.   1.  19.   1.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 254.   2.   0.   8.   0.]\n"," [  7.   3.   5.   0.   6.  11. 256.   0.   4.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   9.   7.   9.   1.  17.   4.   1. 262.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8843803525850644 Precision Macro 0.8838953675199013\n","Change of the performance: 0.00030864197530855453 0.00034930266839783286 \n","Change of cost:  9.947214933803128e-06\n","epoch 23\n","The cost at the end of this epoch is  0.06900367427802591\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 294.   3.   2.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 247.   4.   3.   4.   7.   7.   8.   2.]\n"," [  2.   8.  18. 243.   1.  19.   1.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   1.   6.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 254.   2.   0.   8.   0.]\n"," [  7.   3.   5.   0.   6.  11. 256.   0.   4.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   9.   7.   9.   1.  17.   4.   1. 262.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8843803525850644 Precision Macro 0.8838953675199013\n","Change of the performance: 0.0 0.0 \n","Change of cost:  3.685396855052092e-06\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_19_750x785_10x751\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [800  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (800, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 801)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 800)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.2042496604309062\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   1.   1.  10.   2.   1.   2.   0.]\n"," [  0. 292.   1.   1.   1.   4.   1.   2.   6.   0.]\n"," [  5.   7. 224.   5.   3.   8.   9.  10.  15.   2.]\n"," [  1.  10.  14. 226.   1.  35.   0.   6.   5.   5.]\n"," [  1.   1.   2.   1. 301.   0.   4.   2.   1.   7.]\n"," [  5.   3.   1.   8.   2. 262.   3.   0.   6.   0.]\n"," [  9.   3.   6.   0.   7.   8. 256.   0.   3.   0.]\n"," [  2.   5.   4.   0.   3.   0.   0. 264.   0.  14.]\n"," [  3.  10.   7.   7.   1.  24.   4.   0. 257.  11.]\n"," [  1.   0.   0.   0.  14.   1.   0.  15.   0. 234.]]\n","Accuracy Macro 0.8716224477841592 Precision Macro 0.8740183211317228\n","epoch 1\n","The cost at the end of this epoch is  0.11286498827006756\n","Now let's test the model after this epoch:\n","Confusion array  [[292.   0.   2.   3.   1.  14.   2.   2.   2.   0.]\n"," [  0. 292.   6.   1.   0.   2.   0.   1.   6.   0.]\n"," [  3.   2. 245.   5.   2.   4.   7.   9.  10.   1.]\n"," [  1.   8.  25. 243.   1.  12.   0.   8.   4.   1.]\n"," [  1.   3.   2.   0. 293.   2.   5.   3.   3.   8.]\n"," [  2.   4.   2.  18.   1. 252.   1.   0.  10.   0.]\n"," [  7.   3.   4.   0.   6.   8. 256.   0.   8.   0.]\n"," [  2.   2.   6.   1.   2.   0.   0. 267.   3.   9.]\n"," [  4.   6.  10.   6.   1.   9.   4.   2. 278.   4.]\n"," [  1.   0.   0.   0.  12.   1.   0.  10.   4. 237.]]\n","Accuracy Macro 0.8847016305878757 Precision Macro 0.8855479098626942\n","epoch 2\n","The cost at the end of this epoch is  0.08472539120628675\n","Now let's test the model after this epoch:\n","Confusion array  [[295.   0.   3.   3.   1.  10.   3.   1.   2.   0.]\n"," [  0. 292.   4.   2.   0.   3.   0.   1.   6.   0.]\n"," [  4.   2. 246.   5.   3.   5.   7.   9.   6.   1.]\n"," [  2.   6.  18. 242.   1.  22.   0.   4.   4.   4.]\n"," [  3.   4.   0.   0. 290.   2.   3.   3.   3.  12.]\n"," [  6.   4.   1.  15.   0. 256.   1.   0.   6.   1.]\n"," [  8.   2.   4.   0.   6.  11. 258.   0.   3.   0.]\n"," [  1.   2.   5.   2.   2.   0.   0. 263.   3.  14.]\n"," [  4.   7.   6.   8.   1.  16.   3.   0. 270.   9.]\n"," [  1.   0.   0.   1.  11.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8844593930309861 Precision Macro 0.8847484028222905\n","Change of the performance: 0.0002422375568895685 0.0007995070404036575 \n","Change of cost:  0.002876527348380606\n","epoch 3\n","The cost at the end of this epoch is  0.07989756817776972\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   2.   3.   1.   4.   4.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   1.   6.   0.]\n"," [  4.   2. 245.   6.   3.   3.   7.   8.   9.   1.]\n"," [  2.   7.  20. 243.   1.  16.   0.   7.   2.   5.]\n"," [  2.   3.   0.   0. 294.   2.   5.   3.   2.   9.]\n"," [  7.   3.   1.  17.   0. 250.   3.   0.   8.   1.]\n"," [  7.   2.   3.   0.   4.  10. 261.   0.   5.   0.]\n"," [  1.   2.   5.   1.   2.   0.   0. 267.   3.  11.]\n"," [  5.   7.   7.   8.   1.  14.   4.   2. 267.   9.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   3. 240.]]\n","Accuracy Macro 0.8866142165210041 Precision Macro 0.8858639934771102\n","Change of the performance: 0.002154823490018054 0.001115590654819698 \n","Change of cost:  0.00012907726514842233\n","epoch 4\n","The cost at the end of this epoch is  0.07341656160226624\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 292.   3.   2.   0.   3.   0.   2.   6.   0.]\n"," [  4.   2. 247.   7.   3.   4.   7.   5.   8.   1.]\n"," [  2.   6.  18. 244.   1.  20.   0.   4.   3.   5.]\n"," [  3.   4.   0.   0. 296.   2.   2.   3.   2.   8.]\n"," [  8.   4.   1.  13.   0. 254.   2.   0.   7.   1.]\n"," [  8.   2.   4.   0.   7.  10. 257.   0.   4.   0.]\n"," [  1.   3.   5.   3.   2.   0.   0. 265.   2.  11.]\n"," [  5.   9.   7.   9.   1.  14.   3.   0. 265.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   3. 240.]]\n","Accuracy Macro 0.8863317851089307 Precision Macro 0.8862114391123411\n","Change of the performance: 0.00028243141207340283 0.0003474456352309252 \n","Change of cost:  0.0019155687478238231\n","epoch 5\n","The cost at the end of this epoch is  0.07411196667151762\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   3.   4.   2.   2.   0.]\n"," [  0. 295.   2.   2.   0.   3.   0.   0.   5.   1.]\n"," [  4.   2. 244.   7.   3.   3.   7.   9.   8.   1.]\n"," [  2.  10.  16. 245.   1.  19.   0.   3.   3.   4.]\n"," [  3.   4.   0.   0. 295.   2.   2.   3.   3.   8.]\n"," [  6.   4.   2.  15.   0. 253.   2.   0.   7.   1.]\n"," [  7.   2.   3.   0.   8.  10. 256.   0.   6.   0.]\n"," [  1.   4.   5.   3.   2.   0.   0. 263.   1.  13.]\n"," [  4.   9.   7.   8.   1.  13.   3.   0. 268.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8864643093166457 Precision Macro 0.8863834783762485\n","Change of the performance: 0.00013252420771492357 0.00017203926390740865 \n","Change of cost:  0.0015117089091086083\n","epoch 6\n","The cost at the end of this epoch is  0.07266829501891194\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 247.   6.   3.   3.   7.   8.   7.   1.]\n"," [  2.   8.  19. 241.   1.  20.   0.   4.   2.   6.]\n"," [  2.   4.   0.   0. 294.   2.   5.   3.   2.   8.]\n"," [  6.   5.   1.  15.   0. 252.   2.   0.   8.   1.]\n"," [  7.   2.   3.   0.   8.  11. 257.   0.   4.   0.]\n"," [  1.   4.   6.   1.   2.   0.   0. 263.   1.  14.]\n"," [  3.   9.   7.   8.   1.  17.   4.   0. 262.  13.]\n"," [  1.   0.   0.   0.  11.   1.   0.   8.   2. 242.]]\n","Accuracy Macro 0.8834955657996482 Precision Macro 0.8830917759824166\n","Change of the performance: 0.0029687435169974963 0.003291702393831919 \n","Change of cost:  0.0011183369303636725\n","epoch 7\n","The cost at the end of this epoch is  0.07078118216879595\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   2.   3.   1.   3.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 248.   6.   3.   3.   7.   7.   6.   2.]\n"," [  2.   7.  19. 243.   1.  20.   0.   4.   2.   5.]\n"," [  2.   4.   0.   0. 294.   2.   5.   3.   2.   8.]\n"," [  6.   4.   2.  16.   0. 251.   3.   0.   7.   1.]\n"," [  7.   2.   4.   0.   6.  10. 258.   0.   5.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 265.   1.  12.]\n"," [  3.   9.   7.   9.   1.  15.   4.   1. 264.  11.]\n"," [  1.   0.   0.   0.  11.   1.   0.   7.   2. 243.]]\n","Accuracy Macro 0.8871234623701365 Precision Macro 0.8864706146336365\n","Change of the performance: 0.0036278965704883426 0.0033788386512199065 \n","Change of cost:  0.0003033745861435039\n","epoch 8\n","The cost at the end of this epoch is  0.07000640792479144\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   2.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 248.   6.   3.   3.   7.   8.   6.   1.]\n"," [  2.   9.  19. 240.   1.  20.   0.   4.   3.   5.]\n"," [  2.   4.   0.   0. 296.   2.   3.   3.   2.   8.]\n"," [  7.   4.   1.  15.   0. 251.   3.   0.   8.   1.]\n"," [  7.   2.   4.   0.   6.  10. 258.   0.   5.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 264.   1.  13.]\n"," [  5.   8.   7.   8.   1.  14.   4.   0. 266.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   3. 239.]]\n","Accuracy Macro 0.885209282186359 Precision Macro 0.8848608554759473\n","Change of the performance: 0.0019141801837775363 0.001609759157689239 \n","Change of cost:  4.5730629733439776e-05\n","epoch 9\n","The cost at the end of this epoch is  0.06967637300680382\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   2.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 247.   5.   3.   3.   7.   8.   8.   1.]\n"," [  2.   8.  19. 239.   1.  20.   0.   4.   3.   7.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   2.   8.]\n"," [  7.   4.   1.  15.   0. 252.   2.   0.   8.   1.]\n"," [  7.   2.   4.   0.   6.  11. 258.   0.   4.   0.]\n"," [  1.   3.   6.   1.   2.   0.   0. 263.   2.  14.]\n"," [  3.   9.   7.   8.   1.  15.   4.   0. 266.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8836578164665747 Precision Macro 0.8832198759341396\n","Change of the performance: 0.0015514657197842618 0.0016409795418076412 \n","Change of cost:  0.0002227805060933119\n","epoch 10\n","The cost at the end of this epoch is  0.0691633925026764\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 246.   5.   3.   3.   7.   8.   9.   1.]\n"," [  2.   8.  18. 243.   1.  19.   0.   4.   2.   6.]\n"," [  2.   4.   0.   0. 295.   2.   3.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 251.   3.   0.   8.   1.]\n"," [  7.   2.   4.   0.   6.  10. 258.   0.   5.   0.]\n"," [  1.   4.   5.   0.   2.   0.   0. 266.   1.  13.]\n"," [  5.   9.   7.   8.   1.  14.   4.   0. 266.  10.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8862547267492309 Precision Macro 0.8859129827864975\n","Change of the performance: 0.002596910282656184 0.002693106852357907 \n","Change of cost:  0.00016273939974525975\n","epoch 11\n","The cost at the end of this epoch is  0.06931383239587564\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 246.   6.   3.   4.   7.   7.   8.   1.]\n"," [  3.   7.  18. 245.   1.  18.   0.   4.   2.   5.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   5.   9. 260.   0.   5.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  5.   8.   7.   9.   1.  15.   4.   0. 264.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.   7.   2. 241.]]\n","Accuracy Macro 0.8863300397095735 Precision Macro 0.8857311497915734\n","Change of the performance: 7.531296034257728e-05 0.00018183299492413596 \n","Change of cost:  6.867677931056415e-05\n","epoch 12\n","The cost at the end of this epoch is  0.06911101944481908\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 248.   6.   3.   3.   7.   8.   6.   1.]\n"," [  3.   9.  19. 242.   1.  18.   0.   4.   1.   6.]\n"," [  2.   3.   0.   0. 296.   2.   4.   3.   2.   8.]\n"," [  7.   4.   1.  15.   0. 251.   4.   0.   7.   1.]\n"," [  7.   2.   4.   0.   7.  10. 257.   0.   5.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 264.   1.  13.]\n"," [  5.  10.   7.   9.   1.  15.   4.   0. 262.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8846696730288665 Precision Macro 0.8841495330203791\n","Change of the performance: 0.001660366680707015 0.001581616771194283 \n","Change of cost:  0.0001501156041414653\n","epoch 13\n","The cost at the end of this epoch is  0.06858114150434708\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 246.   5.   3.   3.   7.   8.   8.   1.]\n"," [  2.   8.  18. 244.   1.  19.   0.   4.   1.   6.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   5.   9. 259.   0.   6.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  5.  10.   7.   9.   1.  14.   4.   0. 263.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8845941819964077 Precision Macro 0.8840060843554269\n","Change of the performance: 7.5491032458741e-05 0.00014344866495219488 \n","Change of cost:  9.873943336891067e-05\n","epoch 14\n","The cost at the end of this epoch is  0.0683481026632091\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  4.   2. 247.   5.   3.   3.   7.   8.   8.   1.]\n"," [  2.   8.  19. 242.   1.  19.   0.   4.   1.   7.]\n"," [  2.   3.   0.   0. 295.   2.   5.   3.   2.   8.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   6.   9. 258.   0.   6.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8843162309491707 Precision Macro 0.8836653574099543\n","Change of the performance: 0.0002779510472370461 0.0003407269454726025 \n","Change of cost:  7.701245362726206e-05\n","epoch 15\n","The cost at the end of this epoch is  0.06830788655687525\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 246.   5.   3.   3.   7.   8.   8.   1.]\n"," [  2.   8.  18. 243.   1.  19.   0.   4.   1.   7.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  6.   4.   2.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   6.  10. 258.   0.   5.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 265.   1.  13.]\n"," [  4.  10.   7.   9.   1.  16.   4.   0. 262.  11.]\n"," [  1.   0.   0.   0.  13.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8839555070177987 Precision Macro 0.8834116985483437\n","Change of the performance: 0.00036072393137198677 0.00025365886161066165 \n","Change of cost:  8.282706617970814e-06\n","epoch 16\n","The cost at the end of this epoch is  0.0684853572436376\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   6.   4.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   9.   1.]\n"," [  2.   8.  18. 244.   1.  19.   0.   4.   1.   6.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 252.   3.   0.   8.   1.]\n"," [  7.   2.   4.   0.   5.  11. 259.   0.   4.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   9.   1.  16.   4.   0. 262.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8836845767448753 Precision Macro 0.883262800303609\n","Change of the performance: 0.00027093027292335314 0.00014889824473462987 \n","Change of cost:  3.756855257774916e-06\n","epoch 17\n","The cost at the end of this epoch is  0.06811573691742719\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 246.   5.   3.   3.   7.   8.   8.   1.]\n"," [  2.   8.  19. 242.   1.  19.   0.   4.   1.   7.]\n"," [  2.   3.   0.   0. 295.   2.   5.   3.   2.   8.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   5.  10. 259.   0.   5.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   0.  13.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8839341159898071 Precision Macro 0.8833466107757578\n","Change of the performance: 0.0002495392449317624 8.381047214878201e-05 \n","Change of cost:  1.6785851306141963e-05\n","epoch 18\n","The cost at the end of this epoch is  0.06796654743054674\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   9.   1.]\n"," [  2.   8.  18. 243.   1.  19.   0.   5.   1.   6.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   6.  10. 258.   0.   5.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   1.  13.   1.   0.   9.   2. 238.]]\n","Accuracy Macro 0.8831971025268943 Precision Macro 0.8826877049850304\n","Change of the performance: 0.0007370134629127723 0.0006589057907274709 \n","Change of cost:  3.9647415992632995e-06\n","epoch 19\n","The cost at the end of this epoch is  0.06791613272795823\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 246.   5.   3.   3.   7.   8.   8.   1.]\n"," [  2.   8.  18. 244.   1.  19.   0.   4.   1.   6.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 251.   4.   0.   7.   1.]\n"," [  7.   2.   4.   0.   6.   9. 258.   0.   6.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   1.  13.   1.   0.   9.   2. 238.]]\n","Accuracy Macro 0.8842191853386238 Precision Macro 0.8837463057773098\n","Change of the performance: 0.0010220828117294412 0.001058600792279485 \n","Change of cost:  5.489118149543115e-06\n","epoch 20\n","The cost at the end of this epoch is  0.06787329769221488\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 246.   5.   3.   3.   7.   8.   8.   1.]\n"," [  2.   8.  19. 242.   1.  19.   0.   4.   1.   7.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  6.   4.   2.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   6.   9. 258.   0.   6.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   1.  13.   1.   0.   9.   2. 238.]]\n","Accuracy Macro 0.8832142917458163 Precision Macro 0.8826395322009535\n","Change of the performance: 0.001004893592807421 0.0011067735763563569 \n","Change of cost:  6.149929619544969e-06\n","epoch 21\n","The cost at the end of this epoch is  0.06784647963794663\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 246.   5.   3.   3.   7.   8.   8.   1.]\n"," [  2.   8.  18. 243.   1.  19.   0.   4.   1.   7.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   6.   9. 258.   0.   6.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   1.  13.   1.   0.   9.   2. 238.]]\n","Accuracy Macro 0.8835443247491167 Precision Macro 0.8830102099516637\n","Change of the performance: 0.00033003300330036733 0.00037067775071020215 \n","Change of cost:  4.483101351829277e-06\n","epoch 22\n","The cost at the end of this epoch is  0.06782207605895799\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   9.   1.]\n"," [  2.   8.  18. 243.   1.  19.   0.   4.   1.   7.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   6.  10. 258.   0.   5.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   1.  13.   1.   0.   9.   2. 238.]]\n","Accuracy Macro 0.8831971025268943 Precision Macro 0.8826959044622539\n","Change of the performance: 0.0003472222222223875 0.0003143054894098052 \n","Change of cost:  6.7146125793671185e-06\n","epoch 23\n","The cost at the end of this epoch is  0.06780573079080214\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   9.   1.]\n"," [  2.   8.  18. 244.   1.  19.   0.   4.   1.   6.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   5.   9. 259.   0.   6.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 265.   1.  13.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   1.  13.   1.   0.   9.   2. 238.]]\n","Accuracy Macro 0.8842120670370441 Precision Macro 0.8836682649876011\n","Change of the performance: 0.0010149645101498184 0.0009723605253472156 \n","Change of cost:  8.045067500656033e-07\n","epoch 24\n","The cost at the end of this epoch is  0.06778937831454795\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   9.   1.]\n"," [  2.   8.  18. 243.   1.  19.   0.   4.   1.   7.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   6.   9. 258.   0.   6.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   1.  13.   1.   0.   9.   2. 238.]]\n","Accuracy Macro 0.8831971025268943 Precision Macro 0.8826688265577133\n","Change of the performance: 0.0010149645101498184 0.0009994384298878112 \n","Change of cost:  1.981096702977081e-06\n","epoch 25\n","The cost at the end of this epoch is  0.06777667032526728\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   8.   9.   1.]\n"," [  2.   8.  18. 243.   1.  19.   0.   4.   1.   7.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   7.   1.]\n"," [  7.   2.   4.   0.   6.   9. 258.   0.   6.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   1.  13.   1.   0.   9.   2. 238.]]\n","Accuracy Macro 0.8831971025268943 Precision Macro 0.8826688265577133\n","Change of the performance: 0.0 0.0 \n","Change of cost:  8.555257696579721e-07\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_20_800x785_10x801\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [850  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (850, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 851)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 850)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.06998988004068717\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   3.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 247.   5.   3.   3.   7.   7.   7.   2.]\n"," [  4.   9.  19. 241.   1.  19.   0.   4.   0.   6.]\n"," [  2.   3.   0.   0. 298.   2.   5.   3.   2.   5.]\n"," [  8.   4.   1.  14.   0. 250.   5.   0.   6.   2.]\n"," [  7.   3.   5.   0.   6.   9. 256.   0.   6.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 266.   1.  11.]\n"," [  5.  10.   7.   9.   1.  15.   4.   0. 262.  11.]\n"," [  1.   0.   0.   0.  13.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8848666282976057 Precision Macro 0.8844706154237484\n","epoch 1\n","The cost at the end of this epoch is  0.06894969909873089\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   1.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 246.   5.   3.   3.   7.   8.   8.   1.]\n"," [  1.  10.  19. 242.   1.  20.   0.   4.   1.   5.]\n"," [  2.   3.   0.   0. 295.   2.   5.   3.   2.   8.]\n"," [  6.   4.   1.  15.   0. 253.   2.   0.   8.   1.]\n"," [  7.   3.   4.   0.   5.  11. 258.   0.   4.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 265.   1.  13.]\n"," [  4.  10.   7.   9.   1.  16.   4.   0. 262.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8834649882196599 Precision Macro 0.8831995311657987\n","epoch 2\n","The cost at the end of this epoch is  0.06869499210635764\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   1.   3.   1.   5.   3.   3.   2.   0.]\n"," [  0. 293.   3.   2.   0.   3.   0.   0.   6.   1.]\n"," [  5.   2. 245.   5.   3.   3.   7.   7.   9.   2.]\n"," [  2.   9.  18. 241.   1.  19.   0.   4.   1.   8.]\n"," [  2.   3.   0.   0. 295.   2.   5.   3.   3.   7.]\n"," [  7.   5.   1.  15.   0. 250.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   6.   9. 257.   0.   6.   0.]\n"," [  1.   4.   5.   0.   2.   0.   0. 263.   1.  16.]\n"," [  4.  10.   7.   8.   1.  13.   4.   0. 267.  10.]\n"," [  1.   0.   0.   0.  13.   1.   0.   7.   2. 241.]]\n","Accuracy Macro 0.8839042829775721 Precision Macro 0.8835359418162361\n","Change of the performance: 0.00043929475791215644 0.0003364106504373243 \n","Change of cost:  6.731701405669754e-05\n","epoch 3\n","The cost at the end of this epoch is  0.06844536785872338\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   6.   4.   3.   2.   0.]\n"," [  0. 294.   2.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 243.   6.   3.   4.   7.   7.   9.   1.]\n"," [  2.   8.  18. 243.   1.  19.   0.   3.   2.   7.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  5.   4.   2.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   5.  10. 258.   0.   4.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 264.   1.  14.]\n"," [  3.  11.   7.   9.   1.  13.   4.   0. 263.  13.]\n"," [  1.   0.   0.   1.  13.   1.   0.   8.   2. 239.]]\n","Accuracy Macro 0.8826061232574831 Precision Macro 0.8820923819845378\n","Change of the performance: 0.0012981597200889539 0.0014435598316983045 \n","Change of cost:  0.0002545656442663746\n","epoch 4\n","The cost at the end of this epoch is  0.06999682532202482\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   2.   3.   1.   9.   3.   2.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 246.   6.   3.   3.   7.   7.   7.   2.]\n"," [  2.   8.  21. 240.   1.  18.   0.   5.   1.   7.]\n"," [  2.   3.   0.   0. 292.   2.   7.   3.   3.   8.]\n"," [  5.   4.   2.  15.   0. 253.   2.   0.   8.   1.]\n"," [  7.   3.   5.   0.   5.  10. 257.   0.   5.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 265.   1.  13.]\n"," [  3.  10.   7.  10.   1.  12.   4.   0. 266.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8831368828514352 Precision Macro 0.8825398274200851\n","Change of the performance: 0.0005307595939521015 0.0004474454355473112 \n","Change of cost:  0.0001965815289656503\n","epoch 5\n","The cost at the end of this epoch is  0.07263896463228865\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   3.   3.   3.   2.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   1.   6.   1.]\n"," [  5.   2. 245.   6.   3.   4.   7.   6.   8.   2.]\n"," [  4.   8.  18. 241.   1.  20.   0.   6.   0.   5.]\n"," [  2.   3.   0.   0. 297.   1.   6.   3.   2.   6.]\n"," [  8.   3.   1.  14.   0. 249.   5.   0.   9.   1.]\n"," [  7.   3.   5.   0.   5.   8. 258.   0.   6.   0.]\n"," [  1.   4.   5.   2.   2.   0.   0. 264.   1.  13.]\n"," [  5.   9.   7.   8.   1.  17.   4.   0. 261.  12.]\n"," [  1.   0.   0.   1.  13.   1.   0.   6.   2. 241.]]\n","Accuracy Macro 0.8836362559481025 Precision Macro 0.8830198304076019\n","Change of the performance: 0.0004993730966672549 0.00048000298751682546 \n","Change of cost:  0.0046272643425679105\n","epoch 6\n","The cost at the end of this epoch is  0.06812102651405218\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   1.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 291.   2.   3.   0.   3.   0.   1.   7.   1.]\n"," [  5.   2. 244.   6.   3.   3.   7.   7.   9.   2.]\n"," [  2.   8.  18. 245.   1.  19.   0.   5.   1.   4.]\n"," [  2.   3.   0.   0. 295.   2.   4.   3.   3.   8.]\n"," [  5.   4.   2.  16.   0. 252.   2.   0.   8.   1.]\n"," [  7.   3.   5.   0.   6.  10. 255.   0.   6.   0.]\n"," [  1.   4.   4.   3.   2.   0.   0. 265.   1.  12.]\n"," [  4.  10.   7.  10.   1.  14.   3.   0. 265.  10.]\n"," [  1.   0.   0.   1.  13.   1.   0.   9.   2. 238.]]\n","Accuracy Macro 0.8819102762340787 Precision Macro 0.8817222963673255\n","Change of the performance: 0.0017259797140237731 0.001297534040276438 \n","Change of cost:  0.00034350532041067805\n","epoch 7\n","The cost at the end of this epoch is  0.06749169801961623\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   7.   3.   3.   2.   0.]\n"," [  0. 294.   2.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   6.   3.   3.   7.   7.   9.   2.]\n"," [  2.   8.  19. 243.   1.  18.   0.   4.   1.   7.]\n"," [  2.   3.   0.   0. 294.   2.   5.   3.   3.   8.]\n"," [  7.   4.   1.  15.   0. 250.   4.   0.   7.   2.]\n"," [  7.   3.   5.   0.   5.  10. 257.   0.   5.   0.]\n"," [  1.   4.   4.   0.   2.   0.   0. 266.   1.  14.]\n"," [  4.  10.   7.   8.   1.  15.   4.   0. 263.  12.]\n"," [  1.   0.   0.   0.  13.   1.   0.   7.   2. 241.]]\n","Accuracy Macro 0.8826987561836107 Precision Macro 0.88223915098744\n","Change of the performance: 0.0007884799495320172 0.0005168546201145263 \n","Change of cost:  7.295017570380091e-06\n","epoch 8\n","The cost at the end of this epoch is  0.0668787666487573\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   7.   3.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 243.   5.   3.   3.   7.   8.   8.   2.]\n"," [  2.   8.  20. 242.   1.  18.   0.   5.   1.   6.]\n"," [  2.   3.   0.   0. 294.   1.   7.   3.   2.   8.]\n"," [  7.   4.   1.  15.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   5.  10. 257.   0.   5.   0.]\n"," [  1.   4.   5.   1.   2.   0.   0. 265.   1.  13.]\n"," [  3.  10.   7.   8.   1.  16.   4.   0. 262.  13.]\n"," [  1.   0.   0.   0.  13.   1.   0.   7.   2. 241.]]\n","Accuracy Macro 0.8820849899353309 Precision Macro 0.881476306892367\n","Change of the performance: 0.0006137662482798012 0.0007628440950729898 \n","Change of cost:  7.785365594227545e-05\n","epoch 9\n","The cost at the end of this epoch is  0.06684293402696606\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   1.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 294.   2.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 241.   5.   3.   3.   7.  10.   9.   1.]\n"," [  2.   8.  19. 243.   1.  19.   0.   5.   1.   5.]\n"," [  2.   3.   0.   0. 295.   2.   5.   3.   3.   7.]\n"," [  6.   4.   1.  15.   0. 252.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   5.   9. 258.   0.   5.   0.]\n"," [  1.   4.   4.   1.   2.   0.   0. 266.   1.  13.]\n"," [  3.  10.   7.   9.   1.  16.   4.   0. 261.  13.]\n"," [  1.   0.   0.   0.  13.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8816952231378675 Precision Macro 0.8811596783275848\n","Change of the performance: 0.0003897667974633867 0.00031662856478220647 \n","Change of cost:  0.00010197667498518248\n","epoch 10\n","The cost at the end of this epoch is  0.06649528265187088\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   1.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   6.   3.   3.   7.   7.   9.   2.]\n"," [  2.   7.  20. 242.   1.  18.   0.   5.   1.   7.]\n"," [  2.   3.   0.   0. 293.   1.   7.   3.   3.   8.]\n"," [  6.   4.   1.  15.   0. 252.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   6.  10. 256.   0.   5.   0.]\n"," [  1.   5.   4.   1.   2.   0.   0. 266.   1.  12.]\n"," [  4.  10.   7.   8.   1.  16.   4.   0. 263.  11.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8813869133752531 Precision Macro 0.8808001973829249\n","Change of the performance: 0.00030830976261442267 0.00035948094465987346 \n","Change of cost:  0.00013158106720721763\n","epoch 11\n","The cost at the end of this epoch is  0.06644885577043956\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   1.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   6.   3.   3.   7.   7.   9.   2.]\n"," [  2.   8.  19. 244.   1.  18.   0.   5.   1.   5.]\n"," [  2.   3.   0.   0. 295.   2.   5.   3.   3.   7.]\n"," [  6.   4.   1.  15.   0. 252.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   5.   9. 258.   0.   5.   0.]\n"," [  1.   4.   4.   2.   2.   0.   0. 264.   1.  14.]\n"," [  3.  10.   7.   9.   1.  16.   4.   0. 261.  13.]\n"," [  1.   0.   0.   1.  13.   1.   0.   7.   2. 240.]]\n","Accuracy Macro 0.8820546954312366 Precision Macro 0.8814730199026553\n","Change of the performance: 0.0006677820559835013 0.0006728225197303317 \n","Change of cost:  7.68862786063168e-05\n","epoch 12\n","The cost at the end of this epoch is  0.06620819896980239\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   3.   1.   6.   3.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   5.   3.   3.   7.   8.   9.   2.]\n"," [  2.   7.  20. 241.   1.  19.   0.   6.   1.   6.]\n"," [  2.   3.   0.   0. 295.   2.   5.   3.   3.   7.]\n"," [  6.   4.   2.  15.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   5.   9. 258.   0.   5.   0.]\n"," [  1.   4.   4.   1.   2.   0.   0. 265.   1.  14.]\n"," [  3.  10.   7.   9.   1.  16.   4.   0. 261.  13.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8816911654061632 Precision Macro 0.881016042053741\n","Change of the performance: 0.0003635300250733886 0.00045697784891429727 \n","Change of cost:  8.339844468741031e-05\n","epoch 13\n","The cost at the end of this epoch is  0.06604857574112358\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   7.   3.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   6.   3.   3.   7.   7.   9.   2.]\n"," [  2.   7.  19. 243.   1.  18.   0.   6.   1.   6.]\n"," [  2.   3.   0.   0. 295.   2.   5.   3.   3.   7.]\n"," [  7.   4.   1.  15.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   5.  10. 257.   0.   5.   0.]\n"," [  1.   4.   4.   1.   2.   0.   0. 266.   1.  13.]\n"," [  4.  10.   7.   9.   1.  16.   4.   0. 261.  12.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.882036766003959 Precision Macro 0.8814860054265674\n","Change of the performance: 0.0003456005977957588 0.00046996337282645406 \n","Change of cost:  1.887046210832799e-06\n","epoch 14\n","The cost at the end of this epoch is  0.06602896182644498\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   7.   3.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   6.   3.   3.   7.   7.   9.   2.]\n"," [  2.   7.  19. 243.   1.  18.   0.   6.   1.   6.]\n"," [  2.   3.   0.   0. 295.   2.   5.   3.   3.   7.]\n"," [  7.   4.   1.  15.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   6.   9. 257.   0.   5.   0.]\n"," [  1.   4.   4.   2.   2.   0.   0. 264.   1.  14.]\n"," [  4.  10.   7.   8.   1.  16.   4.   0. 262.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8820378349629843 Precision Macro 0.8814781506625637\n","Change of the performance: 1.0689590252965786e-06 7.85476400366747e-06 \n","Change of cost:  4.462393474634341e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_21_850x785_10x851\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [900  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (900, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 901)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 900)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.06735957510550719\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   1.   3.   1.   8.   4.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 241.   6.   3.   4.   7.   8.   9.   1.]\n"," [  2.   7.  19. 241.   1.  21.   0.   6.   1.   5.]\n"," [  2.   3.   0.   0. 293.   2.   7.   4.   2.   7.]\n"," [  6.   4.   1.  15.   0. 253.   4.   0.   6.   1.]\n"," [  7.   3.   5.   0.   4.   9. 259.   0.   5.   0.]\n"," [  1.   5.   4.   2.   2.   0.   0. 265.   1.  12.]\n"," [  4.  10.   7.   9.   1.  17.   4.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.  10.   2. 239.]]\n","Accuracy Macro 0.8801216674174899 Precision Macro 0.8796179806558474\n","epoch 1\n","The cost at the end of this epoch is  0.1110722029824728\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   3.   1.   5.   3.   3.   2.   1.]\n"," [  0. 289.   2.   3.   0.   3.   0.   2.   8.   1.]\n"," [  5.   8. 226.   6.   2.   4.   7.  16.  12.   2.]\n"," [  3.  12.  13. 229.   1.  17.   1.  14.   6.   7.]\n"," [  2.   3.   0.   0. 299.   2.   2.   3.   2.   7.]\n"," [  6.   6.   2.  13.   1. 242.   4.   1.   8.   7.]\n"," [  7.   2.   3.   0.   8.   8. 256.   0.   8.   0.]\n"," [  1.   2.   2.   0.   3.   0.   0. 272.   1.  11.]\n"," [  2.  13.   6.   4.   1.  13.   3.   2. 268.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.  10.   2. 239.]]\n","Accuracy Macro 0.8725185283401583 Precision Macro 0.87334802149981\n","epoch 2\n","The cost at the end of this epoch is  0.06955082610290816\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   2.   3.   1.   7.   4.   2.   2.   0.]\n"," [  0. 294.   2.   3.   0.   3.   0.   0.   5.   1.]\n"," [  5.   5. 239.   6.   3.   4.   7.   7.  10.   2.]\n"," [  1.   7.  18. 242.   1.  22.   0.   5.   2.   5.]\n"," [  2.   3.   0.   0. 297.   1.   6.   3.   2.   6.]\n"," [  6.   4.   1.  14.   1. 254.   4.   0.   5.   1.]\n"," [  7.   2.   5.   0.   5.  11. 257.   0.   5.   0.]\n"," [  1.   3.   4.   2.   2.   0.   0. 265.   1.  14.]\n"," [  2.  11.   7.   8.   1.  17.   3.   0. 260.  15.]\n"," [  1.   0.   0.   0.  13.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8813062927891837 Precision Macro 0.8810730141716236\n","Change of the performance: 0.008787764449025404 0.007724992671813702 \n","Change of cost:  0.000754616827759888\n","epoch 3\n","The cost at the end of this epoch is  0.06819411211371088\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   3.   3.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   7.   3.   3.   7.   6.   9.   2.]\n"," [  3.   7.  19. 246.   1.  16.   0.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   3.   7.]\n"," [  6.   3.   2.  16.   1. 246.   5.   0.   9.   2.]\n"," [  7.   2.   5.   0.   5.   9. 258.   0.   6.   0.]\n"," [  1.   2.   4.   5.   2.   0.   0. 264.   1.  13.]\n"," [  4.  10.   8.  10.   1.  12.   3.   0. 265.  11.]\n"," [  1.   0.   0.   1.  13.   1.   0.   9.   1. 239.]]\n","Accuracy Macro 0.8830772977840946 Precision Macro 0.8823407029048\n","Change of the performance: 0.0017710049949108964 0.0012676887331763975 \n","Change of cost:  0.0012326232298294354\n","epoch 4\n","The cost at the end of this epoch is  0.06657596920896741\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   1.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 242.   7.   3.   3.   7.   7.   9.   2.]\n"," [  2.   7.  20. 244.   1.  18.   0.   6.   1.   4.]\n"," [  2.   3.   0.   0. 294.   2.   6.   3.   2.   8.]\n"," [  6.   4.   1.  15.   0. 252.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   5.   3.   2.   0.   0. 265.   1.  13.]\n"," [  4.  10.   7.   9.   1.  15.   4.   0. 263.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.   7.   2. 242.]]\n","Accuracy Macro 0.8834566621164106 Precision Macro 0.8827034143375828\n","Change of the performance: 0.0003793643323160012 0.00036271143278276963 \n","Change of cost:  6.167367467391216e-06\n","epoch 5\n","The cost at the end of this epoch is  0.06690841756694522\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   6.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   7.   3.   3.   7.   6.   9.   2.]\n"," [  2.   7.  20. 245.   1.  18.   0.   6.   1.   3.]\n"," [  2.   3.   1.   0. 293.   2.   6.   3.   3.   7.]\n"," [  5.   4.   2.  16.   1. 250.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 265.   1.  13.]\n"," [  4.  10.   8.  10.   1.  11.   4.   0. 265.  11.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   2. 238.]]\n","Accuracy Macro 0.8822068553444552 Precision Macro 0.881475920485323\n","Change of the performance: 0.0012498067719554085 0.0012274938522598422 \n","Change of cost:  4.461059525733002e-05\n","epoch 6\n","The cost at the end of this epoch is  0.06857931028799265\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   3.   3.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 241.   6.   3.   3.   7.   8.   9.   2.]\n"," [  4.   7.  19. 246.   1.  16.   0.   6.   0.   4.]\n"," [  2.   3.   0.   0. 295.   1.   7.   3.   2.   7.]\n"," [  7.   3.   2.  15.   1. 246.   5.   0.   9.   2.]\n"," [  7.   2.   5.   0.   5.   8. 259.   0.   6.   0.]\n"," [  1.   2.   5.   2.   2.   0.   0. 266.   1.  13.]\n"," [  5.  10.   8.   9.   1.  12.   4.   0. 263.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.883830047362095 Precision Macro 0.8829280795825591\n","Change of the performance: 0.0016231920176398296 0.001452159097236172 \n","Change of cost:  0.0018360889730271307\n","epoch 7\n","The cost at the end of this epoch is  0.06621717861627702\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   6.   3.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  6.   4. 240.   6.   3.   4.   7.   6.  10.   2.]\n"," [  2.   7.  19. 244.   1.  18.   0.   5.   1.   6.]\n"," [  2.   3.   0.   0. 296.   2.   5.   3.   2.   7.]\n"," [  7.   4.   1.  15.   0. 251.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   5.   9. 258.   0.   6.   0.]\n"," [  1.   2.   5.   1.   2.   0.   0. 266.   1.  14.]\n"," [  4.  10.   7.   9.   1.  15.   3.   0. 264.  11.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8838821770597756 Precision Macro 0.8833998352323468\n","Change of the performance: 5.2129697680536324e-05 0.00047175564978763074 \n","Change of cost:  4.112395159967808e-05\n","epoch 8\n","The cost at the end of this epoch is  0.06592519497564957\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   5.   3.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 239.   6.   3.   4.   7.   8.  10.   2.]\n"," [  3.   7.  19. 243.   1.  17.   0.   6.   1.   6.]\n"," [  2.   3.   0.   0. 295.   1.   7.   3.   3.   6.]\n"," [  6.   4.   2.  16.   0. 248.   5.   0.   7.   2.]\n"," [  7.   2.   5.   0.   5.   9. 259.   0.   5.   0.]\n"," [  1.   2.   4.   1.   2.   0.   0. 268.   1.  13.]\n"," [  4.  10.   8.   8.   1.  15.   4.   0. 261.  13.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   2. 241.]]\n","Accuracy Macro 0.8826512343093513 Precision Macro 0.8816604496002244\n","Change of the performance: 0.0012309427504242354 0.0017393856321223922 \n","Change of cost:  0.0001003612481116356\n","epoch 9\n","The cost at the end of this epoch is  0.06534966388253907\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   1.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   6.   3.   3.   7.   7.   9.   2.]\n"," [  2.   7.  20. 243.   1.  18.   0.   6.   1.   5.]\n"," [  2.   3.   0.   0. 295.   1.   7.   3.   2.   7.]\n"," [  6.   4.   1.  15.   1. 251.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   5.   9. 259.   0.   5.   0.]\n"," [  1.   2.   4.   2.   2.   0.   0. 265.   1.  15.]\n"," [  3.  10.   8.   8.   1.  16.   3.   0. 263.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.883059408789762 Precision Macro 0.8822761089745974\n","Change of the performance: 0.0004081744804106391 0.0006156593743730232 \n","Change of cost:  7.248594393516328e-05\n","epoch 10\n","The cost at the end of this epoch is  0.06517893081299626\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   1.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 241.   7.   3.   3.   7.   7.   9.   2.]\n"," [  2.   7.  20. 241.   1.  20.   0.   6.   1.   5.]\n"," [  2.   3.   0.   0. 296.   1.   7.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 252.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 267.   1.  13.]\n"," [  4.  10.   8.   9.   1.  17.   3.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8817486294840787 Precision Macro 0.8810134781541816\n","Change of the performance: 0.0013107793056832406 0.0012626308204157777 \n","Change of cost:  1.577147195559736e-05\n","epoch 11\n","The cost at the end of this epoch is  0.06500874144330947\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   7.   3.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   6.   3.   3.   7.   7.   9.   2.]\n"," [  2.   7.  20. 242.   1.  19.   0.   6.   1.   5.]\n"," [  2.   3.   0.   0. 296.   1.   7.   4.   2.   5.]\n"," [  7.   4.   1.  15.   0. 251.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   4.   1.   2.   0.   0. 267.   1.  14.]\n"," [  4.  10.   8.   9.   1.  16.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8827041645075079 Precision Macro 0.8819965692214146\n","Change of the performance: 0.0009555350234291549 0.000983091067232933 \n","Change of cost:  1.8230862976156836e-05\n","epoch 12\n","The cost at the end of this epoch is  0.06491226458424174\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   7.   3.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   6.   3.   3.   7.   7.   9.   2.]\n"," [  2.   7.  19. 244.   1.  18.   0.   6.   1.   5.]\n"," [  2.   3.   0.   0. 294.   2.   6.   4.   3.   6.]\n"," [  6.   4.   2.  16.   0. 250.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   5.   9. 258.   0.   6.   0.]\n"," [  1.   2.   4.   2.   2.   0.   0. 266.   1.  14.]\n"," [  4.  10.   8.   9.   1.  16.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8827437610738482 Precision Macro 0.8819904669794771\n","Change of the performance: 3.959656634033859e-05 6.10224193742237e-06 \n","Change of cost:  5.52330707985077e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_21_900x785_10x901\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [950  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (950, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 951)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 950)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.06903372301040135\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   2.   4.   0.   2.   0.   0.   6.   1.]\n"," [  5.   6. 236.   8.   3.   3.   7.   9.   9.   2.]\n"," [  2.   7.  17. 248.   1.  15.   1.   6.   1.   5.]\n"," [  2.   3.   0.   0. 293.   1.   8.   4.   3.   6.]\n"," [  7.   5.   1.  18.   1. 245.   5.   0.   7.   1.]\n"," [  7.   3.   5.   0.   5.  11. 257.   0.   4.   0.]\n"," [  1.   2.   3.   4.   2.   0.   0. 266.   1.  13.]\n"," [  3.  16.   8.  10.   1.  14.   4.   1. 253.  14.]\n"," [  1.   0.   0.   0.  11.   1.   0.  10.   1. 241.]]\n","Accuracy Macro 0.8768178548579829 Precision Macro 0.8759200673831671\n","epoch 1\n","The cost at the end of this epoch is  0.06735945433037963\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 241.   6.   2.   3.   7.   9.   9.   2.]\n"," [  2.   6.  18. 247.   1.  17.   0.   6.   1.   5.]\n"," [  2.   3.   1.   0. 293.   1.   7.   4.   3.   6.]\n"," [  5.   4.   2.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   5.  10. 257.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 267.   1.  13.]\n"," [  4.  10.   8.  10.   1.  13.   4.   0. 263.  11.]\n"," [  1.   0.   0.   1.  11.   1.   0.  10.   2. 239.]]\n","Accuracy Macro 0.8823279262749336 Precision Macro 0.8814959950090945\n","epoch 2\n","The cost at the end of this epoch is  0.06839945111809116\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   7.   4.   2.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   5. 239.   6.   2.   4.   7.   8.  10.   2.]\n"," [  1.   7.  19. 242.   1.  20.   0.   4.   1.   8.]\n"," [  2.   3.   0.   0. 294.   1.   8.   3.   2.   7.]\n"," [  7.   4.   1.  14.   0. 253.   4.   0.   6.   1.]\n"," [  7.   2.   5.   0.   6.  10. 257.   0.   5.   0.]\n"," [  1.   3.   2.   5.   2.   0.   0. 264.   1.  14.]\n"," [  3.  11.   8.   8.   1.  17.   4.   0. 258.  14.]\n"," [  1.   0.   0.   0.  11.   1.   0.   6.   2. 244.]]\n","Accuracy Macro 0.8812552634446998 Precision Macro 0.8806023603224405\n","Change of the performance: 0.0010726628302337726 0.0008936346866539324 \n","Change of cost:  0.003761947008625255\n","epoch 3\n","The cost at the end of this epoch is  0.2052215547983747\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   1.   3.   1.   3.   3.   3.   3.   0.]\n"," [  0. 282.   9.   4.   0.   2.   0.   0.  10.   1.]\n"," [  5.   1. 248.   7.   1.   1.   8.   4.  11.   2.]\n"," [  3.   5.  27. 245.   1.  10.   0.   6.   4.   2.]\n"," [  1.   3.   6.   1. 285.   0.   4.  11.   4.   5.]\n"," [  8.   4.   2.  20.   0. 226.   5.   0.  22.   3.]\n"," [  6.   2.   6.   0.   5.   3. 258.   0.  12.   0.]\n"," [  1.   2.   3.   2.   1.   0.   0. 268.   3.  12.]\n"," [  3.   6.  11.   5.   0.   1.   3.   0. 288.   7.]\n"," [  1.   0.   0.   2.  10.   0.   0.  20.   2. 230.]]\n","Accuracy Macro 0.8759935890316539 Precision Macro 0.8792980934212726\n","Change of the performance: 0.005261674413045925 0.0013042669011679164 \n","Change of cost:  0.08054077696102604\n","epoch 4\n","The cost at the end of this epoch is  0.08612795280784956\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   1.   3.   1.   3.   3.   3.   2.   0.]\n"," [  0. 294.   3.   3.   0.   2.   0.   0.   5.   1.]\n"," [  4.   4. 239.   5.   3.   4.   7.  11.  10.   1.]\n"," [  2.   7.  18. 253.   1.  10.   0.   8.   2.   2.]\n"," [  1.   3.   0.   0. 296.   3.   6.   3.   1.   7.]\n"," [  4.   4.   1.  18.   2. 249.   2.   0.   7.   3.]\n"," [  9.   3.   5.   0.   4.   9. 259.   0.   3.   0.]\n"," [  1.   2.   1.   2.   2.   0.   0. 271.   2.  11.]\n"," [  4.  14.   8.  12.   1.  12.   4.   1. 254.  14.]\n"," [  1.   0.   0.   0.  12.   1.   0.  12.   2. 237.]]\n","Accuracy Macro 0.8846055021328914 Precision Macro 0.8838075934005272\n","Change of the performance: 0.008611913101237434 0.004509499979254539 \n","Change of cost:  0.005504914824494445\n","epoch 5\n","The cost at the end of this epoch is  0.07659197577030144\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 291.   6.   1.   0.   2.   0.   0.   7.   1.]\n"," [  6.   3. 243.   5.   2.   3.   8.   6.  10.   2.]\n"," [  2.   7.  22. 236.   1.  20.   1.   6.   2.   6.]\n"," [  1.   3.   2.   0. 292.   3.   5.   3.   2.   9.]\n"," [  6.   3.   1.  14.   0. 252.   2.   0.  11.   1.]\n"," [  7.   3.   6.   0.   3.   8. 256.   0.   9.   0.]\n"," [  1.   2.   3.   0.   2.   0.   0. 271.   3.  10.]\n"," [  2.   9.  10.   8.   1.   7.   4.   0. 272.  11.]\n"," [  1.   0.   0.   0.  10.   1.   0.   8.   2. 243.]]\n","Accuracy Macro 0.8850431997625321 Precision Macro 0.8845648356702103\n","Change of the performance: 0.0004376976296407431 0.0007572422696831005 \n","Change of cost:  0.003433558106152104\n","epoch 6\n","The cost at the end of this epoch is  0.06893375372029156\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  4.   2. 244.   7.   3.   4.   7.   5.  10.   2.]\n"," [  1.   7.  19. 245.   1.  19.   0.   5.   2.   4.]\n"," [  1.   3.   1.   0. 294.   3.   5.   3.   2.   8.]\n"," [  6.   4.   1.  15.   0. 252.   3.   0.   8.   1.]\n"," [  6.   2.   5.   0.   4.  11. 257.   0.   7.   0.]\n"," [  1.   2.   3.   2.   2.   0.   0. 265.   3.  14.]\n"," [  3.  10.   8.   9.   1.   8.   4.   0. 271.  10.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   3. 240.]]\n","Accuracy Macro 0.8864820234496777 Precision Macro 0.8860553445222991\n","Change of the performance: 0.0014388236871456517 0.00149050885208879 \n","Change of cost:  0.0010217539178504625\n","epoch 7\n","The cost at the end of this epoch is  0.06736410231120701\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   6.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   6.   3.   4.   7.   8.   8.   1.]\n"," [  2.   7.  19. 239.   1.  21.   1.   6.   2.   5.]\n"," [  2.   3.   0.   0. 296.   2.   5.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 252.   3.   0.   8.   1.]\n"," [  6.   3.   5.   0.   5.  11. 257.   0.   5.   0.]\n"," [  1.   3.   5.   0.   2.   0.   0. 265.   2.  14.]\n"," [  3.  11.   8.   8.   1.  15.   4.   0. 261.  13.]\n"," [  1.   0.   0.   0.  13.   1.   0.   7.   2. 241.]]\n","Accuracy Macro 0.8814088543141061 Precision Macro 0.8808777674299145\n","Change of the performance: 0.0050731691355716535 0.005177577092384533 \n","Change of cost:  0.0001360894964577697\n","epoch 8\n","The cost at the end of this epoch is  0.06718928596728051\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   3.   1.   5.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 241.   6.   3.   4.   7.   8.  10.   1.]\n"," [  3.   7.  20. 242.   1.  16.   1.   6.   2.   5.]\n"," [  2.   3.   1.   0. 295.   2.   5.   3.   2.   7.]\n"," [  5.   4.   2.  16.   0. 250.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  11. 259.   0.   4.   0.]\n"," [  1.   2.   5.   3.   2.   0.   0. 263.   2.  14.]\n"," [  3.  11.   8.  10.   1.  12.   4.   0. 262.  13.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8812953248229185 Precision Macro 0.8803398717364181\n","Change of the performance: 0.0001135294911875917 0.0005378956934963819 \n","Change of cost:  0.000537769387545281\n","epoch 9\n","The cost at the end of this epoch is  0.06610474316434804\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 243.   6.   3.   4.   7.   7.   9.   2.]\n"," [  3.   7.  18. 242.   1.  19.   0.   6.   2.   5.]\n"," [  2.   3.   1.   0. 296.   2.   4.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  6.   2.   5.   0.   5.  11. 258.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 265.   2.  14.]\n"," [  3.  11.   8.  10.   1.  13.   3.   0. 263.  12.]\n"," [  1.   0.   0.   1.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8832982045823032 Precision Macro 0.882626572427682\n","Change of the performance: 0.0020028797593847347 0.00228670069126391 \n","Change of cost:  0.00010712500662614366\n","epoch 10\n","The cost at the end of this epoch is  0.06681902183915657\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 242.   7.   3.   4.   7.   6.  10.   2.]\n"," [  2.   7.  18. 243.   1.  21.   0.   5.   2.   4.]\n"," [  2.   3.   1.   0. 295.   2.   5.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 252.   3.   0.   8.   1.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 265.   2.  14.]\n"," [  3.  10.   8.   9.   1.  15.   3.   0. 263.  12.]\n"," [  1.   0.   0.   1.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8823070536414122 Precision Macro 0.8818693667273141\n","Change of the performance: 0.0009911509408910835 0.0007572057003679689 \n","Change of cost:  0.0002550579651005441\n","epoch 11\n","The cost at the end of this epoch is  0.06599436920625124\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 243.   6.   3.   4.   7.   8.   9.   1.]\n"," [  2.   7.  18. 242.   1.  21.   0.   6.   2.   4.]\n"," [  2.   3.   1.   0. 296.   2.   4.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 252.   3.   0.   8.   1.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   2.   2.   0.   0. 265.   2.  14.]\n"," [  4.  10.   8.   9.   1.  15.   3.   0. 261.  13.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8826832824644683 Precision Macro 0.8821270614689902\n","Change of the performance: 0.0003762288230561017 0.0002576947416761399 \n","Change of cost:  8.357157924415715e-05\n","epoch 12\n","The cost at the end of this epoch is  0.06526020821727288\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   5.   3.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 242.   6.   2.   4.   7.   8.   9.   2.]\n"," [  3.   7.  18. 242.   1.  20.   0.   6.   2.   4.]\n"," [  2.   3.   1.   0. 295.   2.   5.   3.   2.   7.]\n"," [  7.   4.   1.  15.   0. 250.   4.   0.   7.   2.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   2.   3.   1.   2.   0.   0. 268.   1.  14.]\n"," [  4.  10.   8.   9.   1.  15.   3.   0. 262.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8829844097142198 Precision Macro 0.8823732771540603\n","Change of the performance: 0.0003011272497515094 0.00024621568507010583 \n","Change of cost:  4.8461384148698605e-05\n","epoch 13\n","The cost at the end of this epoch is  0.06668155822559335\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   3.   3.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 242.   6.   3.   4.   7.   7.  10.   2.]\n"," [  4.   7.  18. 243.   1.  19.   0.   6.   1.   4.]\n"," [  2.   3.   0.   0. 295.   2.   6.   3.   2.   7.]\n"," [  7.   4.   1.  15.   0. 249.   5.   0.   7.   2.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   3.   4.   2.   0.   0. 265.   1.  14.]\n"," [  5.  10.   8.  10.   1.  12.   3.   0. 263.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8835367218261876 Precision Macro 0.8827889152419376\n","Change of the performance: 0.0005523121119678231 0.000415638087877257 \n","Change of cost:  0.0002374166136800554\n","epoch 14\n","The cost at the end of this epoch is  0.06556002118084239\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  6.   2. 243.   6.   3.   4.   7.   6.   9.   2.]\n"," [  2.   7.  19. 241.   1.  21.   0.   7.   1.   4.]\n"," [  2.   3.   1.   0. 294.   2.   6.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 252.   3.   0.   8.   1.]\n"," [  6.   2.   6.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   3.   4.   2.   0.   0. 265.   1.  14.]\n"," [  3.  10.   8.   9.   1.  15.   3.   0. 263.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8820590683475997 Precision Macro 0.8814595842431239\n","Change of the performance: 0.0014776534785878592 0.0013293309988137159 \n","Change of cost:  0.0005807600161069348\n","epoch 15\n","The cost at the end of this epoch is  0.06484439944180384\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 242.   6.   3.   4.   7.   7.   9.   2.]\n"," [  3.   7.  19. 241.   1.  20.   0.   7.   1.   4.]\n"," [  2.   3.   1.   0. 294.   2.   6.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 266.   1.  14.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8817211311595881 Precision Macro 0.8809821640014329\n","Change of the performance: 0.00033793718801167216 0.0004774202416909512 \n","Change of cost:  4.9493864034688695e-06\n","epoch 16\n","The cost at the end of this epoch is  0.06477409797148699\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 242.   6.   3.   4.   7.   7.   9.   2.]\n"," [  2.   7.  19. 241.   1.  21.   0.   7.   1.   4.]\n"," [  2.   3.   1.   0. 294.   2.   6.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   4.   3.   2.   0.   0. 265.   1.  14.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.881092200341978 Precision Macro 0.8804154154177033\n","Change of the performance: 0.0006289308176100628 0.000566748583729626 \n","Change of cost:  2.7460239052215507e-05\n","epoch 17\n","The cost at the end of this epoch is  0.06452271716537503\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 243.   6.   2.   4.   7.   8.   9.   2.]\n"," [  3.   7.  18. 242.   1.  20.   0.   7.   1.   4.]\n"," [  2.   3.   1.   0. 294.   2.   6.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 266.   1.  14.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8823983863851105 Precision Macro 0.8816497885356812\n","Change of the performance: 0.0013061860431324845 0.001234373117977916 \n","Change of cost:  0.00011093157852523627\n","epoch 18\n","The cost at the end of this epoch is  0.06450800494115592\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 242.   6.   3.   4.   7.   7.  10.   2.]\n"," [  3.   7.  19. 241.   1.  20.   0.   7.   1.   4.]\n"," [  2.   3.   1.   0. 294.   2.   6.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   3.   4.   2.   0.   0. 265.   1.  14.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8813786654061634 Precision Macro 0.8806277527753112\n","Change of the performance: 0.0010197209789470918 0.001022035760369966 \n","Change of cost:  2.8478117590866048e-05\n","epoch 19\n","The cost at the end of this epoch is  0.06436824117311733\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 241.   6.   2.   4.   7.   8.  10.   2.]\n"," [  3.   7.  19. 241.   1.  20.   0.   7.   1.   4.]\n"," [  2.   3.   1.   0. 294.   2.   6.   3.   2.   7.]\n"," [  7.   4.   1.  15.   0. 251.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 266.   1.  14.]\n"," [  4.  10.   8.   9.   1.  15.   3.   0. 262.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8816825509126744 Precision Macro 0.8809595802789817\n","Change of the performance: 0.00030388550651105906 0.00033182750367044545 \n","Change of cost:  3.6199986842566645e-06\n","epoch 20\n","The cost at the end of this epoch is  0.06428549743402615\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 242.   6.   3.   4.   7.   7.  10.   2.]\n"," [  3.   7.  19. 241.   1.  20.   0.   7.   1.   4.]\n"," [  2.   3.   1.   0. 294.   2.   6.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 266.   1.  14.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8817211311595881 Precision Macro 0.8809674938952347\n","Change of the performance: 3.858024691361095e-05 7.913616252963607e-06 \n","Change of cost:  3.9843921694482365e-06\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_22_950x785_10x951\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [1000   10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (1000, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 1001)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 1000)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.06616446277941136\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   5.   4.   2.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 239.   7.   2.   4.   7.   8.  10.   2.]\n"," [  3.   7.  18. 242.   1.  20.   0.   5.   1.   6.]\n"," [  2.   3.   1.   0. 295.   2.   5.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   4.   0.   5.  11. 259.   0.   4.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 266.   1.  14.]\n"," [  4.  10.   7.   9.   1.  16.   4.   0. 260.  13.]\n"," [  1.   0.   0.   0.  11.   1.   0.   9.   1. 242.]]\n","Accuracy Macro 0.8824250036642747 Precision Macro 0.8817227157871763\n","epoch 1\n","The cost at the end of this epoch is  0.06581236153711152\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 247.   6.   2.   4.   7.   6.   8.   1.]\n"," [  2.   6.  20. 243.   1.  19.   0.   7.   1.   4.]\n"," [  1.   3.   1.   0. 297.   2.   5.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 252.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  11. 256.   0.   6.   0.]\n"," [  1.   2.   4.   1.   2.   0.   0. 268.   1.  13.]\n"," [  3.  11.   8.   9.   1.  14.   3.   0. 262.  13.]\n"," [  1.   0.   0.   1.  12.   1.   0.  12.   2. 236.]]\n","Accuracy Macro 0.8838843784677461 Precision Macro 0.8833332983525727\n","epoch 2\n","The cost at the end of this epoch is  0.06577330421499741\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   4.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 244.   7.   2.   3.   7.   6.   8.   2.]\n"," [  3.   7.  19. 245.   1.  16.   1.   6.   1.   4.]\n"," [  1.   3.   0.   0. 298.   2.   6.   4.   2.   4.]\n"," [  6.   5.   2.  16.   1. 247.   4.   0.   7.   2.]\n"," [  6.   3.   5.   0.   5.  10. 258.   0.   5.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 266.   1.  12.]\n"," [  3.  12.   8.  10.   1.  11.   3.   0. 263.  13.]\n"," [  1.   0.   0.   1.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8837205365689356 Precision Macro 0.8829667592192347\n","Change of the performance: 0.00016384189881057942 0.00036653913333795085 \n","Change of cost:  0.0010986408005264486\n","epoch 3\n","The cost at the end of this epoch is  0.06458528799763681\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 241.   8.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  20. 244.   1.  18.   0.   5.   1.   4.]\n"," [  2.   3.   1.   0. 295.   2.   6.   4.   2.   5.]\n"," [  5.   4.   2.  15.   0. 252.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   5.   2.   0.   0. 264.   1.  14.]\n"," [  3.  11.   8.  10.   1.  13.   3.   0. 262.  13.]\n"," [  1.   0.   0.   1.  12.   1.   0.  10.   2. 238.]]\n","Accuracy Macro 0.8822327947742256 Precision Macro 0.8814707275277985\n","Change of the performance: 0.001487741794710007 0.0014960316914361949 \n","Change of cost:  0.0011171160708186856\n","epoch 4\n","The cost at the end of this epoch is  0.06390830644545349\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 246.   6.   2.   3.   7.   6.   9.   2.]\n"," [  3.   7.  19. 244.   1.  18.   1.   5.   1.   4.]\n"," [  1.   3.   1.   0. 296.   2.   6.   3.   2.   6.]\n"," [  5.   4.   2.  16.   0. 249.   4.   0.   8.   2.]\n"," [  6.   3.   6.   0.   4.  10. 258.   0.   5.   0.]\n"," [  1.   2.   3.   4.   2.   0.   0. 264.   1.  15.]\n"," [  3.  11.   8.   9.   1.  15.   3.   0. 262.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8836591743544234 Precision Macro 0.8828360714457059\n","Change of the performance: 0.0014263795801978674 0.0013653439179073246 \n","Change of cost:  0.000320198078539391\n","epoch 5\n","The cost at the end of this epoch is  0.06417038804183454\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  6.   2. 244.   6.   2.   3.   7.   6.  10.   2.]\n"," [  2.   7.  19. 243.   1.  21.   0.   5.   1.   4.]\n"," [  1.   3.   1.   0. 297.   2.   6.   4.   2.   4.]\n"," [  6.   4.   1.  15.   0. 254.   3.   0.   7.   0.]\n"," [  6.   2.   5.   0.   4.  10. 260.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 265.   1.  15.]\n"," [  4.  11.   8.   9.   1.  16.   3.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.  11.   2. 238.]]\n","Accuracy Macro 0.8836978003486277 Precision Macro 0.8831647332239252\n","Change of the performance: 3.8625994204233294e-05 0.0003286617782193302 \n","Change of cost:  2.8674029852598926e-06\n","epoch 6\n","The cost at the end of this epoch is  0.06339306240294104\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   2.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 242.   6.   2.   3.   7.   8.  10.   2.]\n"," [  3.   7.  19. 242.   1.  19.   1.   6.   1.   4.]\n"," [  1.   3.   1.   0. 296.   2.   6.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 252.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   4.  10. 258.   0.   6.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 266.   1.  14.]\n"," [  3.  11.   8.   9.   1.  15.   3.   0. 261.  13.]\n"," [  1.   0.   0.   0.  12.   1.   0.  11.   2. 238.]]\n","Accuracy Macro 0.8819518093591581 Precision Macro 0.8812368483165193\n","Change of the performance: 0.0017459909894695924 0.001927884907405919 \n","Change of cost:  4.625326535036278e-05\n","epoch 7\n","The cost at the end of this epoch is  0.06393701481617046\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   3.   1.   4.   3.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   6.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  19. 244.   1.  19.   0.   5.   1.   4.]\n"," [  1.   3.   0.   0. 297.   2.   6.   3.   2.   6.]\n"," [  6.   4.   2.  15.   0. 249.   5.   0.   7.   2.]\n"," [  6.   2.   6.   0.   5.   9. 258.   0.   6.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  3.  11.   8.   9.   1.  14.   3.   0. 262.  13.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8845678483586162 Precision Macro 0.8837538329329451\n","Change of the performance: 0.00261603899945817 0.002516984616425799 \n","Change of cost:  0.00011433640629565645\n","epoch 8\n","The cost at the end of this epoch is  0.06312272715968395\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   6.   4.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 244.   6.   2.   3.   7.   7.  10.   2.]\n"," [  3.   7.  19. 244.   1.  18.   1.   5.   1.   4.]\n"," [  2.   3.   1.   0. 295.   2.   6.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  3.  11.   8.   9.   1.  15.   3.   0. 261.  13.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8837530673510748 Precision Macro 0.8829308033089633\n","Change of the performance: 0.0008147810075413986 0.0008230296239817303 \n","Change of cost:  0.001547753489646711\n","epoch 9\n","The cost at the end of this epoch is  0.06291421396751269\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  6.   2. 245.   6.   2.   3.   7.   5.  10.   2.]\n"," [  3.   7.  19. 244.   1.  19.   0.   5.   1.   4.]\n"," [  1.   3.   1.   0. 296.   2.   6.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   4.   2.   0.   0. 263.   1.  16.]\n"," [  4.  11.   8.   9.   1.  16.   3.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8827553925363876 Precision Macro 0.882097643984088\n","Change of the performance: 0.000997674814687266 0.0008331593248753766 \n","Change of cost:  0.00013588724932689367\n","epoch 10\n","The cost at the end of this epoch is  0.06282207173907312\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   2.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  6.   2. 243.   6.   2.   4.   7.   6.  10.   2.]\n"," [  3.   7.  18. 244.   1.  20.   0.   5.   1.   4.]\n"," [  1.   3.   1.   0. 295.   2.   7.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  16.   3.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.882405379254173 Precision Macro 0.8818023738751626\n","Change of the performance: 0.0003500132822146229 0.00029527010892538286 \n","Change of cost:  4.772378935674615e-05\n","epoch 11\n","The cost at the end of this epoch is  0.06318895002419789\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 244.   7.   2.   3.   7.   6.  10.   2.]\n"," [  2.   7.  19. 244.   1.  19.   0.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  3.  11.   8.   9.   1.  15.   3.   0. 262.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8830554200182072 Precision Macro 0.8822513073608373\n","Change of the performance: 0.0006500407640342987 0.0004489334856747629 \n","Change of cost:  0.0006735531371244441\n","epoch 12\n","The cost at the end of this epoch is  0.06254227659356046\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 243.   6.   2.   3.   7.   7.  10.   2.]\n"," [  3.   7.  18. 245.   1.  19.   0.   5.   1.   4.]\n"," [  1.   3.   1.   0. 295.   2.   7.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  3.  11.   8.   9.   1.  16.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.  10.   2. 239.]]\n","Accuracy Macro 0.8823522303334108 Precision Macro 0.8816810513944571\n","Change of the performance: 0.0007031896847964347 0.0005702559663802731 \n","Change of cost:  3.3244277524435706e-05\n","epoch 13\n","The cost at the end of this epoch is  0.062376519494960724\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   3.   1.   5.   3.   2.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 243.   7.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  19. 243.   1.  19.   0.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   8.   2. 241.]]\n","Accuracy Macro 0.8840192083519673 Precision Macro 0.8832184112544589\n","Change of the performance: 0.0016669780185565308 0.001537359860001808 \n","Change of cost:  0.0002549272975697417\n","epoch 14\n","The cost at the end of this epoch is  0.0623999775443717\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   2.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   6.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  19. 244.   1.  19.   0.   5.   1.   4.]\n"," [  1.   3.   1.   0. 296.   1.   8.   4.   2.   4.]\n"," [  5.   4.   2.  15.   0. 252.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  14.   3.   0. 262.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8843744352354415 Precision Macro 0.883609829037165\n","Change of the performance: 0.00035522688347411346 0.00039141778270612715 \n","Change of cost:  2.5549128111868047e-05\n","epoch 15\n","The cost at the end of this epoch is  0.06211630619334039\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   6.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  20. 243.   1.  18.   0.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.  10.   2. 239.]]\n","Accuracy Macro 0.8823866087712545 Precision Macro 0.8815527407961262\n","Change of the performance: 0.001987826464186937 0.0020570882410387847 \n","Change of cost:  1.662694613304566e-05\n","epoch 16\n","The cost at the end of this epoch is  0.062086864180666966\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   6.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  19. 244.   1.  19.   0.   5.   1.   4.]\n"," [  1.   3.   1.   0. 296.   1.   8.   4.   2.   4.]\n"," [  6.   4.   1.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.883406500265121 Precision Macro 0.8826297127051829\n","Change of the performance: 0.0010198914938664982 0.0010769719090566454 \n","Change of cost:  3.095229071595207e-05\n","epoch 17\n","The cost at the end of this epoch is  0.062018790873438895\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   6.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  19. 244.   1.  19.   0.   5.   1.   4.]\n"," [  1.   3.   1.   0. 296.   1.   8.   4.   2.   4.]\n"," [  5.   4.   2.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.883720965673926 Precision Macro 0.8829318457248603\n","Change of the performance: 0.00031446540880497587 0.0003021330196774086 \n","Change of cost:  2.6166641378715105e-05\n","epoch 18\n","The cost at the end of this epoch is  0.06202358949094659\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   6.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  19. 244.   1.  19.   0.   5.   1.   4.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  5.   4.   2.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8830940002651209 Precision Macro 0.8822855758816353\n","Change of the performance: 0.0006269654088051357 0.0006462698432250225 \n","Change of cost:  5.446832103503385e-06\n","epoch 19\n","The cost at the end of this epoch is  0.06196635508592964\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   6.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  19. 244.   1.  18.   0.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  5.   4.   2.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.883408465673926 Precision Macro 0.882565002965468\n","Change of the performance: 0.0003144654088050869 0.0002794270838327728 \n","Change of cost:  9.790471575885085e-07\n","epoch 20\n","The cost at the end of this epoch is  0.06192754255135328\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   6.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  19. 244.   1.  18.   0.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  5.   4.   2.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.  10.   2. 239.]]\n","Accuracy Macro 0.8830311071833599 Precision Macro 0.8822013101892361\n","Change of the performance: 0.00037735849056608206 0.00036369277623193863 \n","Change of cost:  6.307184370162033e-06\n","epoch 21\n","The cost at the end of this epoch is  0.06191672775590563\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   6.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  19. 244.   1.  18.   0.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  5.   4.   2.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.883408465673926 Precision Macro 0.882565002965468\n","Change of the performance: 0.00037735849056608206 0.00036369277623193863 \n","Change of cost:  1.912928138926573e-06\n","epoch 22\n","The cost at the end of this epoch is  0.06190406821451882\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 245.   6.   2.   3.   7.   6.  10.   2.]\n"," [  3.   7.  19. 244.   1.  18.   0.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  5.   4.   2.  15.   0. 251.   4.   0.   8.   1.]\n"," [  7.   2.   5.   0.   4.  10. 259.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 264.   1.  16.]\n"," [  4.  11.   8.   9.   1.  15.   3.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.883408465673926 Precision Macro 0.882565002965468\n","Change of the performance: 0.0 0.0 \n","Change of cost:  8.086978536131495e-08\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_23_1000x785_10x1001\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [1050   10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (1050, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 1051)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 1050)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.06255551668917092\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   1.   3.   1.   7.   4.   3.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  5.   2. 244.   5.   2.   3.   7.   8.  10.   2.]\n"," [  3.   7.  18. 242.   1.  19.   0.   7.   1.   5.]\n"," [  1.   3.   1.   0. 294.   2.   7.   4.   3.   5.]\n"," [  5.   4.   2.  15.   0. 252.   4.   0.   7.   1.]\n"," [  7.   2.   5.   0.   5.  10. 257.   0.   6.   0.]\n"," [  1.   2.   2.   0.   2.   0.   0. 268.   1.  16.]\n"," [  3.  11.   8.   8.   1.  14.   3.   0. 262.  14.]\n"," [  1.   0.   0.   0.  12.   1.   0.  11.   2. 238.]]\n","Accuracy Macro 0.8823578961235308 Precision Macro 0.8816415440962093\n","epoch 1\n","The cost at the end of this epoch is  0.14560976244442017\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   0.   4.   1.   3.   3.   3.   0.   0.]\n"," [  0. 294.   4.   2.   0.   2.   0.   0.   5.   1.]\n"," [  6.   2. 241.   7.   1.   4.   8.  13.   5.   1.]\n"," [  3.   7.  18. 247.   1.  17.   1.   7.   0.   2.]\n"," [  1.   3.   1.   1. 289.   3.   8.   6.   2.   6.]\n"," [  7.   3.   1.  17.   0. 253.   3.   0.   6.   0.]\n"," [  9.   3.   5.   0.   4.  12. 254.   1.   4.   0.]\n"," [  1.   2.   1.   1.   0.   0.   0. 277.   1.   9.]\n"," [  6.  14.   9.  14.   1.  25.   4.   3. 231.  17.]\n"," [  1.   0.   0.   1.  13.   1.   0.  18.   0. 231.]]\n","Accuracy Macro 0.874120039097901 Precision Macro 0.8742527296183251\n","epoch 2\n","The cost at the end of this epoch is  0.251154561652833\n","Now let's test the model after this epoch:\n","Confusion array  [[292.   0.   0.   4.   1.  12.   3.   2.   3.   1.]\n"," [  0. 296.   1.   2.   0.   3.   0.   1.   4.   1.]\n"," [  4.   6. 228.   8.   2.  10.   7.  14.   8.   1.]\n"," [  0.   9.   9. 239.   1.  30.   0.   7.   2.   6.]\n"," [  0.   4.   0.   0. 293.   5.   3.   8.   1.   6.]\n"," [  3.   4.   1.   9.   0. 265.   1.   0.   6.   1.]\n"," [  9.   5.   0.   0.   7.  22. 244.   1.   4.   0.]\n"," [  1.   6.   0.   1.   3.   0.   0. 265.   2.  14.]\n"," [  7.  18.   3.  16.   1.  49.   2.   1. 207.  20.]\n"," [  1.   0.   0.   0.  14.   2.   0.  16.   1. 231.]]\n","Accuracy Macro 0.8542879289780327 Precision Macro 0.8617800313792658\n","Change of the performance: 0.019832110119868296 0.012472698239059277 \n","Change of cost:  0.08846660110527937\n","epoch 3\n","The cost at the end of this epoch is  0.07708857313760908\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   0.   3.   1.   9.   3.   3.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   1.   6.   0.]\n"," [  3.   3. 243.   6.   3.   6.   7.   7.   9.   1.]\n"," [  2.   7.  21. 241.   1.  19.   1.   5.   2.   4.]\n"," [  1.   3.   1.   0. 295.   2.   4.   3.   2.   9.]\n"," [  6.   4.   1.  16.   0. 253.   3.   0.   7.   0.]\n"," [  6.   3.   5.   0.   5.   9. 256.   0.   8.   0.]\n"," [  1.   2.   4.   1.   2.   0.   0. 268.   2.  12.]\n"," [  3.  11.   9.   8.   1.  14.   2.   0. 269.   7.]\n"," [  1.   0.   0.   0.  11.   1.   0.  10.   3. 239.]]\n","Accuracy Macro 0.8842188896397121 Precision Macro 0.8841919660513053\n","Change of the performance: 0.02993096066167933 0.022411934672039502 \n","Change of cost:  0.0002836712499058591\n","epoch 4\n","The cost at the end of this epoch is  0.08430085341107237\n","Now let's test the model after this epoch:\n","Confusion array  [[296.   0.   1.   3.   1.  10.   3.   1.   3.   0.]\n"," [  0. 290.   2.   5.   0.   2.   0.   1.   6.   2.]\n"," [  3.   2. 244.   7.   2.   6.   8.   4.  10.   2.]\n"," [  1.   5.  15. 247.   1.  20.   0.   4.   4.   6.]\n"," [  0.   4.   1.   0. 293.   3.   4.   3.   2.  10.]\n"," [  4.   4.   1.  17.   0. 253.   2.   0.   8.   1.]\n"," [  8.   2.   4.   0.   4.  11. 257.   0.   6.   0.]\n"," [  2.   2.   2.   6.   2.   0.   0. 261.   1.  16.]\n"," [  4.   6.   6.   9.   1.  18.   2.   0. 261.  17.]\n"," [  1.   0.   0.   0.  11.   1.   0.   7.   2. 243.]]\n","Accuracy Macro 0.8819327875469574 Precision Macro 0.8823304560142488\n","Change of the performance: 0.002286102092754705 0.0018615100370565907 \n","Change of cost:  0.004739161924809249\n","epoch 5\n","The cost at the end of this epoch is  0.06494874177126984\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   3.   1.   4.   4.   2.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 242.   6.   3.   6.   7.   6.   8.   2.]\n"," [  3.   7.  19. 243.   1.  18.   1.   5.   1.   5.]\n"," [  2.   3.   1.   0. 291.   2.   7.   3.   2.   9.]\n"," [  6.   4.   1.  16.   0. 252.   3.   0.   7.   1.]\n"," [  7.   2.   5.   0.   3.  10. 258.   0.   7.   0.]\n"," [  1.   3.   3.   4.   2.   0.   0. 262.   1.  16.]\n"," [  3.  12.   7.   9.   1.  14.   2.   0. 264.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.882287983891038 Precision Macro 0.8817251762397078\n","Change of the performance: 0.0003551963440806549 0.0006052797745409455 \n","Change of cost:  0.0006023410101528848\n","epoch 6\n","The cost at the end of this epoch is  0.0641881480930061\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   4.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  4.   3. 240.   8.   3.   5.   7.   7.   9.   2.]\n"," [  3.   7.  18. 240.   1.  22.   0.   5.   3.   4.]\n"," [  2.   3.   1.   0. 294.   2.   6.   3.   2.   7.]\n"," [  7.   4.   1.  15.   0. 254.   3.   0.   6.   0.]\n"," [  7.   2.   5.   0.   4.  10. 258.   0.   6.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 264.   1.  14.]\n"," [  2.  12.   7.   9.   1.  15.   2.   0. 263.  13.]\n"," [  1.   0.   0.   0.  13.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8816005958324709 Precision Macro 0.8811433030408569\n","Change of the performance: 0.0006873880585671621 0.0005818731988509462 \n","Change of cost:  0.0002246714436369146\n","epoch 7\n","The cost at the end of this epoch is  0.06405669452606454\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   3.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  4.   3. 240.   9.   3.   5.   7.   7.   8.   2.]\n"," [  3.   7.  19. 245.   1.  15.   1.   5.   1.   6.]\n"," [  2.   4.   1.   0. 295.   2.   4.   3.   2.   7.]\n"," [  5.   4.   2.  15.   0. 253.   3.   0.   8.   0.]\n"," [  6.   3.   6.   0.   5.  10. 256.   0.   6.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 264.   1.  14.]\n"," [  3.  12.   7.   9.   1.  12.   2.   0. 266.  12.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8828933899459933 Precision Macro 0.8824675570335458\n","Change of the performance: 0.0012927941135224552 0.001324253992688984 \n","Change of cost:  0.0005611522457054374\n","epoch 8\n","The cost at the end of this epoch is  0.06320753153305461\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  4.   3. 241.   9.   3.   5.   7.   6.   8.   2.]\n"," [  3.   7.  20. 245.   1.  15.   1.   5.   1.   5.]\n"," [  2.   3.   1.   1. 291.   2.   7.   3.   2.   8.]\n"," [  5.   4.   2.  16.   0. 251.   4.   0.   8.   0.]\n"," [  7.   2.   5.   0.   3.  10. 258.   0.   7.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 263.   1.  15.]\n"," [  3.  12.   7.   9.   1.  11.   2.   0. 267.  12.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.88226653013334 Precision Macro 0.881545774185969\n","Change of the performance: 0.0006268598126533131 0.0009217828475768242 \n","Change of cost:  0.00016381340053601978\n","epoch 9\n","The cost at the end of this epoch is  0.06504555642144551\n","Now let's test the model after this epoch:\n","Confusion array  [[295.   0.   0.   3.   1.  10.   3.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  4.   3. 242.   8.   3.   5.   7.   6.   8.   2.]\n"," [  2.   7.  18. 246.   1.  17.   1.   4.   1.   6.]\n"," [  1.   4.   1.   0. 294.   2.   5.   3.   2.   8.]\n"," [  5.   4.   2.  16.   0. 253.   3.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   3.   3.   5.   2.   0.   0. 262.   1.  15.]\n"," [  3.  12.   7.  10.   1.  14.   2.   0. 263.  12.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8817080448967773 Precision Macro 0.8814489197637478\n","Change of the performance: 0.0005584852365626558 9.685442222118201e-05 \n","Change of cost:  0.001975252241737571\n","epoch 10\n","The cost at the end of this epoch is  0.06322403515918841\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   4.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 243.   7.   3.   4.   7.   6.   8.   2.]\n"," [  3.   7.  20. 244.   1.  16.   1.   5.   1.   5.]\n"," [  2.   3.   1.   0. 294.   2.   7.   3.   2.   6.]\n"," [  6.   4.   2.  16.   0. 251.   4.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.   9. 257.   0.   7.   0.]\n"," [  1.   3.   3.   5.   2.   0.   0. 262.   1.  15.]\n"," [  4.  12.   8.  10.   1.  15.   2.   0. 260.  12.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8816664124668894 Precision Macro 0.8809266093860346\n","Change of the performance: 4.163242988797222e-05 0.0005223103777132199 \n","Change of cost:  0.00039555736400079256\n","epoch 11\n","The cost at the end of this epoch is  0.06281345801389447\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 242.   7.   3.   6.   7.   5.   8.   2.]\n"," [  3.   7.  20. 243.   1.  17.   1.   5.   1.   5.]\n"," [  2.   3.   1.   0. 294.   1.   8.   3.   2.   6.]\n"," [  5.   4.   2.  16.   0. 252.   3.   0.   8.   0.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   3.   3.   5.   2.   0.   0. 262.   1.  15.]\n"," [  3.  12.   8.  10.   1.  15.   2.   0. 261.  12.]\n"," [  1.   0.   0.   0.  13.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8803847651676623 Precision Macro 0.8798345417378618\n","Change of the performance: 0.0012816472992270844 0.001092067648172823 \n","Change of cost:  0.0001261717983647992\n","epoch 12\n","The cost at the end of this epoch is  0.062496293387050914\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   5.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 244.   6.   2.   5.   7.   5.   9.   2.]\n"," [  3.   7.  20. 242.   1.  18.   1.   5.   1.   5.]\n"," [  2.   3.   1.   0. 294.   2.   7.   3.   2.   6.]\n"," [  6.   4.   2.  16.   0. 251.   4.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   3.   5.   2.   0.   0. 263.   1.  15.]\n"," [  4.  12.   8.  10.   1.  16.   2.   0. 259.  12.]\n"," [  1.   0.   1.   0.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8810729270518219 Precision Macro 0.8804080258264222\n","Change of the performance: 0.0006881618841596548 0.0005734840885603942 \n","Change of cost:  3.8242216363185144e-05\n","epoch 13\n","The cost at the end of this epoch is  0.062310131012076095\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   8.   3.   2.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 243.   7.   2.   5.   7.   5.   9.   2.]\n"," [  3.   7.  19. 244.   1.  17.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   2.   7.   3.   2.   6.]\n"," [  6.   4.   1.  15.   0. 253.   3.   0.   8.   0.]\n"," [  7.   3.   4.   0.   3.  11. 258.   0.   6.   0.]\n"," [  1.   2.   3.   5.   2.   0.   0. 263.   1.  15.]\n"," [  3.  12.   8.  10.   1.  16.   2.   0. 260.  12.]\n"," [  1.   0.   1.   0.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8824101029197374 Precision Macro 0.8819858607798278\n","Change of the performance: 0.0013371758679154855 0.0015778349534055769 \n","Change of cost:  0.00021982795336593364\n","epoch 14\n","The cost at the end of this epoch is  0.06227974605505786\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 244.   6.   2.   6.   7.   5.   8.   2.]\n"," [  3.   7.  20. 243.   1.  17.   1.   5.   1.   5.]\n"," [  2.   3.   1.   0. 294.   1.   8.   3.   2.   6.]\n"," [  5.   4.   2.  16.   0. 252.   3.   0.   8.   0.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   3.   3.   5.   2.   0.   0. 262.   1.  15.]\n"," [  3.  12.   8.  10.   1.  15.   2.   0. 261.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8810792096121067 Precision Macro 0.8804999563576553\n","Change of the performance: 0.0013308933076306984 0.001485904422172446 \n","Change of cost:  0.00014389698029659836\n","epoch 15\n","The cost at the end of this epoch is  0.0619543251888594\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   2.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 244.   6.   2.   5.   7.   5.   9.   2.]\n"," [  3.   7.  20. 242.   1.  18.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 252.   4.   0.   8.   0.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   2.   3.   5.   2.   0.   0. 263.   1.  15.]\n"," [  3.  12.   8.  10.   1.  16.   2.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8814099657957275 Precision Macro 0.8807859490404226\n","Change of the performance: 0.00033075618362077286 0.00028599268276729983 \n","Change of cost:  6.772913259345259e-06\n","epoch 16\n","The cost at the end of this epoch is  0.06204277585429747\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 244.   6.   2.   5.   7.   5.   9.   2.]\n"," [  3.   7.  20. 242.   1.  18.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  15.   0. 253.   3.   0.   8.   0.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   2.   3.   4.   2.   0.   0. 264.   1.  15.]\n"," [  3.  12.   8.  10.   1.  16.   2.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8817827937265541 Precision Macro 0.8811605434385001\n","Change of the performance: 0.0003728279308266025 0.00037459439807752126 \n","Change of cost:  3.778570975267875e-05\n","epoch 17\n","The cost at the end of this epoch is  0.06184370345674334\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   6.   4.   3.   2.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 244.   6.   2.   5.   7.   5.   9.   2.]\n"," [  3.   7.  20. 242.   1.  18.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   8.   0.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   2.   3.   5.   2.   0.   0. 263.   1.  15.]\n"," [  4.  12.   8.  10.   1.  16.   2.   0. 259.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.881070961643017 Precision Macro 0.88036387031802\n","Change of the performance: 0.0007118320835370895 0.0007966731204801514 \n","Change of cost:  8.131220043394727e-07\n","epoch 18\n","The cost at the end of this epoch is  0.06181356974854012\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 244.   6.   2.   5.   7.   5.   9.   2.]\n"," [  3.   7.  19. 242.   1.  19.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  5.   4.   2.  16.   0. 251.   4.   0.   8.   0.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   2.   4.   5.   2.   0.   0. 262.   1.  15.]\n"," [  3.  12.   8.  10.   1.  16.   2.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8807226724560959 Precision Macro 0.8800609269310463\n","Change of the performance: 0.00034828918692109134 0.0003029433869736753 \n","Change of cost:  2.2447136875172746e-06\n","epoch 19\n","The cost at the end of this epoch is  0.061762595138515855\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 244.   6.   2.   5.   7.   5.   9.   2.]\n"," [  3.   7.  19. 243.   1.  18.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   2.   7.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   8.   0.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   2.   3.   5.   2.   0.   0. 263.   1.  15.]\n"," [  3.  12.   8.  10.   1.  16.   2.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8813951712128208 Precision Macro 0.8807847567981038\n","Change of the performance: 0.0006724987567249263 0.000723829867057435 \n","Change of cost:  3.172061795168879e-06\n","epoch 20\n","The cost at the end of this epoch is  0.061742906365394125\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 243.   7.   2.   5.   7.   5.   9.   2.]\n"," [  3.   7.  20. 243.   1.  17.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   8.   0.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   2.   3.   5.   2.   0.   0. 263.   1.  15.]\n"," [  3.  12.   8.  10.   1.  16.   2.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8810479489905987 Precision Macro 0.8803335917658236\n","Change of the performance: 0.0003472222222221655 0.00045116503228015414 \n","Change of cost:  3.2409777880465507e-06\n","epoch 21\n","The cost at the end of this epoch is  0.061724242738681545\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   3. 243.   7.   2.   5.   7.   5.   9.   2.]\n"," [  3.   7.  20. 243.   1.  17.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   8.   0.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   2.   3.   5.   2.   0.   0. 263.   1.  15.]\n"," [  3.  12.   8.  10.   1.  16.   2.   0. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8810479489905987 Precision Macro 0.8803335917658236\n","Change of the performance: 0.0 0.0 \n","Change of cost:  2.457615627990406e-06\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_24_1050x785_10x1051\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [1100   10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (1100, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 1101)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 1100)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.06484511536799245\n","Now let's test the model after this epoch:\n","Confusion array  [[303.   0.   0.   3.   1.   4.   3.   2.   2.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  6.   3. 240.   8.   2.   4.   7.   6.  10.   2.]\n"," [  4.   7.  17. 242.   1.  20.   1.   6.   0.   5.]\n"," [  2.   3.   1.   0. 294.   1.   8.   4.   2.   5.]\n"," [  7.   4.   1.  15.   0. 250.   5.   0.   8.   0.]\n"," [  8.   2.   4.   0.   4.   8. 259.   0.   7.   0.]\n"," [  1.   2.   2.   3.   2.   0.   0. 266.   1.  15.]\n"," [  5.  12.   8.  10.   1.  15.   2.   1. 259.  11.]\n"," [  1.   0.   0.   0.  12.   1.   0.  12.   2. 237.]]\n","Accuracy Macro 0.8808628600985664 Precision Macro 0.8801693741886745\n","epoch 1\n","The cost at the end of this epoch is  0.06397309965629429\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   4.   3.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  6.   3. 243.   6.   3.   4.   7.   5.   9.   2.]\n"," [  3.   7.  19. 247.   1.  14.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 292.   2.   6.   4.   2.   9.]\n"," [  5.   4.   2.  17.   0. 250.   3.   0.   8.   1.]\n"," [  9.   3.   5.   0.   4.   7. 257.   0.   7.   0.]\n"," [  1.   2.   2.   4.   2.   0.   0. 265.   1.  15.]\n"," [  5.  12.   8.  10.   0.  12.   2.   0. 262.  13.]\n"," [  1.   0.   0.   0.  11.   1.   0.  10.   1. 241.]]\n","Accuracy Macro 0.8833840482673654 Precision Macro 0.8826078657594326\n","epoch 2\n","The cost at the end of this epoch is  0.12089357262754129\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   8.   3.   2.   2.   0.]\n"," [  0. 293.   1.   4.   0.   2.   1.   1.   6.   0.]\n"," [  6.   4. 231.   7.   2.   7.  10.   8.  12.   1.]\n"," [  3.   7.  19. 244.   1.  15.   1.   5.   1.   7.]\n"," [  1.   3.   2.   0. 282.   0.   6.   9.   4.  13.]\n"," [  5.   4.   1.  22.   0. 249.   2.   0.   5.   2.]\n"," [ 10.   2.   6.   0.   5.  10. 255.   0.   4.   0.]\n"," [  1.   2.   1.   3.   2.   0.   0. 267.   1.  15.]\n"," [  5.  13.   4.  11.   0.  10.   2.   0. 260.  19.]\n"," [  1.   0.   0.   0.  11.   2.   0.  12.   1. 238.]]\n","Accuracy Macro 0.8723893746805358 Precision Macro 0.8718251567336841\n","Change of the performance: 0.010994673586829595 0.010782709025748516 \n","Change of cost:  0.03586460416484087\n","epoch 3\n","The cost at the end of this epoch is  0.06362114983536347\n","Now let's test the model after this epoch:\n","Confusion array  [[302.   0.   0.   3.   1.   4.   3.   2.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   2. 243.   9.   3.   3.   7.   7.   7.   2.]\n"," [  3.   7.  21. 243.   1.  15.   1.   6.   1.   5.]\n"," [  2.   3.   1.   0. 293.   2.   7.   3.   2.   7.]\n"," [  6.   4.   1.  16.   0. 252.   3.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.   9. 257.   0.   7.   0.]\n"," [  1.   2.   3.   4.   2.   0.   0. 264.   1.  15.]\n"," [  3.  12.   8.  10.   0.  14.   2.   0. 261.  14.]\n"," [  1.   0.   0.   0.  13.   1.   0.  10.   1. 239.]]\n","Accuracy Macro 0.8819747121255176 Precision Macro 0.8810984512107456\n","Change of the performance: 0.0095853374449818 0.009273294477061489 \n","Change of cost:  0.00028854117608508034\n","epoch 4\n","The cost at the end of this epoch is  0.06350220750323596\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   5.   3.   2.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   3. 241.   9.   2.   4.   7.   7.   8.   2.]\n"," [  3.   7.  19. 244.   1.  16.   1.   6.   1.   5.]\n"," [  2.   4.   1.   0. 293.   2.   6.   4.   2.   6.]\n"," [  6.   4.   1.  15.   0. 253.   3.   0.   8.   0.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   2.   3.   4.   2.   0.   0. 265.   1.  14.]\n"," [  3.  12.   8.  10.   1.  12.   2.   0. 264.  12.]\n"," [  1.   0.   1.   0.  11.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8832864130316921 Precision Macro 0.8826441560688281\n","Change of the performance: 0.0013117009061744955 0.001545704858082475 \n","Change of cost:  1.5027857530380828e-05\n","epoch 5\n","The cost at the end of this epoch is  0.06516094812483114\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   3.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 240.   9.   2.   3.   7.   9.   7.   2.]\n"," [  2.   7.  19. 244.   1.  15.   1.   7.   1.   6.]\n"," [  2.   3.   1.   0. 293.   1.   8.   4.   2.   6.]\n"," [  5.   4.   2.  15.   0. 252.   3.   0.   8.   1.]\n"," [  7.   3.   4.   0.   5.   9. 257.   0.   7.   0.]\n"," [  1.   3.   4.   3.   2.   0.   0. 266.   1.  12.]\n"," [  3.  14.   8.   9.   1.  12.   2.   0. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8802542832438274 Precision Macro 0.8794914670867457\n","Change of the performance: 0.0030321297878647124 0.003152688982082319 \n","Change of cost:  0.0020683880802907645\n","epoch 6\n","The cost at the end of this epoch is  0.06278364747165636\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   8.   3.   2.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   3. 243.   6.   2.   5.   7.   7.   8.   2.]\n"," [  3.   7.  20. 243.   1.  17.   1.   5.   1.   5.]\n"," [  1.   3.   3.   0. 292.   1.   8.   3.   2.   7.]\n"," [  6.   4.   1.  15.   0. 254.   3.   0.   6.   1.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   3.   3.   5.   2.   0.   0. 263.   1.  14.]\n"," [  3.  12.   8.  10.   1.  13.   2.   0. 263.  12.]\n"," [  1.   0.   1.   0.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8813688238599038 Precision Macro 0.880806992987492\n","Change of the performance: 0.0011145406160764093 0.0013155259007462394 \n","Change of cost:  0.0003969573242153107\n","epoch 7\n","The cost at the end of this epoch is  0.06227330312704429\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   3.   3.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   3. 242.   7.   2.   5.   7.   7.   8.   2.]\n"," [  3.   7.  21. 243.   1.  16.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 293.   1.   8.   3.   2.   8.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   3.   2.   0.   0. 265.   1.  14.]\n"," [  3.  12.   8.   8.   0.  16.   2.   0. 261.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.880430159517054 Precision Macro 0.8797060668250183\n","Change of the performance: 0.0009386643428498376 0.0011009261624737032 \n","Change of cost:  0.001718301022767356\n","epoch 8\n","The cost at the end of this epoch is  0.06278966157284772\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   3.   3.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  4.   3. 243.   6.   2.   5.   7.   7.   9.   2.]\n"," [  2.   7.  21. 244.   1.  16.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 294.   2.   7.   3.   2.   7.]\n"," [  5.   4.   2.  15.   0. 253.   3.   0.   7.   1.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   3.   4.   4.   2.   0.   0. 264.   1.  13.]\n"," [  3.  12.   8.   9.   0.  12.   2.   0. 264.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8823156715969256 Precision Macro 0.881744718748474\n","Change of the performance: 0.001885512079871643 0.0020386519234557587 \n","Change of cost:  7.6052285369832e-05\n","epoch 9\n","The cost at the end of this epoch is  0.062471351112522215\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   8.   3.   2.   3.   0.]\n"," [  0. 293.   4.   2.   0.   2.   0.   0.   6.   1.]\n"," [  6.   3. 241.   7.   2.   5.   7.   6.   9.   2.]\n"," [  2.   7.  21. 244.   1.  16.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 292.   1.   8.   5.   2.   7.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   3.   3.   5.   2.   0.   0. 263.   1.  14.]\n"," [  3.  12.   8.   9.   0.  15.   2.   0. 261.  14.]\n"," [  1.   0.   1.   0.  11.   1.   0.  11.   2. 238.]]\n","Accuracy Macro 0.8792999625436311 Precision Macro 0.8786394509954271\n","Change of the performance: 0.003015709053294513 0.0031052677530469808 \n","Change of cost:  1.813717493521355e-05\n","epoch 10\n","The cost at the end of this epoch is  0.061726940496296935\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   8.   3.   3.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  4.   3. 244.   8.   2.   4.   7.   7.   7.   2.]\n"," [  2.   7.  21. 244.   1.  16.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 294.   1.   8.   4.   2.   6.]\n"," [  6.   4.   1.  16.   0. 252.   3.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 263.   1.  15.]\n"," [  3.  12.   8.  10.   0.  14.   2.   0. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8806035995477668 Precision Macro 0.8798917079537901\n","Change of the performance: 0.001303637004135716 0.0012522569583630627 \n","Change of cost:  0.0003108207707191446\n","epoch 11\n","The cost at the end of this epoch is  0.06207866513965699\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   8.   3.   2.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  4.   3. 241.   8.   2.   6.   7.   7.   8.   2.]\n"," [  2.   7.  21. 245.   1.  15.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 293.   1.   8.   5.   2.   6.]\n"," [  6.   4.   1.  15.   0. 253.   3.   0.   7.   1.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   3.   3.   4.   2.   0.   0. 263.   1.  15.]\n"," [  3.  12.   8.   9.   0.  13.   2.   0. 263.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.  10.   2. 238.]]\n","Accuracy Macro 0.8809247593452871 Precision Macro 0.8802988399858889\n","Change of the performance: 0.00032115979752034285 0.0004071320320987448 \n","Change of cost:  0.0005273222343028794\n","epoch 12\n","The cost at the end of this epoch is  0.061536458050955416\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  4.   3. 243.   6.   2.   5.   7.   8.   8.   2.]\n"," [  3.   7.  21. 243.   1.  15.   1.   6.   1.   5.]\n"," [  1.   3.   1.   0. 293.   1.   8.   5.   2.   6.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   3.   2.   0.   0. 264.   1.  15.]\n"," [  3.  12.   8.   9.   0.  14.   2.   0. 262.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.879611482489462 Precision Macro 0.8787769109240265\n","Change of the performance: 0.0013132768558251628 0.001521929061862326 \n","Change of cost:  2.8463006004841862e-05\n","epoch 13\n","The cost at the end of this epoch is  0.061143726713198766\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   7.   4.   2.   2.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   3. 242.   7.   2.   5.   7.   7.   8.   2.]\n"," [  3.   7.  20. 243.   1.  17.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 294.   1.   8.   4.   2.   6.]\n"," [  6.   4.   1.  16.   0. 250.   4.   0.   8.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   3.   2.   0.   0. 264.   1.  15.]\n"," [  3.  12.   8.   9.   0.  14.   2.   0. 262.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8798608634986429 Precision Macro 0.8791228169919686\n","Change of the performance: 0.00024938100918092676 0.0003459060679420478 \n","Change of cost:  3.3844327117435458e-06\n","epoch 14\n","The cost at the end of this epoch is  0.06104454831442084\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  6.   3. 244.   6.   2.   3.   7.   6.   9.   2.]\n"," [  3.   7.  20. 243.   1.  17.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 293.   1.   8.   5.   2.   6.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 263.   1.  15.]\n"," [  3.  12.   8.   9.   0.  14.   2.   0. 262.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8796162389582598 Precision Macro 0.8788339142846615\n","Change of the performance: 0.0002446245403830982 0.00028890270730708156 \n","Change of cost:  4.721261741974514e-06\n","epoch 15\n","The cost at the end of this epoch is  0.060975055336653546\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  6.   3. 243.   6.   2.   5.   7.   6.   8.   2.]\n"," [  3.   7.  20. 243.   1.  17.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 293.   1.   8.   5.   2.   6.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   3.  11. 257.   0.   6.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 264.   1.  14.]\n"," [  3.  12.   8.   9.   0.  14.   2.   0. 262.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.879611482489462 Precision Macro 0.878908671252591\n","Change of the performance: 4.756468797828539e-06 7.475696792946795e-05 \n","Change of cost:  6.679148184558781e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_24_1100x785_10x1101\n","Lambda exported:  0.0\n","No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [1150   10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (1150, 785)\n","The # 1  weights layer is RNGed, shape:  (10, 1151)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 1150)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.06301812738010616\n","Now let's test the model after this epoch:\n","Confusion array  [[304.   0.   0.   3.   1.   3.   3.   2.   2.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   3. 240.   7.   2.   6.   7.   8.   9.   1.]\n"," [  3.   7.  20. 242.   1.  17.   1.   6.   1.   5.]\n"," [  1.   3.   0.   0. 294.   1.   8.   5.   2.   6.]\n"," [  7.   3.   1.  16.   0. 249.   5.   0.   8.   1.]\n"," [  7.   3.   5.   0.   4.   8. 258.   0.   7.   0.]\n"," [  1.   4.   3.   3.   2.   0.   0. 264.   1.  14.]\n"," [  5.  12.   8.  10.   0.  14.   2.   1. 260.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.  14.   2. 235.]]\n","Accuracy Macro 0.8790343503303918 Precision Macro 0.8782545851091381\n","epoch 1\n","The cost at the end of this epoch is  0.06338059131908602\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   3. 243.   7.   2.   5.   7.   5.   9.   2.]\n"," [  3.   6.  17. 246.   1.  18.   0.   5.   2.   5.]\n"," [  1.   3.   1.   0. 293.   2.   6.   5.   3.   6.]\n"," [  5.   4.   2.  17.   0. 251.   4.   0.   6.   1.]\n"," [  7.   3.   5.   0.   4.  12. 256.   0.   5.   0.]\n"," [  1.   3.   3.   5.   2.   0.   0. 264.   1.  13.]\n"," [  2.   9.   8.  10.   0.  13.   2.   0. 266.  14.]\n"," [  1.   0.   1.   1.  12.   1.   0.  11.   2. 236.]]\n","Accuracy Macro 0.881430790565412 Precision Macro 0.8809963642178313\n","epoch 2\n","The cost at the end of this epoch is  0.06265464060433058\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 293.   3.   3.   0.   2.   0.   0.   6.   1.]\n"," [  5.   4. 242.   7.   2.   5.   7.   6.   8.   2.]\n"," [  3.   6.  17. 244.   1.  19.   1.   5.   1.   6.]\n"," [  1.   3.   0.   0. 296.   1.   7.   3.   2.   7.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  11. 257.   0.   5.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 266.   1.  14.]\n"," [  3.  12.   8.   8.   0.  17.   2.   0. 259.  15.]\n"," [  1.   0.   1.   0.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.881747549647837 Precision Macro 0.8811862527672136\n","Change of the performance: 0.00031675908242501105 0.00018988854938228883 \n","Change of cost:  0.0008208564411827102\n","epoch 3\n","The cost at the end of this epoch is  0.06213949574346903\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   6.   4.   2.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  4.   4. 240.   8.   2.   6.   7.   7.   8.   2.]\n"," [  3.   7.  21. 244.   1.  16.   0.   5.   1.   5.]\n"," [  1.   3.   3.   0. 291.   1.   8.   3.   3.   7.]\n"," [  5.   4.   2.  17.   0. 249.   4.   0.   8.   1.]\n"," [  7.   3.   5.   0.   4.   9. 258.   0.   6.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 263.   1.  15.]\n"," [  3.  13.   8.  10.   0.  13.   2.   0. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8793461999429901 Precision Macro 0.8785463176183462\n","Change of the performance: 0.0024013497048468446 0.0026399351488674005 \n","Change of cost:  4.636597307632745e-05\n","epoch 4\n","The cost at the end of this epoch is  0.06169698929780992\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 241.   6.   2.   6.   7.   6.   9.   2.]\n"," [  3.   6.  19. 242.   1.  21.   0.   5.   1.   5.]\n"," [  1.   3.   0.   0. 295.   1.   7.   5.   3.   5.]\n"," [  6.   4.   1.  15.   0. 253.   4.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.   9. 257.   0.   7.   0.]\n"," [  1.   2.   4.   5.   2.   0.   0. 263.   1.  14.]\n"," [  3.  12.   8.   8.   1.  16.   2.   0. 261.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8812631311017501 Precision Macro 0.8807712082200675\n","Change of the performance: 0.0019169311587600157 0.0022248906017212633 \n","Change of cost:  0.0005195533612552261\n","epoch 5\n","The cost at the end of this epoch is  0.06290004869351407\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   5.   4.   2.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   2. 244.   7.   2.   5.   7.   5.   9.   2.]\n"," [  3.   6.  19. 240.   1.  22.   0.   5.   1.   6.]\n"," [  1.   3.   0.   0. 295.   1.   7.   4.   3.   6.]\n"," [  7.   4.   1.  15.   0. 253.   4.   0.   6.   0.]\n"," [  7.   3.   5.   0.   3.  10. 257.   0.   7.   0.]\n"," [  1.   2.   6.   4.   2.   0.   0. 262.   1.  14.]\n"," [  3.  11.   8.   8.   1.  16.   3.   0. 260.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8810565171148438 Precision Macro 0.8804923350696952\n","Change of the performance: 0.00020661398690635657 0.0002788731503723385 \n","Change of cost:  0.00011504616594526507\n","epoch 6\n","The cost at the end of this epoch is  0.0613078603885882\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   2.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   3. 241.   8.   2.   6.   7.   5.   9.   2.]\n"," [  2.   6.  19. 247.   1.  17.   0.   5.   1.   5.]\n"," [  1.   3.   1.   0. 294.   1.   7.   5.   2.   6.]\n"," [  5.   4.   2.  17.   0. 250.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.   9. 257.   0.   7.   0.]\n"," [  1.   2.   3.   5.   2.   0.   0. 263.   1.  15.]\n"," [  3.  11.   8.  10.   0.  11.   2.   1. 266.  12.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8814114100286268 Precision Macro 0.8807934507209225\n","Change of the performance: 0.00035489291378298926 0.0003011156512273683 \n","Change of cost:  6.66911219766031e-05\n","epoch 7\n","The cost at the end of this epoch is  0.061002194458441905\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   5.   4.   3.   2.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 239.   9.   2.   6.   7.   6.   8.   2.]\n"," [  3.   7.  19. 242.   1.  20.   0.   5.   1.   5.]\n"," [  1.   3.   1.   0. 294.   1.   7.   5.   2.   6.]\n"," [  7.   4.   1.  16.   0. 251.   4.   0.   6.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   3.   3.   2.   0.   0. 265.   1.  15.]\n"," [  3.  13.   8.   9.   0.  15.   2.   1. 261.  12.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8791822806018039 Precision Macro 0.8786106126138211\n","Change of the performance: 0.002229129426822851 0.0021828381071014036 \n","Change of cost:  0.00018176327230088468\n","epoch 8\n","The cost at the end of this epoch is  0.06046083458490189\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   1.   3.   1.   6.   4.   2.   2.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  4.   4. 240.   7.   2.   7.   7.   7.   8.   2.]\n"," [  3.   7.  21. 242.   1.  16.   1.   5.   1.   6.]\n"," [  1.   3.   1.   0. 294.   1.   8.   4.   2.   6.]\n"," [  5.   4.   2.  17.   0. 249.   5.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  10. 258.   0.   5.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 263.   1.  15.]\n"," [  2.  13.   8.   8.   0.  14.   2.   0. 262.  15.]\n"," [  1.   0.   1.   0.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8796236339363894 Precision Macro 0.8787932730401551\n","Change of the performance: 0.00044135333458550363 0.00018266042633396928 \n","Change of cost:  0.00030386186846709934\n","epoch 9\n","The cost at the end of this epoch is  0.060151309180323534\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  4.   4. 240.   9.   2.   6.   7.   6.   8.   2.]\n"," [  2.   7.  19. 244.   1.  17.   1.   5.   2.   5.]\n"," [  1.   3.   1.   0. 293.   1.   8.   5.   2.   6.]\n"," [  5.   4.   2.  17.   0. 250.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   5.   2.   0.   0. 262.   1.  15.]\n"," [  3.  14.   8.   8.   0.  15.   2.   0. 260.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.   9.   2. 239.]]\n","Accuracy Macro 0.8786364535811645 Precision Macro 0.8778654434622896\n","Change of the performance: 0.000987180355224937 0.0009278295778655243 \n","Change of cost:  0.00032248835545108795\n","epoch 10\n","The cost at the end of this epoch is  0.059926102657591754\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 240.   9.   2.   6.   7.   5.   8.   2.]\n"," [  3.   7.  20. 240.   1.  20.   1.   5.   1.   5.]\n"," [  1.   3.   2.   0. 292.   1.   8.   5.   2.   6.]\n"," [  6.   4.   1.  16.   0. 252.   4.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 263.   1.  15.]\n"," [  3.  12.   8.   8.   0.  15.   2.   0. 262.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8784016541173747 Precision Macro 0.8777716591854912\n","Change of the performance: 0.0002347994637897921 9.378427679840318e-05 \n","Change of cost:  2.496043844606166e-06\n","epoch 11\n","The cost at the end of this epoch is  0.06013749572903838\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  4.   4. 237.   8.   2.   7.   7.   9.   8.   2.]\n"," [  3.   7.  17. 241.   1.  18.   1.   7.   2.   6.]\n"," [  1.   3.   2.   0. 292.   1.   8.   5.   2.   6.]\n"," [  6.   4.   1.  16.   0. 250.   4.   0.   8.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   3.   2.   0.   0. 266.   1.  13.]\n"," [  3.  12.   9.   8.   0.  13.   2.   1. 264.  12.]\n"," [  1.   0.   0.   0.  12.   1.   0.  12.   2. 237.]]\n","Accuracy Macro 0.8775129710207878 Precision Macro 0.8768416825498091\n","Change of the performance: 0.0008886830965868509 0.0009299766356820616 \n","Change of cost:  0.0001613347737317375\n","epoch 12\n","The cost at the end of this epoch is  0.059415213063859634\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  4.   4. 239.   9.   2.   7.   7.   6.   8.   2.]\n"," [  3.   7.  17. 243.   1.  19.   1.   5.   2.   5.]\n"," [  1.   3.   1.   0. 293.   1.   8.   5.   2.   6.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  11. 257.   0.   5.   0.]\n"," [  1.   2.   4.   3.   2.   0.   0. 264.   1.  15.]\n"," [  3.  13.   8.   9.   0.  14.   2.   0. 261.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8782284170340695 Precision Macro 0.877626576096309\n","Change of the performance: 0.000715446013281662 0.0007848935464999096 \n","Change of cost:  2.541932534454172e-06\n","epoch 13\n","The cost at the end of this epoch is  0.05931197592473591\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  4.   4. 239.   9.   2.   7.   7.   6.   8.   2.]\n"," [  3.   7.  18. 242.   1.  18.   1.   6.   2.   5.]\n"," [  1.   3.   2.   0. 292.   1.   8.   5.   2.   6.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   3.   2.   0.   0. 265.   1.  14.]\n"," [  3.  12.   8.   8.   0.  15.   2.   0. 262.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.  10.   2. 238.]]\n","Accuracy Macro 0.8782998848412635 Precision Macro 0.8776281689451935\n","Change of the performance: 7.146780719402557e-05 1.5928488844574318e-06 \n","Change of cost:  6.501283322184193e-05\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_25_1150x785_10x1151\n","Lambda exported:  0.0\n"],"name":"stdout"}]},{"metadata":{"id":"36ZHIFjxKQgu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1895},"outputId":"4e88887a-f5e0-4e8c-aba7-5abdbaaf3180","executionInfo":{"status":"ok","timestamp":1551234775100,"user_tz":300,"elapsed":604,"user":{"displayName":"Jason Guo","photoUrl":"","userId":"14099781163872529237"}}},"cell_type":"code","source":["#result = {\"confusion\":confusion,\"accMacro\":accMacro, \"precMacro\":precMacro}\n","#For each iteration, a result list is returned. results = [result]\n","#This time, we return a list of the result list.\n","\n","costs_end = []\n","acc_end = []\n","prec_end = []\n","costs_250 = []\n","acc_10 = []\n","prec_10 = []\n","\n","\n","\n","\n","print(\"The costs at the last point of fitting are:\")\n","for i in Result_list:\n","    print(i['nodes'], i['costs'][len(i['costs']) - 1])\n","    costs_end.append(i['costs'][len(i['costs']) - 1])\n","    costs_250.append(i['costs'][250])\n","    \n","print(\"The costs at the 250th iteration:\")\n","for i in costs_250:\n","    print(i)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["The costs at the last point of fitting are:\n","100 0.18955605178755638\n","150 0.1512905640618812\n","200 0.13414595935768406\n","250 0.11896248892231492\n","300 0.11078005065548885\n","350 0.10103430794323673\n","400 0.09623171282948245\n","450 0.0890100017506292\n","500 0.08282664623663842\n","550 0.07805307920387422\n","600 0.07661055314007117\n","650 0.07321167260683617\n","700 0.06967952959288551\n","750 0.06900367427802591\n","800 0.06777667032526728\n","850 0.06602896182644498\n","900 0.06491226458424174\n","950 0.06428549743402615\n","1000 0.06190406821451882\n","1050 0.061724242738681545\n","1100 0.060975055336653546\n","1150 0.05931197592473591\n","The costs at the 250th iteration:\n","0.21056662904430642\n","0.16287431628853258\n","0.14063895275266186\n","0.12413350585658388\n","0.11418758396610225\n","0.10396134260383014\n","0.09790121065853621\n","0.0917477200010214\n","0.08539284366280572\n","0.07982801107397251\n","0.07889972320573796\n","0.07361434197672057\n","0.07102703188010281\n","0.07072373023074402\n","0.06919134145642535\n","0.06773463958888504\n","0.06519089801943974\n","0.0661927839514581\n","0.06272072517316257\n","0.06305403457391028\n","0.06150800401832247\n","0.05993381071813489\n","The precisions at the last point of fitting:\n","100 0.8877521282655583\n","150 0.8913805619886535\n","200 0.8859592298745917\n","250 0.884922171942598\n","300 0.8859174250031272\n","350 0.8886137152263464\n","400 0.88944441690006\n","450 0.8901810559783009\n","500 0.8889742753841707\n","550 0.887679364369286\n","600 0.8855838807625789\n","650 0.8827295983755006\n","700 0.8817136827816459\n","750 0.8843803525850644\n","800 0.8831971025268943\n","850 0.8820378349629843\n","900 0.8827437610738482\n","950 0.8817211311595881\n","1000 0.883408465673926\n","1050 0.8810479489905987\n","1100 0.879611482489462\n","1150 0.8782998848412635\n","The accuracy at the last point of fitting:\n","100 0.8876258638633596\n","150 0.8913337938408439\n","200 0.886169039319031\n","250 0.8853856803554259\n","300 0.886033657569644\n","350 0.8885478620134359\n","400 0.8893052655265865\n","450 0.8898087646914776\n","500 0.8884401521444593\n","550 0.8872774813295081\n","600 0.8852424109356235\n","650 0.8824041223539052\n","700 0.8812416556924362\n","750 0.8838953675199013\n","800 0.8826688265577133\n","850 0.8814781506625637\n","900 0.8819904669794771\n","950 0.8809674938952347\n","1000 0.882565002965468\n","1050 0.8803335917658236\n","1100 0.878908671252591\n","1150 0.8776281689451935\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAewAAAFNCAYAAADCalwrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYQYAP4/RQxLxPwFDIMAAAAASUVORK5CYII=\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"631IUgY0zLbs","colab_type":"text"},"cell_type":"markdown","source":["**The costs keep dropping as we increase the number of nodes.\n","Let's see how precision and accuracy behaves.**"]},{"metadata":{"id":"209EIDKIzKMq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1122},"outputId":"b76d0c7f-ba15-4fa5-c1ec-14e741c57712","executionInfo":{"status":"ok","timestamp":1551234947248,"user_tz":300,"elapsed":901,"user":{"displayName":"Jason Guo","photoUrl":"","userId":"14099781163872529237"}}},"cell_type":"code","source":["print(\"The precisions at the last point of fitting:\")\n","for i in Result_list:\n","    print(i['nodes'], i['results'][len(i['results']) - 1]['accMacro'])\n","    acc_end.append(i['results'][len(i['results']) - 1]['accMacro'])\n","    acc_10.append(i['results'][10]['accMacro'])\n","\n","print(\"The accuracy at the last point of fitting:\")\n","for i in Result_list:\n","    print(i['nodes'], i['results'][len(i['results']) - 1]['precMacro'])\n","    prec_end.append(i['results'][len(i['results']) - 1]['precMacro'])\n","    prec_10.append(i['results'][10]['precMacro'])\n","    \n","\n","fig, ax = plt.subplots()\n","\n","ax.plot(acc_end, 'red')\n","ax.plot(prec_end, 'blue')\n","ax.plot(acc_10, 'yellow')\n","ax.plot(prec_10, 'purple')\n","\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["The precisions at the last point of fitting:\n","100 0.8877521282655583\n","150 0.8913805619886535\n","200 0.8859592298745917\n","250 0.884922171942598\n","300 0.8859174250031272\n","350 0.8886137152263464\n","400 0.88944441690006\n","450 0.8901810559783009\n","500 0.8889742753841707\n","550 0.887679364369286\n","600 0.8855838807625789\n","650 0.8827295983755006\n","700 0.8817136827816459\n","750 0.8843803525850644\n","800 0.8831971025268943\n","850 0.8820378349629843\n","900 0.8827437610738482\n","950 0.8817211311595881\n","1000 0.883408465673926\n","1050 0.8810479489905987\n","1100 0.879611482489462\n","1150 0.8782998848412635\n","The accuracy at the last point of fitting:\n","100 0.8876258638633596\n","150 0.8913337938408439\n","200 0.886169039319031\n","250 0.8853856803554259\n","300 0.886033657569644\n","350 0.8885478620134359\n","400 0.8893052655265865\n","450 0.8898087646914776\n","500 0.8884401521444593\n","550 0.8872774813295081\n","600 0.8852424109356235\n","650 0.8824041223539052\n","700 0.8812416556924362\n","750 0.8838953675199013\n","800 0.8826688265577133\n","850 0.8814781506625637\n","900 0.8819904669794771\n","950 0.8809674938952347\n","1000 0.882565002965468\n","1050 0.8803335917658236\n","1100 0.878908671252591\n","1150 0.8776281689451935\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAewAAAFNCAYAAADCalwrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"0uvS_Lq_z30H","colab_type":"text"},"cell_type":"markdown","source":["Something is wrong with the length of the performance list. It repeated itself twice. And since we studied 100~1150 in steps of 50, clearly only the first 24 points are useful.\n","##The number of layers is chosen to be 450.\n","And we clearly didn't see an"]},{"metadata":{"id":"xalgU1b50qLX","colab_type":"text"},"cell_type":"markdown","source":["#Change the number of layers to 3."]},{"metadata":{"id":"H9wNrzeKqbo4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":5695},"outputId":"b8ba9cd5-16c7-4773-f07f-0cceb614b073","executionInfo":{"status":"ok","timestamp":1551235516116,"user_tz":300,"elapsed":46192,"user":{"displayName":"Jason Guo","photoUrl":"","userId":"14099781163872529237"}}},"cell_type":"code","source":["threeLayers = neuralNetwork()\n","threeLayers.initialize(XTrain, np.array([450, 450, 10]), Lambda=0.0)\n","costs, results = NN.fit(yTrain_oneHot, learningRate=0.01, epochs=100, numBatches=20, realtime_eval=True, delta= 0.0001, XTest=XTest, yTest_oneHot=yTest_oneHot)\n","\n","nn.export()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["No sample data passed, please use load() or initialize() to build your network\n","No weights layers passed, please use load() or initialize() to build your network\n","All memory of current progress has been cleared\n","Randomly generating new network layers using hidden_nodes\n","The numbers of hidden nodes are:  [450 450  10]\n","The #0 weights layer is RNGed, shape:  <class 'list'> (450, 785)\n","The # 1  weights layer is RNGed, shape:  (450, 451)\n","The # 2  weights layer is RNGed, shape:  (10, 451)\n","The original sample:\n"," <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 0 ] is  <class 'numpy.ndarray'> (7000, 784)\n","The generated neural layers: z[ 1 ] is  <class 'numpy.ndarray'> (7000, 450)\n","The generated neural layers: z[ 2 ] is  <class 'numpy.ndarray'> (7000, 450)\n","The generated neural layers: z[ 3 ] is  <class 'numpy.ndarray'> (7000, 10)\n","The a list: a[ 0 ] is <class 'numpy.ndarray'>\n","The a list: a[ 1 ] is <class 'numpy.ndarray'>\n","The a list: a[ 2 ] is <class 'numpy.ndarray'>\n","The output probabilities are:\n"," <class 'numpy.ndarray'> (7000, 10)\n","epoch 0\n","The cost at the end of this epoch is  0.06072140962920775\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   6.   4.   2.   2.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  6.   4. 239.   8.   2.   6.   7.   5.   9.   2.]\n"," [  3.   7.  20. 238.   1.  21.   1.   5.   1.   6.]\n"," [  1.   3.   1.   0. 294.   1.   8.   3.   2.   7.]\n"," [  7.   4.   1.  16.   0. 251.   5.   0.   6.   0.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   2.   4.   4.   2.   0.   0. 263.   1.  15.]\n"," [  3.  11.   8.   9.   0.  14.   2.   0. 263.  14.]\n"," [  1.   0.   1.   0.  12.   1.   0.   8.   2. 240.]]\n","Accuracy Macro 0.8789265765040687 Precision Macro 0.8783163441746822\n","epoch 1\n","The cost at the end of this epoch is  0.060391428383193495\n","Now let's test the model after this epoch:\n","Confusion array  [[300.   0.   0.   3.   1.   5.   4.   2.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 240.   9.   2.   5.   7.   6.   8.   2.]\n"," [  3.   7.  19. 240.   1.  19.   1.   4.   2.   7.]\n"," [  1.   3.   1.   0. 293.   1.   8.   5.   3.   5.]\n"," [  5.   4.   2.  17.   0. 249.   5.   0.   8.   0.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   4.   3.   4.   2.   0.   0. 263.   2.  13.]\n"," [  4.  12.   8.   9.   1.  12.   2.   0. 263.  13.]\n"," [  1.   0.   0.   0.  12.   1.   0.  13.   2. 236.]]\n","Accuracy Macro 0.8774222755982137 Precision Macro 0.87671187511523\n","epoch 2\n","The cost at the end of this epoch is  0.06213058507617146\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   5.   4.   3.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   3. 246.   4.   2.   5.   7.   5.   9.   2.]\n"," [  3.   6.  19. 242.   1.  18.   0.   6.   2.   6.]\n"," [  1.   3.   3.   0. 293.   2.   6.   5.   2.   5.]\n"," [  6.   4.   1.  17.   0. 249.   4.   0.   9.   0.]\n"," [  7.   3.   5.   0.   3.   9. 258.   0.   7.   0.]\n"," [  1.   2.   4.   3.   2.   0.   0. 264.   1.  15.]\n"," [  3.   8.   8.   9.   0.  12.   2.   1. 267.  14.]\n"," [  1.   0.   0.   0.  12.   1.   0.  14.   1. 236.]]\n","Accuracy Macro 0.8817707089374265 Precision Macro 0.8811116768207947\n","Change of the performance: 0.004348433339212754 0.004399801705564754 \n","Change of cost:  0.0002414134555035613\n","epoch 3\n","The cost at the end of this epoch is  0.06088181342821481\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   8.   3.   2.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  4.   4. 239.   8.   2.   7.   7.   7.   8.   2.]\n"," [  2.   7.  20. 242.   1.  17.   1.   5.   1.   7.]\n"," [  1.   3.   2.   0. 294.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  17.   0. 251.   4.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.  11. 257.   0.   5.   0.]\n"," [  1.   3.   3.   4.   2.   0.   0. 264.   1.  14.]\n"," [  3.  13.   8.   9.   1.  12.   2.   0. 263.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8788281679813865 Precision Macro 0.8782364840388075\n","Change of the performance: 0.002942540956039963 0.0028751927819872236 \n","Change of cost:  0.0002961073791857907\n","epoch 4\n","The cost at the end of this epoch is  0.06041026846967594\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 238.   8.   2.   5.   7.   7.  10.   2.]\n"," [  3.   7.  19. 240.   1.  20.   1.   5.   2.   5.]\n"," [  1.   3.   2.   0. 295.   1.   7.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 252.   4.   0.   7.   0.]\n"," [  8.   2.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   3.   4.   3.   2.   0.   0. 265.   1.  13.]\n"," [  2.  13.   8.   8.   1.  15.   2.   0. 261.  14.]\n"," [  1.   0.   1.   0.  13.   1.   0.  11.   2. 236.]]\n","Accuracy Macro 0.8778260306510118 Precision Macro 0.8772526493790774\n","Change of the performance: 0.001002137330374686 0.0009838346597300651 \n","Change of cost:  0.0013390660622900896\n","epoch 5\n","The cost at the end of this epoch is  0.060900679760340824\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 291.   4.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 238.   8.   2.   5.   7.   8.   9.   2.]\n"," [  3.   6.  19. 244.   1.  18.   0.   5.   2.   5.]\n"," [  1.   3.   3.   0. 293.   2.   6.   4.   3.   5.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   7.   1.]\n"," [  8.   3.   5.   0.   4.  11. 256.   0.   5.   0.]\n"," [  1.   2.   2.   3.   2.   0.   0. 266.   1.  15.]\n"," [  2.  11.   8.   9.   0.  14.   2.   0. 263.  15.]\n"," [  1.   0.   1.   0.  11.   1.   0.   9.   2. 240.]]\n","Accuracy Macro 0.8799783776662125 Precision Macro 0.8793180594605273\n","Change of the performance: 0.0021523470152006174 0.002065410081449892 \n","Change of cost:  0.0022361738664598216\n","epoch 6\n","The cost at the end of this epoch is  0.06095049032712558\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   1.   3.   1.   8.   3.   2.   2.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  4.   4. 243.   6.   2.   7.   7.   5.   8.   2.]\n"," [  1.   7.  22. 241.   1.  18.   1.   5.   1.   6.]\n"," [  1.   3.   3.   1. 292.   1.   8.   4.   2.   5.]\n"," [  5.   4.   2.  17.   0. 251.   4.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   3.   4.   3.   2.   0.   0. 265.   1.  13.]\n"," [  3.  12.   8.   9.   1.  12.   2.   1. 264.  12.]\n"," [  1.   0.   1.   0.  12.   1.   0.  13.   2. 235.]]\n","Accuracy Macro 0.8791584146145762 Precision Macro 0.8786532659402404\n","Change of the performance: 0.00081996305163623 0.0006647935202869215 \n","Change of cost:  0.0015633344039602814\n","epoch 7\n","The cost at the end of this epoch is  0.061004131435769465\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 241.   7.   2.   6.   7.   5.   9.   2.]\n"," [  3.   6.  20. 242.   1.  20.   0.   4.   1.   6.]\n"," [  1.   3.   1.   0. 294.   1.   8.   5.   2.   5.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   8.   0.]\n"," [  8.   3.   5.   0.   4.   9. 257.   0.   6.   0.]\n"," [  1.   3.   4.   4.   2.   0.   0. 263.   1.  14.]\n"," [  3.   9.   8.   9.   0.  14.   2.   1. 265.  13.]\n"," [  1.   0.   1.   0.  12.   2.   0.  11.   2. 236.]]\n","Accuracy Macro 0.8791056067236525 Precision Macro 0.8786413893189314\n","Change of the performance: 5.280789092376725e-05 1.1876621308970492e-05 \n","Change of cost:  0.0005920436660885597\n","epoch 8\n","The cost at the end of this epoch is  0.0595909979374458\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   1.   3.   1.   8.   3.   3.   2.   0.]\n"," [  0. 292.   4.   2.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 243.   6.   2.   6.   7.   5.   8.   2.]\n"," [  2.   7.  21. 241.   1.  20.   0.   5.   1.   5.]\n"," [  1.   3.   2.   0. 294.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 252.   4.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.  11. 257.   0.   5.   0.]\n"," [  1.   2.   4.   3.   2.   0.   0. 265.   1.  14.]\n"," [  3.  11.   8.   8.   0.  16.   2.   1. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  10.   2. 238.]]\n","Accuracy Macro 0.880328568313059 Precision Macro 0.8799570508763349\n","Change of the performance: 0.0012229615894064905 0.0013156615574034802 \n","Change of cost:  5.3155028747357835e-05\n","epoch 9\n","The cost at the end of this epoch is  0.05888857771384533\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   6.   4.   2.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   5. 239.   8.   2.   6.   7.   6.   8.   2.]\n"," [  3.   7.  18. 242.   1.  18.   1.   6.   1.   6.]\n"," [  1.   3.   2.   0. 294.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  17.   0. 250.   5.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   3.   4.   3.   2.   0.   0. 265.   1.  13.]\n"," [  3.  13.   8.   9.   1.  13.   2.   0. 262.  13.]\n"," [  1.   0.   1.   0.  13.   1.   0.  11.   2. 236.]]\n","Accuracy Macro 0.8784542710915346 Precision Macro 0.8778160329302034\n","Change of the performance: 0.0018742972215243237 0.0021410179461315293 \n","Change of cost:  0.00012009009139726107\n","epoch 10\n","The cost at the end of this epoch is  0.05898026730343679\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   2.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  6.   4. 241.   7.   2.   5.   7.   6.   8.   2.]\n"," [  2.   7.  20. 243.   1.  18.   1.   5.   1.   5.]\n"," [  1.   3.   2.   0. 294.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  17.   0. 249.   5.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  11. 257.   0.   5.   0.]\n"," [  1.   3.   4.   4.   2.   0.   0. 264.   1.  13.]\n"," [  3.  13.   8.   9.   0.  13.   2.   1. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8788543482814088 Precision Macro 0.8781923887976628\n","Change of the performance: 0.00040007718987422614 0.0003763558674594325 \n","Change of cost:  8.173353549793122e-05\n","epoch 11\n","The cost at the end of this epoch is  0.05918320483618483\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 238.   9.   2.   6.   7.   6.   9.   2.]\n"," [  3.   7.  18. 241.   1.  18.   1.   6.   2.   6.]\n"," [  1.   3.   1.   0. 294.   1.   8.   5.   2.   5.]\n"," [  7.   4.   1.  16.   0. 249.   5.   0.   7.   1.]\n"," [  8.   2.   5.   0.   4.   9. 258.   0.   6.   0.]\n"," [  1.   3.   4.   3.   2.   0.   0. 266.   1.  12.]\n"," [  3.  13.   8.   9.   0.  12.   2.   1. 263.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8794320510701393 Precision Macro 0.8786401058102943\n","Change of the performance: 0.0005777027887304831 0.00044771701263146557 \n","Change of cost:  0.0004373685124272192\n","epoch 12\n","The cost at the end of this epoch is  0.05846895146400056\n","Now let's test the model after this epoch:\n","Confusion array  [[297.   0.   0.   3.   1.   7.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 241.   8.   2.   5.   7.   6.   8.   2.]\n"," [  2.   7.  19. 242.   1.  19.   1.   5.   2.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 250.   5.   0.   7.   1.]\n"," [  8.   3.   5.   0.   4.  11. 256.   0.   5.   0.]\n"," [  1.   3.   4.   3.   2.   0.   0. 265.   1.  13.]\n"," [  3.  13.   8.   9.   0.  13.   2.   1. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8788671774555106 Precision Macro 0.8782316873203134\n","Change of the performance: 0.0005648736146287581 0.00040841848998085517 \n","Change of cost:  0.000345043888431415\n","epoch 13\n","The cost at the end of this epoch is  0.058130641143498474\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   6.   4.   2.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 239.   9.   2.   6.   7.   6.   8.   2.]\n"," [  3.   7.  18. 240.   1.  22.   0.   5.   2.   5.]\n"," [  1.   3.   1.   0. 296.   1.   7.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 252.   4.   0.   7.   0.]\n"," [  8.   3.   5.   0.   4.  10. 256.   0.   6.   0.]\n"," [  1.   3.   4.   3.   2.   0.   0. 265.   1.  13.]\n"," [  3.  13.   8.   8.   0.  14.   2.   1. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.879143752994489 Precision Macro 0.8787586965738828\n","Change of the performance: 0.0002765755389784186 0.0005270092535694104 \n","Change of cost:  6.517082883528147e-05\n","epoch 14\n","The cost at the end of this epoch is  0.05809993692436319\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   2.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 241.   8.   2.   5.   7.   6.   8.   2.]\n"," [  2.   7.  20. 243.   1.  18.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  17.   0. 250.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  11. 257.   0.   5.   0.]\n"," [  1.   3.   4.   4.   2.   0.   0. 264.   1.  13.]\n"," [  3.  13.   8.   9.   0.  13.   2.   1. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8795116758676158 Precision Macro 0.8788801603888438\n","Change of the performance: 0.0003679228731268136 0.0001214638149609204 \n","Change of cost:  0.00032605697993149524\n","epoch 15\n","The cost at the end of this epoch is  0.058312258279327664\n","Now let's test the model after this epoch:\n","Confusion array  [[301.   0.   0.   3.   1.   5.   4.   2.   2.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 241.   8.   2.   5.   7.   6.   8.   2.]\n"," [  3.   7.  19. 241.   1.  19.   1.   5.   2.   5.]\n"," [  1.   3.   0.   0. 295.   1.   8.   5.   2.   5.]\n"," [  6.   4.   1.  16.   0. 251.   5.   0.   7.   0.]\n"," [  7.   3.   5.   0.   4.   9. 258.   0.   6.   0.]\n"," [  1.   3.   4.   4.   2.   0.   0. 264.   1.  13.]\n"," [  3.  13.   8.   9.   0.  13.   2.   1. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8804822994270616 Precision Macro 0.8797455380461827\n","Change of the performance: 0.0009706235594457713 0.0008653776573389615 \n","Change of cost:  0.0003967723594918704\n","epoch 16\n","The cost at the end of this epoch is  0.057883436823032416\n","Now let's test the model after this epoch:\n","Confusion array  [[299.   0.   0.   3.   1.   6.   4.   2.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 241.   8.   2.   5.   7.   6.   8.   2.]\n"," [  3.   7.  20. 242.   1.  18.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 250.   5.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   3.   4.   3.   2.   0.   0. 265.   1.  13.]\n"," [  3.  13.   8.   9.   0.  13.   2.   1. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8798385740265452 Precision Macro 0.8791152936675495\n","Change of the performance: 0.0006437254005163817 0.0006302443786332379 \n","Change of cost:  5.956238497188682e-06\n","epoch 17\n","The cost at the end of this epoch is  0.05807815271643835\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   7.   4.   2.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 241.   8.   2.   6.   7.   5.   8.   2.]\n"," [  2.   7.  20. 240.   1.  21.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 251.   4.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  11. 257.   0.   5.   0.]\n"," [  1.   3.   4.   4.   2.   0.   0. 264.   1.  13.]\n"," [  3.  12.   8.   9.   0.  13.   2.   1. 263.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8791750464192303 Precision Macro 0.8786592504848603\n","Change of the performance: 0.0006635276073149177 0.0004560431826892142 \n","Change of cost:  4.823238286109921e-05\n","epoch 18\n","The cost at the end of this epoch is  0.057684835525860075\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 241.   8.   2.   5.   7.   6.   8.   2.]\n"," [  3.   7.  19. 242.   1.  18.   1.   5.   2.   5.]\n"," [  1.   3.   1.   0. 296.   1.   7.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 250.   5.   0.   7.   1.]\n"," [  8.   3.   5.   0.   4.  11. 256.   0.   5.   0.]\n"," [  1.   3.   4.   4.   2.   0.   0. 264.   1.  13.]\n"," [  3.  13.   8.   9.   0.  13.   2.   1. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8791516771108906 Precision Macro 0.8785121644598561\n","Change of the performance: 2.3369308339682426e-05 0.00014708602500412837 \n","Change of cost:  1.6884565179689504e-05\n","epoch 19\n","The cost at the end of this epoch is  0.05766067067331548\n","Now let's test the model after this epoch:\n","Confusion array  [[298.   0.   0.   3.   1.   6.   4.   3.   3.   0.]\n"," [  0. 292.   3.   3.   0.   2.   0.   0.   7.   1.]\n"," [  5.   4. 241.   8.   2.   5.   7.   6.   8.   2.]\n"," [  3.   7.  20. 242.   1.  18.   1.   5.   1.   5.]\n"," [  1.   3.   1.   0. 295.   1.   8.   4.   2.   5.]\n"," [  6.   4.   1.  16.   0. 250.   5.   0.   7.   1.]\n"," [  7.   3.   5.   0.   4.  10. 257.   0.   6.   0.]\n"," [  1.   3.   4.   4.   2.   0.   0. 264.   1.  13.]\n"," [  3.  13.   8.   9.   0.  13.   2.   1. 262.  13.]\n"," [  1.   0.   1.   0.  12.   1.   0.  11.   2. 237.]]\n","Accuracy Macro 0.8791816428643155 Precision Macro 0.878450686990513\n","Change of the performance: 2.9965753424954222e-05 6.14774693431519e-05 \n","Change of cost:  4.120141122769538e-06\n","The fitting stopped improving and has been terminated, while the progress has been saved.\n","The filename will be:  2019_2_27_2_45_1150x785_10x1151\n","Lambda exported:  0.0\n"],"name":"stdout"}]},{"metadata":{"id":"dAAxCdy22HWn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":347},"outputId":"ec1a3401-cba3-4492-fe31-7dafcc837c0c","executionInfo":{"status":"ok","timestamp":1551235594772,"user_tz":300,"elapsed":609,"user":{"displayName":"Jason Guo","photoUrl":"","userId":"14099781163872529237"}}},"cell_type":"code","source":["plt.plot(costs)\n","plt.show()"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAe0AAAFKCAYAAAAwrQetAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYQivgMAnrGU/ZaX7wAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}