{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase boundary recognition\n",
    "We will now apply the trained multiheaded network and apply it to the phase diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD0_0~0_0.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD0_1~0_1.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD0_2~0_2.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD0_3~0_3.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD0_4~0_4.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD0_5~0_5.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD0_7~0_7.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD0_6~0_6.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD0_9~0_9.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD0_8~0_8.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD1_0~1_0.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD1_1~1_1.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD1_2~1_2.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD1_5~1_5.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD1_6~1_6.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD1_3~1_3.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD1_4~1_4.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD1_9~1_9.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD1_7~1_7.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD1_8~1_8.csv added\n",
      "/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/PhaseDiagramD2_0~2_0.csv added\n",
      "The size of our phase diagram:  7056\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#The data is stored here. We will use a list to store all the relavant PhaseDiagram csv files.\n",
    "filepath = \"/users/PAS1495/gsdbuilder/6820BigData/bigdata_6820-JasonGuo0/ProjectData/Summary/Dataset/\"\n",
    "Phases = []\n",
    "for roots, dirs, files in os.walk(filepath):\n",
    "    for file_ in files:\n",
    "        if file_.endswith('.csv') and file_.startswith('PhaseDiagram'):\n",
    "            print(filepath + file_ +\" added\")\n",
    "            Phases.append(filepath + file_)\n",
    "\n",
    "#Concatenate all the csv files.\n",
    "phase_diagram = pd.DataFrame()\n",
    "for i in range(len(Phases)):\n",
    "    phase_diagram = pd.concat([phase_diagram, pd.read_csv(Phases[i])])\n",
    "    \n",
    "print(\"The size of our phase diagram: \", len(phase_diagram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7056, 28, 28, 1)\n",
      "(7056, 2)\n",
      "(7056, 1)\n"
     ]
    }
   ],
   "source": [
    "images_z = phase_diagram.iloc[:, 1568:2352].values.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "DB_coordinates = phase_diagram.iloc[:, 2352:2354].values\n",
    "\n",
    "ave_zspin = phase_diagram.iloc[:, 2356].values.reshape(-1, 1)\n",
    "\n",
    "print(images_z.shape)\n",
    "print(DB_coordinates.shape)\n",
    "print(ave_zspin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "small_kernels (InputLayer)      (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "medium_kernels (InputLayer)     (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "large_kernels (InputLayer)      (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 24, 24, 100)  2600        small_kernels[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 20, 20, 100)  8200        medium_kernels[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 100)  17000       large_kernels[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 100)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 100)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 100)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 100)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 100)          0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 100)          0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_zspin (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 301)          0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 average_zspin[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          30200       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            303         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 58,303\n",
      "Trainable params: 58,303\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Use our train multiheaded network\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D, Reshape\n",
    "from keras.models import Model, load_model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "multiheaded = load_model(\"best_model.multiheaded_withz.h5\")\n",
    "print(\"summary\")\n",
    "print(multiheaded.summary())\n",
    "plot_model(multiheaded, to_file='multiheaded.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7056, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = multiheaded.predict([images_z, images_z, images_z, ave_zspin])\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of all labels: (7056,)\n",
      "The shape of 0vs1 labels:  (5552,)\n",
      "The shape of 0vs1 phase points:  (5552, 2)\n",
      "The shape of 1vs2 labels:  (4005,)\n",
      "The shape of 1vs2 phase points:  (4005, 2)\n"
     ]
    }
   ],
   "source": [
    "labels_0vs1 = []\n",
    "phase_pts_0vs1 = []\n",
    "labels_1vs2 = []\n",
    "phase_pts_1vs2 = []\n",
    "labels = []\n",
    "phase_pts = []\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    max_index = np.argmax(pred[i])\n",
    "    max_value = np.max(pred[i])\n",
    "    \n",
    "    labels.append(max_index)\n",
    "    \n",
    "    #Only keep the predictions that we are confident about enough\n",
    "    if max_value > 0.9:\n",
    "        if max_index == 0 or max_index == 1:\n",
    "            labels_0vs1.append(max_index)\n",
    "            phase_pts_0vs1.append(DB_coordinates[i])\n",
    "        if max_index == 0 or max_index == 2:\n",
    "            labels_1vs2.append(max_index)\n",
    "            phase_pts_1vs2.append(DB_coordinates[i])\n",
    "            \n",
    "labels_0vs1 = np.asarray(labels_0vs1, dtype=np.int)\n",
    "phase_pts_0vs1 = np.asarray(phase_pts_0vs1, dtype=np.float32)\n",
    "\n",
    "labels_1vs2 = np.asarray(labels_1vs2, dtype=np.int)\n",
    "phase_pts_1vs2 = np.asarray(phase_pts_1vs2, dtype=np.float32)\n",
    "labels = np.asarray(labels, dtype=np.int)\n",
    "\n",
    "print(\"The shape of all labels:\", labels.shape)\n",
    "print(\"The shape of 0vs1 labels: \", labels_0vs1.shape)\n",
    "print(\"The shape of 0vs1 phase points: \", phase_pts_0vs1.shape)\n",
    "print(\"The shape of 1vs2 labels: \", labels_1vs2.shape)\n",
    "print(\"The shape of 1vs2 phase points: \", phase_pts_1vs2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_0vs1 = SVC(kernel='rbf')\n",
    "clf_0vs1.fit(phase_pts_0vs1, labels_0vs1)\n",
    "\n",
    "clf_1vs2 = SVC(kernel='rbf')\n",
    "clf_1vs2.fit(phase_pts_1vs2, labels_1vs2)\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0, 2, 200), np.linspace(0, 2, 200))\n",
    "\n",
    "print(xx.shape)\n",
    "\n",
    "Z_0vs1 = clf_0vs1.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z_1vs2 = clf_1vs2.decision_function(np.c_[xx.ravel(), yy.ravel()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.6-conda5.2/lib/python3.6/site-packages/matplotlib/contour.py:1004: UserWarning: The following kwargs were not used by contour: 'linewidth', 'linestyle'\n",
      "  s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(Z_0vs1.shape)\n",
    "Z_0vs1 = Z_0vs1.reshape(xx.shape)\n",
    "Z_1vs2 = Z_1vs2.reshape(xx.shape)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "contours_0vs1 = ax.contour(xx, yy, Z_0vs1, levels=[0], linewidth=4, linestyle='--')\n",
    "contours_1vs2 = ax.contour(xx, yy, Z_1vs2, levels=[0], linewidth=4, linestyle='--')\n",
    "\"\"\"\n",
    "Skyrmions are labeled 0 and reside in the middle of the phase diagram.\n",
    "Ferromagnetic phases are labeled 2 and reside at the top left corner of the diagram.\n",
    "Spin spirals are labeled 1 and reside at the bottom right corner of the diagram \n",
    "\"\"\"\n",
    "\n",
    "points = ax.scatter(DB_coordinates[:, 0], DB_coordinates[:, 1], s=30, c=labels, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "fig.colorbar(points, ax=ax)\n",
    "plt.xlabel('D values')\n",
    "plt.ylabel('B values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decent boundaries between different phases. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Conda 5.2) [python/3.6-conda5.2]",
   "language": "python",
   "name": "sys_python36conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
