{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment5.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "FggU7Q2CI7Du",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment 6: Multi-class classification\n",
        "\n",
        "For this assignment, there are two basic tasks and an open ended additional task for more challenges:\n",
        "1.  Add the \"macro\" averaged precision and recall to the **multiPerformance** method from the multicassv2 exercise (copy all of the relevant code to this module).\n",
        "2.  Add one more class - letters - to your multi-class classifier.   So your classifier will have a total of 11 classes.   The letters data sample is here:\n",
        "            *  Shorter (1000 samples): https://raw.githubusercontent.com/big-data-analytics-physics/data/master/emnist/emnist_letters_shuffled_1k.csv\n",
        "            *  Longer (7000 samples): https://raw.githubusercontent.com/big-data-analytics-physics/data/master/emnist/emnist_letters_shuffled_7k.csv\n",
        "      Note that each of these files has a random sample of 26 upper and lower case english letters.\n",
        "      \n",
        "3.  Extra stuff: if you have time and are looking to expand your abilities, try your hand at data augmentation of the MNIST dataset.   The idea is to examine how to increase (or augment) your data sample, by resampling your existing data sample.  Here are some ideas:\n",
        "             * shift randomly, by 1-2 pixels, the images up/down/left/right\n",
        "             * random rotations by a few degrees.\n",
        "             \n",
        "      First verify that your modifications are working (by displaying the images), then make a \"test\" set using the augmented images only, and compare how it performs using a training set drawn from the original (non-augmented) data set"
      ]
    },
    {
      "metadata": {
        "id": "0NsKyljoM68S",
        "colab_type": "code",
        "outputId": "c05b497f-ef09-4287-9568-2b07b9649e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "letters = pd.read_csv(\"https://raw.githubusercontent.com/big-data-analytics-physics/data/master/emnist/emnist_letters_shuffled_1k.csv\", header=None)\n",
        "letters['digit'] = 10\n",
        "\n",
        "short = \"short_\"\n",
        "\n",
        "# Read in all of the other digits\n",
        "dfCombined = pd.DataFrame()\n",
        "for digit in range(10):\n",
        "    print(\"Processing digit \",digit)\n",
        "    fname = 'https://raw.githubusercontent.com/big-data-analytics-physics/data/master/ch3/digit_' + short + str(digit) + '.csv'\n",
        "    df = pd.read_csv(fname,header=None)\n",
        "    df['digit'] = digit\n",
        "    dfCombined = pd.concat([dfCombined, df])\n",
        "\n",
        "print(\"Length of sample:     \",len(dfCombined))\n",
        "\n",
        "dfCombined = pd.concat([dfCombined, letters])\n",
        "print(\"The length of the combined: \", len(dfCombined))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing digit  0\n",
            "Processing digit  1\n",
            "Processing digit  2\n",
            "Processing digit  3\n",
            "Processing digit  4\n",
            "Processing digit  5\n",
            "Processing digit  6\n",
            "Processing digit  7\n",
            "Processing digit  8\n",
            "Processing digit  9\n",
            "Length of sample:      10000\n",
            "The length of the combined:  11000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FAJlSfkANppY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The multiclass performance method."
      ]
    },
    {
      "metadata": {
        "id": "h11i3IrrOJAL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "dfCombinedShuffle = shuffle(dfCombined,random_state=42)    # by setting the random state we will get reproducible results\n",
        "#We divide the images and the labels and later use KFold to access them.\n",
        "X = dfCombinedShuffle.as_matrix(columns=dfCombinedShuffle.columns[:784])\n",
        "y = dfCombinedShuffle['digit'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aPLVAxQfS4EJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since accuracy's definition here is the same as recall, I'll simply just add macro precision here."
      ]
    },
    {
      "metadata": {
        "id": "2XkOQGkbNo1y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Used to implement the multi-dimensional counter we need in the performance class\n",
        "from collections import defaultdict\n",
        "def autovivify(levels=1, final=dict):\n",
        "    return (defaultdict(final) if levels < 2 else\n",
        "            defaultdict(lambda: autovivify(levels-1, final)))\n",
        "\n",
        "# Determine the performance\n",
        "def multiPerformance(y,y_pred,y_score,debug=False):\n",
        "#\n",
        "# Make our matrix\n",
        "  confusionMatrix = autovivify(2,int) #This matrix is still 2D, but now it's 10x10\n",
        "  classes = set()\n",
        "  totalTrue = defaultdict(int)\n",
        "  totalPred = defaultdict(int)\n",
        "  for i in range(len(y_pred)):\n",
        "    trueClass = y[i] # What the label/digit it really is.\n",
        "    classes.add(trueClass)\n",
        "    predClass = y_pred[i]\n",
        "    totalTrue[trueClass] += 1 #totalTrue is an array of 10 slots, and they keep track of \n",
        "    # the time a digit label shows up.\n",
        "    totalPred[predClass] += 1 # keeps track of the times a certain prediction is made.\n",
        "    confusionMatrix[trueClass][predClass] += 1\n",
        "\n",
        "  if debug:\n",
        "    for trueClass in classes:\n",
        "      print(\"True: \",trueClass,end=\"\")\n",
        "      for predClass in classes:\n",
        "        print(\"\\t\",confusionMatrix[trueClass][predClass],end=\"\")\n",
        "      print()\n",
        "    print()\n",
        "#\n",
        "#\n",
        "# Overall accuracy - sum the diagonals and divide by total\n",
        "  accMicro = 0.0\n",
        "  accMacro = 0.0\n",
        "  precMacro = 0.0\n",
        "  for c1 in classes: #We now will iterate over all the 10 classes.\n",
        "    accMicro += confusionMatrix[c1][c1]\n",
        "    accMacro += confusionMatrix[c1][c1]/totalTrue[c1] #The probability of accurately catching a digit. \n",
        "    #Precision is how confident you are sure of your predictions. A digit really what you predict/ all the predictions of this digit you made\n",
        "    prediction = 0\n",
        "    for c2 in classes:\n",
        "      prediction += confusionMatrix[c2][c1] # We add all the times we predict c1, only [c1][c1] is right though.\n",
        "    precMacro += confusionMatrix[c1][c1] / prediction\n",
        "    #Recall is how sensitive your estimator is to the digit you should catch.\n",
        "    \n",
        "  accMicro /= len(y)\n",
        "  accMacro /=  len(classes) #accMacro averaged.\n",
        "  precMacro /= len(classes)\n",
        "  results = {\"confusionMatrix\":confusionMatrix,\"accuracyMicro\":accMicro,\"accuracyMacro\":accMacro, \"precisionMacro\":precMacro}\n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fRMcmT0aNzka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def runFitter(estimator,X_train,y_train,X_test,y_test,debug=False):\n",
        "#\n",
        "# Now fit to our training set\n",
        "  estimator.fit(X_train,y_train)\n",
        "#\n",
        "# Now predict the classes and get the score for our traing set\n",
        "  y_train_pred = estimator.predict(X_train)\n",
        "  y_train_score = estimator.decision_function(X_train)   # NOTE: some estimators have a predict_prob method instead od descision_function\n",
        "#\n",
        "# Now predict the classes and get the score for our test set\n",
        "  y_test_pred = estimator.predict(X_test)\n",
        "  y_test_score = estimator.decision_function(X_test)\n",
        "\n",
        "#\n",
        "# Now get the performaance\n",
        "  results_test = multiPerformance(y_test,y_test_pred,y_test_score,debug=False)\n",
        "  results_train = multiPerformance(y_train,y_train_pred,y_train_score,debug=False)\n",
        "#\n",
        "# Decide what you want to return: for now, just precision, recall, and auc for both test and train\n",
        "  results = {\n",
        "      'cf_test':results_test['confusionMatrix'],\n",
        "      'cf_train':results_train['confusionMatrix'],\n",
        "      'accuracyMicro_test':results_test['accuracyMicro'],\n",
        "      'accuracyMacro_test':results_test['accuracyMacro'],\n",
        "      'accuracyMicro_train':results_train['accuracyMicro'],\n",
        "      'accuracyMacro_train':results_train['accuracyMacro'],\n",
        "      'precisionMacro_train':results_train['precisionMacro'],\n",
        "      'precisionMacro_test':results_test['precisionMacro']\n",
        "}\n",
        "\n",
        "  return results\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5FgDG8KfOLFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "kfolds = 5\n",
        "\n",
        "#skf = StratifiedKFold(n_splits=kfolds)\n",
        "skf = KFold(n_splits=kfolds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2HjzIjHOOMx",
        "colab_type": "code",
        "outputId": "8635e6c1-5d70-4c23-e696-0acbffd1d4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# Get our estimator and predict\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "estimator = LinearSVC(random_state=42,dual=False,max_iter=500,tol=0.01)    # use dual=False when  n_samples > n_features which is what we have\n",
        "#estimator = SGDClassifier(random_state=42,max_iter=500,tol=0.01)    # use dual=False when  n_samples > n_features which is what we have\n",
        "#\n",
        "# Cresate some vars to keep track of everything\n",
        "avg_accuracyMicro_test = 0.0\n",
        "avg_accuracyMicro_train = 0.0\n",
        "avg_accuracyMacro_test = 0.0\n",
        "avg_accuracyMacro_train = 0.0\n",
        "avg_precisionMacro_train = 0.0\n",
        "avg_precisionMacro_test = 0.0\n",
        "numSplits = 0.0\n",
        "#\n",
        "# Also keep track of the \n",
        "#\n",
        "# Now loop\n",
        "lastCF_train = None\n",
        "lastCF_test = None\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "  print(\"Training\")\n",
        "  X_train = X[train_index]\n",
        "  y_train = y[train_index]\n",
        "  X_test = X[test_index]\n",
        "  y_test = y[test_index]\n",
        "  \n",
        "#\n",
        "# Now fit to our training set\n",
        "  results = runFitter(estimator,X_train,y_train,X_test,y_test)\n",
        "#\n",
        "# \n",
        "  avg_accuracyMicro_test += results['accuracyMicro_test']\n",
        "  avg_accuracyMicro_train += results['accuracyMicro_train']\n",
        "  avg_accuracyMacro_test += results['accuracyMacro_test']\n",
        "  avg_accuracyMacro_train += results['accuracyMacro_train']\n",
        "  avg_precisionMacro_train += results['precisionMacro_train']\n",
        "  avg_precisionMacro_test += results['precisionMacro_test']\n",
        "  lastCF_train = results['cf_train']\n",
        "  lastCF_test = results['cf_test']\n",
        "  numSplits += 1.0\n",
        "  print(\"   Split \",numSplits,\"; accuracyMicro test/train\",results['accuracyMicro_test'],results['accuracyMicro_train'],\"; accuracyMacro test/train\",results['accuracyMacro_test'],results['accuracyMacro_train'])\n",
        "#\n",
        "avg_accuracyMicro_test /= numSplits\n",
        "avg_accuracyMicro_train /= numSplits\n",
        "avg_accuracyMacro_test /= numSplits\n",
        "avg_accuracyMacro_train /= numSplits\n",
        "avg_precisionMacro_train /= numSplits\n",
        "avg_precisionMacro_test /= numSplits\n",
        "\n",
        "print(\"average accuracyMicro test:  \",avg_accuracyMicro_test)\n",
        "print(\"average accuracyMicro train: \",avg_accuracyMicro_train)\n",
        "print(\"average accuracyMacro test:  \",avg_accuracyMacro_test)\n",
        "print(\"average accuracyMacro train: \",avg_accuracyMacro_train)\n",
        "print(\"avg_precisionMacro train: \", avg_precisionMacro_train)\n",
        "print(\"avg_precisionMacro test: \", avg_precisionMacro_test)\n",
        "\n",
        "#This is just making the confusion matrix easier to print on screen\n",
        "print(\"Test confusion matrix\")\n",
        "for trueClass in range(10):\n",
        "  print(\"True: \",trueClass,end=\"\")\n",
        "  for predClass in range(10):\n",
        "    print(\"\\t\",lastCF_test[trueClass][predClass],end=\"\")\n",
        "  print()\n",
        "print()\n",
        "\n",
        "print(\"Train confusion matrix\")\n",
        "for trueClass in range(10):\n",
        "  print(\"True: \",trueClass,end=\"\")\n",
        "  for predClass in range(10):\n",
        "    print(\"\\t\",lastCF_train[trueClass][predClass],end=\"\")\n",
        "  print()\n",
        "print()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n",
            "   Split  1.0 ; accuracyMicro test/train 0.8781818181818182 0.9584090909090909 ; accuracyMacro test/train 0.8777550525016533 0.9583432290590896\n",
            "Training\n",
            "   Split  2.0 ; accuracyMicro test/train 0.8613636363636363 0.96375 ; accuracyMacro test/train 0.8600415288030387 0.9639726662434761\n",
            "Training\n",
            "   Split  3.0 ; accuracyMicro test/train 0.8754545454545455 0.9625 ; accuracyMacro test/train 0.8756474043333871 0.9625930754816242\n",
            "Training\n",
            "   Split  4.0 ; accuracyMicro test/train 0.865 0.9645454545454546 ; accuracyMacro test/train 0.8672396470767807 0.9642454116468427\n",
            "Training\n",
            "   Split  5.0 ; accuracyMicro test/train 0.8631818181818182 0.9609090909090909 ; accuracyMacro test/train 0.8624542280124128 0.9609462727311823\n",
            "average accuracyMicro test:   0.8686363636363638\n",
            "average accuracyMicro train:  0.9620227272727273\n",
            "average accuracyMacro test:   0.8686275721454544\n",
            "average accuracyMacro train:  0.9620201310324429\n",
            "avg_precisionMacro train:  0.9619778989728319\n",
            "avg_precisionMacro test:  0.8684645324972682\n",
            "Test confusion matrix\n",
            "True:  0\t 188\t 0\t 4\t 0\t 0\t 1\t 3\t 0\t 0\t 0\n",
            "True:  1\t 0\t 186\t 3\t 2\t 0\t 1\t 0\t 1\t 3\t 0\n",
            "True:  2\t 1\t 6\t 149\t 5\t 1\t 1\t 4\t 2\t 9\t 2\n",
            "True:  3\t 0\t 2\t 4\t 173\t 0\t 11\t 0\t 0\t 4\t 0\n",
            "True:  4\t 1\t 1\t 2\t 0\t 177\t 2\t 1\t 4\t 4\t 5\n",
            "True:  5\t 2\t 1\t 1\t 10\t 2\t 163\t 5\t 0\t 8\t 3\n",
            "True:  6\t 0\t 0\t 2\t 0\t 2\t 11\t 188\t 0\t 1\t 1\n",
            "True:  7\t 1\t 0\t 2\t 3\t 5\t 0\t 0\t 192\t 1\t 11\n",
            "True:  8\t 0\t 6\t 5\t 6\t 4\t 4\t 6\t 1\t 149\t 7\n",
            "True:  9\t 1\t 1\t 1\t 3\t 8\t 3\t 0\t 8\t 4\t 157\n",
            "\n",
            "Train confusion matrix\n",
            "True:  0\t 800\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\n",
            "True:  1\t 0\t 796\t 1\t 0\t 0\t 0\t 0\t 0\t 5\t 1\n",
            "True:  2\t 2\t 1\t 775\t 4\t 2\t 0\t 1\t 2\t 19\t 1\n",
            "True:  3\t 1\t 1\t 10\t 750\t 3\t 14\t 1\t 5\t 8\t 6\n",
            "True:  4\t 0\t 1\t 0\t 1\t 789\t 0\t 1\t 0\t 3\t 8\n",
            "True:  5\t 0\t 0\t 4\t 14\t 2\t 747\t 4\t 0\t 17\t 4\n",
            "True:  6\t 1\t 1\t 0\t 0\t 1\t 5\t 785\t 0\t 2\t 0\n",
            "True:  7\t 0\t 1\t 3\t 0\t 0\t 0\t 0\t 769\t 0\t 8\n",
            "True:  8\t 4\t 5\t 9\t 14\t 2\t 12\t 4\t 1\t 746\t 5\n",
            "True:  9\t 1\t 2\t 2\t 7\t 3\t 0\t 0\t 8\t 11\t 772\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}